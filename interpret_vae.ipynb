{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret VAE\n",
    "\n",
    "This notebook interprets the weights and biases of a VAE to identify the genes most important to defining the learned clusters in latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from framework.common.dataset import Dataset\n",
    "from framework.keras.autoencoder import VariationalAutoencoder as VAE\n",
    "\n",
    "np.random.seed(1013)\n",
    "tf.set_random_seed(1013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model directory\n",
    "model_dir = \"results/patel/Train1000gPatelGBMVAE/PatelGBMVAE_Final\"\n",
    "\n",
    "# File that lists the cluster associated with each cell\n",
    "cluster_file = model_dir + \"/consensus_clusters_k7.txt\"\n",
    "# Which column in the file to use as the clusters\n",
    "cluster_col = \"consensus_cluster\"\n",
    "\n",
    "dataset_file = \"data/GSE57872_GBM/processed/gbm.1000g.centered.txt\"\n",
    "# GSE57872_GBM; GSE72056_Melanoma, GSE75688_Breast_Cancer\n",
    "dataset_features_start_idx = 1\n",
    "# Start indexes: melanoma = 1; gbm = 1; breast = 2\n",
    "\n",
    "latent_space_file = model_dir + \"/latent_representations.txt\"\n",
    "# What column in latent space file marks the end of \n",
    "# the features and the beginning of labels/other information\n",
    "features_end_col_idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters: 7\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    dataset = pd.read_csv(dataset_file, sep=\"\\t\", header=0, index_col=0)\n",
    "    features = dataset.iloc[:, dataset_features_start_idx:].values.astype(dtype=np.float64)\n",
    "    cell_ids = dataset.index.values\n",
    "    \n",
    "    return dataset, cell_ids, features\n",
    "\n",
    "def load_latent_space():\n",
    "    df = pd.read_csv(latent_space_file, sep=\"\\t\", header=0, index_col=0)\n",
    "    latent_space = df.iloc[:, 0:features_end_col_idx]\n",
    "    \n",
    "    return latent_space\n",
    "\n",
    "def load_clusters():\n",
    "    clusters_df = pd.read_csv(cluster_file, sep=\"\\t\", header=0, index_col=0)\n",
    "    clusters = clusters_df.loc[:, cluster_col]\n",
    "    return clusters\n",
    "\n",
    "dataset, cell_ids, features = load_dataset()\n",
    "latent_space = load_latent_space()\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "clusters = load_clusters()\n",
    "clusters = clusters[cell_ids]\n",
    "\n",
    "latent_space = latent_space.loc[cell_ids, :].values.astype(dtype=np.float64)\n",
    "\n",
    "classes = np.unique(clusters.values)\n",
    "print(\"Number of Clusters:\", len(classes))\n",
    "\n",
    "vae = VAE.restore(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mean_log_var = K.function([vae.autoencoder_model.layers[0].input, K.learning_phase()],\n",
    "                              [vae.autoencoder_model.layers[5].output,\n",
    "                               vae.autoencoder_model.layers[6].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_mean, latent_log_var = tuple(get_mean_log_var([features_scaled, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a t-SNE model to the features for visualization purposes\n",
    "def fit_tsne(features):\n",
    "    tsne_model = TSNE(n_components=2, init='pca', random_state=0, perplexity=30)\n",
    "    return tsne_model.fit_transform(features)\n",
    "\n",
    "tsne_output = fit_tsne(latent_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot_labels = list(clusters)\n",
    "plt.scatter(tsne_output[:, 0], tsne_output[:, 1], \n",
    "            c=tsne_plot_labels, cmap=plt.cm.get_cmap(\n",
    "                \"rainbow\", len(np.unique(tsne_plot_labels))))\n",
    "plt.colorbar(ticks=np.unique(tsne_plot_labels))\n",
    "plt.clim(np.min(tsne_plot_labels)-0.5, np.max(tsne_plot_labels) + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoder_model = Model(vae.encoder_model.layers[0].input, vae.encoder_model.layers[5].output)\n",
    "mean_encoder_model.trainable = False\n",
    "clustering_output = Dense(7, activation=\"linear\")(mean_encoder_model(vae.x))\n",
    "clustering_output = Activation(\"softmax\")(clustering_output)\n",
    "clustering_model = Model(vae.x, clustering_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "x (InputLayer)               (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 10)                1438010   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 77        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,438,087\n",
      "Trainable params: 77\n",
      "Non-trainable params: 1,438,010\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clustering_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
    "                         metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "430/430 [==============================] - 0s - loss: 1.7826 - acc: 0.3093     \n",
      "Epoch 2/100\n",
      "430/430 [==============================] - 0s - loss: 1.7293 - acc: 0.3279     \n",
      "Epoch 3/100\n",
      "430/430 [==============================] - 0s - loss: 1.6773 - acc: 0.3581     \n",
      "Epoch 4/100\n",
      "430/430 [==============================] - 0s - loss: 1.6297 - acc: 0.3837     \n",
      "Epoch 5/100\n",
      "430/430 [==============================] - 0s - loss: 1.6074 - acc: 0.4070     \n",
      "Epoch 6/100\n",
      "430/430 [==============================] - 0s - loss: 1.5668 - acc: 0.4465     \n",
      "Epoch 7/100\n",
      "430/430 [==============================] - 0s - loss: 1.4956 - acc: 0.4628     \n",
      "Epoch 8/100\n",
      "430/430 [==============================] - 0s - loss: 1.4786 - acc: 0.4884     \n",
      "Epoch 9/100\n",
      "430/430 [==============================] - 0s - loss: 1.4198 - acc: 0.5419     \n",
      "Epoch 10/100\n",
      "430/430 [==============================] - 0s - loss: 1.4068 - acc: 0.5140     - ETA: 0s - loss: 1.4249 - acc: 0.505\n",
      "Epoch 11/100\n",
      "430/430 [==============================] - 0s - loss: 1.3571 - acc: 0.5512     \n",
      "Epoch 12/100\n",
      "430/430 [==============================] - 0s - loss: 1.3180 - acc: 0.5791     \n",
      "Epoch 13/100\n",
      "430/430 [==============================] - 0s - loss: 1.2836 - acc: 0.6070     \n",
      "Epoch 14/100\n",
      "430/430 [==============================] - 0s - loss: 1.2515 - acc: 0.6163     \n",
      "Epoch 15/100\n",
      "430/430 [==============================] - 0s - loss: 1.2212 - acc: 0.6209     \n",
      "Epoch 16/100\n",
      "430/430 [==============================] - 0s - loss: 1.2032 - acc: 0.6326     \n",
      "Epoch 17/100\n",
      "430/430 [==============================] - 0s - loss: 1.1643 - acc: 0.6488     \n",
      "Epoch 18/100\n",
      "430/430 [==============================] - 0s - loss: 1.1268 - acc: 0.6651     \n",
      "Epoch 19/100\n",
      "430/430 [==============================] - 0s - loss: 1.1065 - acc: 0.6791     \n",
      "Epoch 20/100\n",
      "430/430 [==============================] - 0s - loss: 1.0842 - acc: 0.6860     \n",
      "Epoch 21/100\n",
      "430/430 [==============================] - 0s - loss: 1.0483 - acc: 0.6953     \n",
      "Epoch 22/100\n",
      "430/430 [==============================] - 0s - loss: 1.0260 - acc: 0.7093     \n",
      "Epoch 23/100\n",
      "430/430 [==============================] - 0s - loss: 1.0265 - acc: 0.6837     \n",
      "Epoch 24/100\n",
      "430/430 [==============================] - 0s - loss: 0.9848 - acc: 0.7093     \n",
      "Epoch 25/100\n",
      "430/430 [==============================] - 0s - loss: 0.9515 - acc: 0.7256     \n",
      "Epoch 26/100\n",
      "430/430 [==============================] - 0s - loss: 0.9423 - acc: 0.7116     \n",
      "Epoch 27/100\n",
      "430/430 [==============================] - 0s - loss: 0.9144 - acc: 0.7442     \n",
      "Epoch 28/100\n",
      "430/430 [==============================] - 0s - loss: 0.9092 - acc: 0.7372     \n",
      "Epoch 29/100\n",
      "430/430 [==============================] - 0s - loss: 0.8683 - acc: 0.7651     \n",
      "Epoch 30/100\n",
      "430/430 [==============================] - 0s - loss: 0.8658 - acc: 0.7512     \n",
      "Epoch 31/100\n",
      "430/430 [==============================] - 0s - loss: 0.8518 - acc: 0.7605     \n",
      "Epoch 32/100\n",
      "430/430 [==============================] - 0s - loss: 0.8228 - acc: 0.7651     \n",
      "Epoch 33/100\n",
      "430/430 [==============================] - 0s - loss: 0.8044 - acc: 0.7814     \n",
      "Epoch 34/100\n",
      "430/430 [==============================] - 0s - loss: 0.8060 - acc: 0.7860     \n",
      "Epoch 35/100\n",
      "430/430 [==============================] - 0s - loss: 0.7728 - acc: 0.7767     \n",
      "Epoch 36/100\n",
      "430/430 [==============================] - 0s - loss: 0.7609 - acc: 0.8023     \n",
      "Epoch 37/100\n",
      "430/430 [==============================] - 0s - loss: 0.7446 - acc: 0.7814     \n",
      "Epoch 38/100\n",
      "430/430 [==============================] - 0s - loss: 0.7267 - acc: 0.8093     \n",
      "Epoch 39/100\n",
      "430/430 [==============================] - 0s - loss: 0.7198 - acc: 0.8209     \n",
      "Epoch 40/100\n",
      "430/430 [==============================] - 0s - loss: 0.7048 - acc: 0.8186     \n",
      "Epoch 41/100\n",
      "430/430 [==============================] - 0s - loss: 0.6876 - acc: 0.8372     \n",
      "Epoch 42/100\n",
      "430/430 [==============================] - 0s - loss: 0.6757 - acc: 0.8488     \n",
      "Epoch 43/100\n",
      "430/430 [==============================] - 0s - loss: 0.6660 - acc: 0.8395     \n",
      "Epoch 44/100\n",
      "430/430 [==============================] - 0s - loss: 0.6409 - acc: 0.8395     \n",
      "Epoch 45/100\n",
      "430/430 [==============================] - 0s - loss: 0.6457 - acc: 0.8395     \n",
      "Epoch 46/100\n",
      "430/430 [==============================] - 0s - loss: 0.6283 - acc: 0.8419     \n",
      "Epoch 47/100\n",
      "430/430 [==============================] - 0s - loss: 0.6157 - acc: 0.8558     \n",
      "Epoch 48/100\n",
      "430/430 [==============================] - 0s - loss: 0.6027 - acc: 0.8651     \n",
      "Epoch 49/100\n",
      "430/430 [==============================] - 0s - loss: 0.5969 - acc: 0.8581     \n",
      "Epoch 50/100\n",
      "430/430 [==============================] - 0s - loss: 0.5921 - acc: 0.8767     \n",
      "Epoch 51/100\n",
      "430/430 [==============================] - 0s - loss: 0.5773 - acc: 0.8698     \n",
      "Epoch 52/100\n",
      "430/430 [==============================] - 0s - loss: 0.5640 - acc: 0.8628     \n",
      "Epoch 53/100\n",
      "430/430 [==============================] - 0s - loss: 0.5630 - acc: 0.8698     \n",
      "Epoch 54/100\n",
      "430/430 [==============================] - 0s - loss: 0.5437 - acc: 0.8791     \n",
      "Epoch 55/100\n",
      "430/430 [==============================] - 0s - loss: 0.5378 - acc: 0.8767     \n",
      "Epoch 56/100\n",
      "430/430 [==============================] - 0s - loss: 0.5307 - acc: 0.8721     \n",
      "Epoch 57/100\n",
      "430/430 [==============================] - 0s - loss: 0.5186 - acc: 0.8837     \n",
      "Epoch 58/100\n",
      "430/430 [==============================] - 0s - loss: 0.5069 - acc: 0.8814     \n",
      "Epoch 59/100\n",
      "430/430 [==============================] - 0s - loss: 0.5219 - acc: 0.8860     \n",
      "Epoch 60/100\n",
      "430/430 [==============================] - 0s - loss: 0.5083 - acc: 0.8884     \n",
      "Epoch 61/100\n",
      "430/430 [==============================] - 0s - loss: 0.4973 - acc: 0.8814     \n",
      "Epoch 62/100\n",
      "430/430 [==============================] - 0s - loss: 0.4839 - acc: 0.8907     \n",
      "Epoch 63/100\n",
      "430/430 [==============================] - 0s - loss: 0.4779 - acc: 0.8791     \n",
      "Epoch 64/100\n",
      "430/430 [==============================] - 0s - loss: 0.4703 - acc: 0.9023     \n",
      "Epoch 65/100\n",
      "430/430 [==============================] - 0s - loss: 0.4667 - acc: 0.8884     \n",
      "Epoch 66/100\n",
      "430/430 [==============================] - 0s - loss: 0.4594 - acc: 0.9023     \n",
      "Epoch 67/100\n",
      "430/430 [==============================] - 0s - loss: 0.4595 - acc: 0.9000     \n",
      "Epoch 68/100\n",
      "430/430 [==============================] - 0s - loss: 0.4503 - acc: 0.8977     \n",
      "Epoch 69/100\n",
      "430/430 [==============================] - 0s - loss: 0.4459 - acc: 0.9140     \n",
      "Epoch 70/100\n",
      "430/430 [==============================] - 0s - loss: 0.4575 - acc: 0.8953     \n",
      "Epoch 71/100\n",
      "430/430 [==============================] - 0s - loss: 0.4433 - acc: 0.8977     \n",
      "Epoch 72/100\n",
      "430/430 [==============================] - 0s - loss: 0.4240 - acc: 0.9093     \n",
      "Epoch 73/100\n",
      "430/430 [==============================] - 0s - loss: 0.4157 - acc: 0.9070     \n",
      "Epoch 74/100\n",
      "430/430 [==============================] - 0s - loss: 0.4172 - acc: 0.9000     \n",
      "Epoch 75/100\n",
      "430/430 [==============================] - 0s - loss: 0.4104 - acc: 0.9093     \n",
      "Epoch 76/100\n",
      "430/430 [==============================] - 0s - loss: 0.4016 - acc: 0.9070     \n",
      "Epoch 77/100\n",
      "430/430 [==============================] - 0s - loss: 0.4037 - acc: 0.9116     \n",
      "Epoch 78/100\n",
      "430/430 [==============================] - 0s - loss: 0.4021 - acc: 0.9209     \n",
      "Epoch 79/100\n",
      "430/430 [==============================] - 0s - loss: 0.3977 - acc: 0.9186     \n",
      "Epoch 80/100\n",
      "430/430 [==============================] - 0s - loss: 0.3956 - acc: 0.9070     \n",
      "Epoch 81/100\n",
      "430/430 [==============================] - 0s - loss: 0.3817 - acc: 0.9302     \n",
      "Epoch 82/100\n",
      "430/430 [==============================] - 0s - loss: 0.3817 - acc: 0.9233     \n",
      "Epoch 83/100\n",
      "430/430 [==============================] - 0s - loss: 0.3724 - acc: 0.9233     \n",
      "Epoch 84/100\n",
      "430/430 [==============================] - 0s - loss: 0.3747 - acc: 0.9302     \n",
      "Epoch 85/100\n",
      "430/430 [==============================] - 0s - loss: 0.3657 - acc: 0.9233     \n",
      "Epoch 86/100\n",
      "430/430 [==============================] - 0s - loss: 0.3730 - acc: 0.9233     \n",
      "Epoch 87/100\n",
      "430/430 [==============================] - 0s - loss: 0.3738 - acc: 0.9233     \n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 0s - loss: 0.3520 - acc: 0.9302     \n",
      "Epoch 89/100\n",
      "430/430 [==============================] - 0s - loss: 0.3604 - acc: 0.9326     \n",
      "Epoch 90/100\n",
      "430/430 [==============================] - 0s - loss: 0.3548 - acc: 0.9326     \n",
      "Epoch 91/100\n",
      "430/430 [==============================] - 0s - loss: 0.3429 - acc: 0.9279     \n",
      "Epoch 92/100\n",
      "430/430 [==============================] - 0s - loss: 0.3496 - acc: 0.9279     \n",
      "Epoch 93/100\n",
      "430/430 [==============================] - 0s - loss: 0.3416 - acc: 0.9326     \n",
      "Epoch 94/100\n",
      "430/430 [==============================] - 0s - loss: 0.3441 - acc: 0.9233     \n",
      "Epoch 95/100\n",
      "430/430 [==============================] - 0s - loss: 0.3421 - acc: 0.9302     \n",
      "Epoch 96/100\n",
      "430/430 [==============================] - 0s - loss: 0.3324 - acc: 0.9279     \n",
      "Epoch 97/100\n",
      "430/430 [==============================] - 0s - loss: 0.3263 - acc: 0.9395     \n",
      "Epoch 98/100\n",
      "430/430 [==============================] - 0s - loss: 0.3183 - acc: 0.9488     \n",
      "Epoch 99/100\n",
      "430/430 [==============================] - 0s - loss: 0.3160 - acc: 0.9488     \n",
      "Epoch 100/100\n",
      "430/430 [==============================] - 0s - loss: 0.3203 - acc: 0.9349     - ETA: 0s - loss: 0.3175 - acc: 0.935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1169f58d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_model.fit(features_scaled, to_categorical(clusters.values - 1), epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = latent_mean\n",
    "# R[:, 1:] = 0\n",
    "pred_clusters = K.function([clustering_model.layers[0].input, K.learning_phase()],\n",
    "                           [clustering_model.layers[2].output])([features_scaled, 0])[0]\n",
    "R = np.maximum(pred_clusters, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate back through clustering model dense layer\n",
    "last_layer_W = clustering_model.layers[2].get_weights()[0]\n",
    "last_layer_W_sq = np.square(np.expand_dims(last_layer_W, 0))\n",
    "\n",
    "last_layer_N = last_layer_W_sq / np.expand_dims(np.sum(last_layer_W_sq, 1), 1)\n",
    "R = np.sum((last_layer_N * np.expand_dims(R, 1)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate back through z_mean layer\n",
    "# z_mean_input = K.function([vae.encoder_model.layers[0].input, K.learning_phase()],\n",
    "#                           [vae.encoder_model.layers[4].output])([features_scaled, 0])\n",
    "z_mean_W = vae.encoder_model.layers[5].get_weights()[0]\n",
    "z_mean_W_sq = np.square(np.expand_dims(z_mean_W, 0))\n",
    "\n",
    "z_mean_N = z_mean_W_sq / np.expand_dims(np.sum(z_mean_W_sq, 1), 1)\n",
    "R = np.sum((z_mean_N * np.expand_dims(R, 1)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate back through 2nd encoder layer\n",
    "# layer_2_input = K.function([vae.encoder_model.layers[0].input, K.learning_phase()],\n",
    "#                            [vae.encoder_model.layers[2].output])([features_scaled, 0])\n",
    "layer_2_W = vae.encoder_model.layers[3].get_weights()[0]\n",
    "layer_2_W_sq = np.square(np.expand_dims(layer_2_W, 0))\n",
    "\n",
    "layer_2_N = layer_2_W_sq / np.expand_dims(np.sum(layer_2_W_sq, 1), 1)\n",
    "R = np.sum((layer_2_N * np.expand_dims(R, 1)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate back through 1st encoder layer\n",
    "# layer_1_input = features_scaled\n",
    "layer_1_W = vae.encoder_model.layers[1].get_weights()[0]\n",
    "layer_1_W_sq = np.square(np.expand_dims(layer_1_W, 0))\n",
    "\n",
    "layer_1_N = layer_1_W_sq / np.expand_dims(np.sum(layer_1_W_sq, 1), 1)\n",
    "R = np.sum((layer_1_N * np.expand_dims(R, 1)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = features_scaled * R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AGT', 'METTL7B', 'EFEMP1', 'POSTN', 'SCG2', 'TNC', 'SERPINA3',\n",
       "       'EGFR', 'LANCL2', 'SLC2A3', 'ALDOC', 'BCAN', 'KLHL4', 'PLS3',\n",
       "       'DUSP6', 'PSAT1', 'BCAT1', 'MEG3', 'BTG2', 'TXNIP', 'KLF10',\n",
       "       'MAP1A', 'BHLHE40', 'WARS', 'TPP1', 'CXCR7', 'NEDD9', 'TFRC',\n",
       "       'SGK1', 'KPNA2', 'MCM7', 'ID2', 'GLB1', 'QARS', 'VCAN', 'GSS',\n",
       "       'PRMT5', 'CTSA', 'MIR198', 'EZR', 'PLTP', 'C5orf62', 'AHCYL1',\n",
       "       'CPVL', 'TSPAN6', 'LHFPL3', 'RFX4', 'EDNRB', 'ELOVL2', 'NCALD',\n",
       "       'TSR1', 'TMEM43', 'TCTN3', 'FKBP5', 'IVNS1ABP', 'UBR7', 'PLOD1',\n",
       "       'HERPUD1', 'ANXA7', 'PRCP', 'CLDN12', 'TCP1', 'SAT1', 'HMG20A',\n",
       "       'PRNP', 'AARS', 'MEIS1', 'JAM3', 'SAE1', 'TSC22D1', 'CARS',\n",
       "       'ALDH9A1', 'C19orf48', 'SEC61A1', 'HIF1A', 'ARID5B', 'ZNF146',\n",
       "       'CTSL1', 'ARCN1', 'FAM126A', 'PLEKHB1', 'AASDHPPT', 'ACO2', 'HEXA',\n",
       "       'PFN2', 'PMP2', 'TSC22D3', 'PCIF1', 'TRIM22', 'APEH', 'STOML2',\n",
       "       'GDAP1', 'RSU1', 'DNAJB1', 'DDAH1', 'IL1RAP', 'ALDH6A1', 'ALDH1L1',\n",
       "       'SEC23B', 'BUB3', 'SLC39A9', 'SORBS1', 'EIF3D', 'NCSTN', 'SPARCL1',\n",
       "       'CDCA7L', 'CD82', 'ATP13A4', 'SLC39A6', 'FLOT2', 'NXF1', 'EIF2B4',\n",
       "       'HNRNPF', 'TPD52L2', 'RPA2', 'RASSF2', 'PAPSS1', 'ARMCX3', 'DHX9',\n",
       "       'PJA1', 'ARRDC3', 'EPHA4', 'GRIA3', 'ACPL2', 'PRPF8', 'VAMP3',\n",
       "       'LRP4', 'STX12', 'CHL1', 'FIBIN', 'TKT', 'BSDC1', 'SGPL1', 'CRKL',\n",
       "       'NLGN3', 'TMED5', 'CASP3', 'PDHB', 'TCTA', 'PHKB', 'COPS7A', 'PGD',\n",
       "       'NUDT21', 'CKAP5', 'WDR6', 'CYB5R1', 'MAPRE2', 'MMP16', 'SEC61G',\n",
       "       'SLC40A1', 'NRAS', 'PSMD1', 'KIAA1033', 'VPS16', 'ZNF410', 'IQGAP1',\n",
       "       'ALDH7A1', 'FAM54B', 'GPN1', 'PPP1R9A', 'TNPO3', 'IFITM3', 'GOSR2',\n",
       "       'TFIP11', 'MLLT11', 'ALAS1', 'NDP', 'CYFIP2', 'UROD', 'BECN1',\n",
       "       'SEC23A', 'VTA1', 'IGFBP5', 'TCEB3', 'APOD', 'PDE4B', 'NDUFS1',\n",
       "       'C16orf62', 'YIPF3', 'PLEKHB2', 'CDK20', 'ZEB1', 'FAM82A2', 'COPS3',\n",
       "       'METTL3', 'SRR', 'TSPAN7', 'LHFP', 'DIABLO', 'TMEM222', 'B4GALT3',\n",
       "       'UBA3', 'FBXL5', 'TPD52', 'MRPL3', 'VPS8', 'PLIN3', 'ZC3H14',\n",
       "       'IDH3G', 'AMD1', 'NRSN2', 'ACLY', 'NOLC1', 'TRIB2', 'IFT52', 'SCG5',\n",
       "       'EPM2AIP1', 'ABCE1', 'CLCN3', 'CNR1', 'FXYD6', 'ZDHHC4', 'RDX',\n",
       "       'TET2', 'KBTBD2', 'CIAPIN1', 'MCRS1', 'DPH2', 'RNH1', 'CRYZ',\n",
       "       'TOMM34', 'CAV1', 'RAE1', 'EFNA1', 'LEPROTL1', 'PDRG1', 'PNMA2',\n",
       "       'LITAF', 'DNTTIP2', 'KLHL7', 'VPS41', 'PEG10', 'OAZ2', 'MRPS18A',\n",
       "       'CNDP2', 'HBP1', 'ZNF776', 'AGPAT5', 'KDM3A', 'C16orf80', 'RRN3',\n",
       "       'RBM23', 'YIPF6', 'HSPA4', 'PDHA1', 'PTGFRN', 'RNF20', 'KARS',\n",
       "       'RAB5A', 'SMARCA1', 'FTSJ3', 'MYH10', 'CUL4B', 'HNRNPH3', 'C5orf43',\n",
       "       'UBE2L6', 'SNX13', 'ABCF3', 'OXA1L', 'SLC35A1', 'MAPRE1', 'HIBCH',\n",
       "       'BAG5', 'DBNDD2', 'ATF4', 'SMC1A', 'AP2B1', 'HDHD2', 'ANK2', 'CRBN',\n",
       "       'FDFT1', 'TMEM9B', 'CHMP5', 'DRG1', 'AGK', 'SART3', 'C17orf81',\n",
       "       'PIAS1', 'COG5', 'VPS11', 'SLC11A2', 'NBR1', 'SDF2', 'ASAH1',\n",
       "       'TMX3', 'CLASP2', 'TUBB2B', 'ZNF548', 'CYFIP1', 'IBTK', 'GNPAT',\n",
       "       'LIN7C', 'MLH1', 'UFL1', 'BCS1L', 'ETV1', 'EXOSC10', 'ACAD11',\n",
       "       'TSPYL4', 'MPV17', 'GART', 'SFXN3', 'ARMC1', 'TBCK', 'SLC25A4',\n",
       "       'MIR100HG', 'RNF180', 'PCMTD2', 'ZNF644', 'ABLIM1', 'PAPD4',\n",
       "       'ZNF577', 'RHOJ', 'TEX264', 'MTHFD2', 'NDUFA10', 'BZW2', 'FAM136A',\n",
       "       'DCP2', 'TCF12', 'VPS45', 'ACAA2', 'PHLDA1', 'SLC30A9', 'RPS4Y1',\n",
       "       'ERP44', 'BBS4', 'ATP6V0D1', 'DGKG', 'GMPR2', 'AMZ2', 'NDRG2',\n",
       "       'WDR12', 'RCHY1', 'GRIA4', 'SACS', 'MANBAL', 'PSMD13', 'ZNF24',\n",
       "       'TMX2', 'CHD1L', 'LBR', 'EXOC7', 'CTR9', '7-Mar', 'CNIH', 'PSMF1',\n",
       "       'SCG3', 'CNOT2', 'PPP6C', 'ZIM2', 'DSCAM', 'NARF', 'HMGN4',\n",
       "       'MRPS14', 'KIAA0141', 'C14orf159', 'LYSMD3', 'MT1X', 'SCOC',\n",
       "       'ACAT1', 'ATP6V1A', 'ARL2BP', 'PDZD11', 'DPYSL3', 'SLC4A4',\n",
       "       'R3HCC1', 'PIK3R3', 'UBE2H', 'SCAMP2', 'MAPK6', 'PIGT', 'KIDINS220',\n",
       "       'CPEB4', 'TMED9', 'FAM69A', 'ZNF462', 'GYG1', 'SF3A3', 'KIAA1191',\n",
       "       'RFTN2', 'CDK6', 'FKBP15', 'NLGN4X', 'NAE1', 'FLAD1', 'RUVBL1',\n",
       "       'IMMT', 'SLC25A17', 'CCDC93', 'PLK1S1', 'GRIA2', 'AAMP', 'LTN1',\n",
       "       'LTA4H', 'SIKE1', 'PUF60', 'SYS1', 'NUMB', 'TSG101', 'NAA25',\n",
       "       'PFKM', 'DDX47', 'ANKMY2', 'KLHL28', 'CCAR1', 'MCL1', 'BLM',\n",
       "       'PCMT1', 'SPOP', 'ALDH18A1', 'ASH1L', 'YPEL5', 'CADM2', 'ACTR10',\n",
       "       'TIMM22', 'APBB2', 'NECAP2', 'DNAJB11', 'PWP1', 'PGAM1', 'HBS1L',\n",
       "       'ZMYM2', 'ETFA', 'UBXN7', 'CDC123', 'PRPF4', 'NSMCE1', 'ZFHX4',\n",
       "       'DCAF5', 'FAM18B1', 'MTMR4', 'ZNF292', 'BCKDHA', 'SGTA', 'FCGRT',\n",
       "       'ZNF419', 'ARFGAP3', 'TULP3', 'SORT1', 'RNF141', 'PARP14', 'SPTSSA',\n",
       "       'RLF', 'STIP1', 'NRN1', 'ABCD3', 'CKAP2', 'CMTM6', 'AZIN1', 'NDRG4',\n",
       "       'PRPF3', 'RNF103', 'DPF2', 'IARS', 'DMTF1', 'C12orf10', 'RRAGB',\n",
       "       'ING4', 'SLC35B1', 'ITFG1', 'GRHPR', 'CALCOCO1', 'BCHE', 'SNX11',\n",
       "       'PPIL1', 'FAM192A', 'CTSD', 'IDS', 'HMGCL', 'TFG', 'DECR1', 'NR3C1',\n",
       "       'RRM2B', 'SCAMP3', 'SPG20', 'POLR1C', 'EIF2A', 'DHX15', 'SRP54',\n",
       "       'PI4KB', 'NRXN1', 'PAF1', 'PLD3', 'UMPS', 'TP53BP1', 'FEM1C',\n",
       "       'WDR54', 'SNRNP200', 'MYL12A', 'COPB2', 'MBTPS2'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns[1:].values[result[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.027032083010134298"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
