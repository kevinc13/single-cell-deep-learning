+ pylon5=/pylon5/ms4s84p/kchen8
+ project_name=single-cell-deep-learning
+ cd /pylon5/ms4s84p/kchen8/single-cell-deep-learning
+ module load tensorflow/1.1.0_nogpu
++ /usr/bin/modulecmd bash load tensorflow/1.1.0_nogpu
+ eval GCC_DIR=/opt/packages/gcc/5.3.0 ';export' 'GCC_DIR;GCC_VERSION=5.3.0' ';export' 'GCC_VERSION;LD_LIBRARY_PATH=/opt/packages/python/2_7_11_gcc_np1_11_v3/lib:/opt/packages/gcc/5.3.0/lib64:/opt/packages/gcc/5.3.0/lib:/opt/intel/itac/2017.3.030/mic/slib:/opt/intel/itac/2017.3.030/intel64/slib:/opt/intel//itac/2017.3.030/mic/slib:/opt/intel//itac/2017.3.030/intel64/slib:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/mic/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.7:/opt/intel/debugger_2017/iga/lib:/opt/intel/debugger_2017/libipt/intel64/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/../tbb/lib/intel64_lin/gcc4.4' ';export' 'LD_LIBRARY_PATH;LOADEDMODULES=psc_path/1.1:slurm/17.02.5:intel/17.4:gcc/5.3.0:python2/2.7.11_gcc_np1.11:tensorflow/1.1.0_nogpu' ';export' 'LOADEDMODULES;MANPATH=/opt/packages/gcc/5.3.0/share/man:/opt/intel//itac/2017.3.030/man:/opt/intel/man/common:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/man:/opt/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/packages/slurm/17.02.5/share/man:/usr/local/man:/usr/share/man:/opt/packages/slash2/psc/man:' ';export' 'MANPATH;MKL_THREADING_LAYER=GNU' ';export' 'MKL_THREADING_LAYER;PATH=/opt/packages/python/2_7_11_gcc_np1_11_v3/bin:/opt/packages/gcc/5.3.0/bin:/usr/lib64/qt-3.3/bin:/opt/intel/advisor_2017.1.3.510716/bin64:/opt/intel/vtune_amplifier_xe_2017.3.0.510739/bin64:/opt/intel/inspector_2017.1.3.510645/bin64:/opt/intel/itac/2017.3.030/intel64/bin:/opt/intel//itac/2017.3.030/intel64/bin:/opt/intel//clck/2017.2.019/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin:/opt/intel/debugger_2017/gdb/intel64_mic/bin:/opt/packages/slurm/17.02.5/bin:/opt/packages/allocations:/opt/packages/interact/bin:/usr/lib64/ccache:/usr/local/bin:/bin:/usr/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/puppet/bin:/opt/packages/slash2/psc/sbin:/opt/intel/parallel_studio_xe_2017.4.056/bin:/opt/puppetlabs/bin:/home/kchen8/.local/bin:/home/kchen8/bin' ';export' 'PATH;PYTHON_ROOT=/opt/packages/python/2_7_11_gcc_np1_11_v3' ';export' 'PYTHON_ROOT;TENSORFLOW_ENV=/opt/packages/TensorFlow/TensorFlow_1.1.0/TensorFlowNoGPUEnv' ';export' 'TENSORFLOW_ENV;_LMFILES_=/opt/modulefiles/psc_path/1.1:/opt/modulefiles/slurm/17.02.5:/opt/modulefiles/intel/17.4:/opt/modulefiles/gcc/5.3.0:/opt/modulefiles/python2/2.7.11_gcc_np1.11:/opt/modulefiles/tensorflow/1.1.0_nogpu' ';export' '_LMFILES_;'
++ GCC_DIR=/opt/packages/gcc/5.3.0
++ export GCC_DIR
++ GCC_VERSION=5.3.0
++ export GCC_VERSION
++ LD_LIBRARY_PATH=/opt/packages/python/2_7_11_gcc_np1_11_v3/lib:/opt/packages/gcc/5.3.0/lib64:/opt/packages/gcc/5.3.0/lib:/opt/intel/itac/2017.3.030/mic/slib:/opt/intel/itac/2017.3.030/intel64/slib:/opt/intel//itac/2017.3.030/mic/slib:/opt/intel//itac/2017.3.030/intel64/slib:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/mic/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.7:/opt/intel/debugger_2017/iga/lib:/opt/intel/debugger_2017/libipt/intel64/lib:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin:/opt/intel/compilers_and_libraries_2017.4.196/linux/daal/../tbb/lib/intel64_lin/gcc4.4
++ export LD_LIBRARY_PATH
++ LOADEDMODULES=psc_path/1.1:slurm/17.02.5:intel/17.4:gcc/5.3.0:python2/2.7.11_gcc_np1.11:tensorflow/1.1.0_nogpu
++ export LOADEDMODULES
++ MANPATH=/opt/packages/gcc/5.3.0/share/man:/opt/intel//itac/2017.3.030/man:/opt/intel/man/common:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/man:/opt/intel/documentation_2017/en/debugger//gdb-ia/man/:/opt/intel/documentation_2017/en/debugger//gdb-mic/man/:/opt/intel/documentation_2017/en/debugger//gdb-igfx/man/:/opt/packages/slurm/17.02.5/share/man:/usr/local/man:/usr/share/man:/opt/packages/slash2/psc/man:
++ export MANPATH
++ MKL_THREADING_LAYER=GNU
++ export MKL_THREADING_LAYER
++ PATH=/opt/packages/python/2_7_11_gcc_np1_11_v3/bin:/opt/packages/gcc/5.3.0/bin:/usr/lib64/qt-3.3/bin:/opt/intel/advisor_2017.1.3.510716/bin64:/opt/intel/vtune_amplifier_xe_2017.3.0.510739/bin64:/opt/intel/inspector_2017.1.3.510645/bin64:/opt/intel/itac/2017.3.030/intel64/bin:/opt/intel//itac/2017.3.030/intel64/bin:/opt/intel//clck/2017.2.019/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin:/opt/intel/debugger_2017/gdb/intel64_mic/bin:/opt/packages/slurm/17.02.5/bin:/opt/packages/allocations:/opt/packages/interact/bin:/usr/lib64/ccache:/usr/local/bin:/bin:/usr/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/puppet/bin:/opt/packages/slash2/psc/sbin:/opt/intel/parallel_studio_xe_2017.4.056/bin:/opt/puppetlabs/bin:/home/kchen8/.local/bin:/home/kchen8/bin
++ export PATH
++ PYTHON_ROOT=/opt/packages/python/2_7_11_gcc_np1_11_v3
++ export PYTHON_ROOT
++ TENSORFLOW_ENV=/opt/packages/TensorFlow/TensorFlow_1.1.0/TensorFlowNoGPUEnv
++ export TENSORFLOW_ENV
++ _LMFILES_=/opt/modulefiles/psc_path/1.1:/opt/modulefiles/slurm/17.02.5:/opt/modulefiles/intel/17.4:/opt/modulefiles/gcc/5.3.0:/opt/modulefiles/python2/2.7.11_gcc_np1.11:/opt/modulefiles/tensorflow/1.1.0_nogpu
++ export _LMFILES_
+ module load keras/2.0.4
++ /usr/bin/modulecmd bash load keras/2.0.4
+ eval KERAS_ENV=/opt/packages/keras/keras_2.0.4/kerasEnv ';export' 'KERAS_ENV;LOADEDMODULES=psc_path/1.1:slurm/17.02.5:intel/17.4:gcc/5.3.0:python2/2.7.11_gcc_np1.11:tensorflow/1.1.0_nogpu:keras/2.0.4' ';export' 'LOADEDMODULES;_LMFILES_=/opt/modulefiles/psc_path/1.1:/opt/modulefiles/slurm/17.02.5:/opt/modulefiles/intel/17.4:/opt/modulefiles/gcc/5.3.0:/opt/modulefiles/python2/2.7.11_gcc_np1.11:/opt/modulefiles/tensorflow/1.1.0_nogpu:/opt/modulefiles/keras/2.0.4' ';export' '_LMFILES_;'
++ KERAS_ENV=/opt/packages/keras/keras_2.0.4/kerasEnv
++ export KERAS_ENV
++ LOADEDMODULES=psc_path/1.1:slurm/17.02.5:intel/17.4:gcc/5.3.0:python2/2.7.11_gcc_np1.11:tensorflow/1.1.0_nogpu:keras/2.0.4
++ export LOADEDMODULES
++ _LMFILES_=/opt/modulefiles/psc_path/1.1:/opt/modulefiles/slurm/17.02.5:/opt/modulefiles/intel/17.4:/opt/modulefiles/gcc/5.3.0:/opt/modulefiles/python2/2.7.11_gcc_np1.11:/opt/modulefiles/tensorflow/1.1.0_nogpu:/opt/modulefiles/keras/2.0.4
++ export _LMFILES_
+ source /opt/packages/keras/keras_2.0.4/kerasEnv/bin/activate
++ deactivate nondestructive
++ unset -f pydoc
++ '[' -z '' ']'
++ '[' -z '' ']'
++ '[' -n /bin/bash ']'
++ hash -r
++ '[' -z '' ']'
++ unset VIRTUAL_ENV
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/opt/packages/keras/keras_2.0.4/kerasEnv
++ export VIRTUAL_ENV
++ _OLD_VIRTUAL_PATH=/opt/packages/python/2_7_11_gcc_np1_11_v3/bin:/opt/packages/gcc/5.3.0/bin:/usr/lib64/qt-3.3/bin:/opt/intel/advisor_2017.1.3.510716/bin64:/opt/intel/vtune_amplifier_xe_2017.3.0.510739/bin64:/opt/intel/inspector_2017.1.3.510645/bin64:/opt/intel/itac/2017.3.030/intel64/bin:/opt/intel//itac/2017.3.030/intel64/bin:/opt/intel//clck/2017.2.019/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin:/opt/intel/debugger_2017/gdb/intel64_mic/bin:/opt/packages/slurm/17.02.5/bin:/opt/packages/allocations:/opt/packages/interact/bin:/usr/lib64/ccache:/usr/local/bin:/bin:/usr/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/puppet/bin:/opt/packages/slash2/psc/sbin:/opt/intel/parallel_studio_xe_2017.4.056/bin:/opt/puppetlabs/bin:/home/kchen8/.local/bin:/home/kchen8/bin
++ PATH=/opt/packages/keras/keras_2.0.4/kerasEnv/bin:/opt/packages/python/2_7_11_gcc_np1_11_v3/bin:/opt/packages/gcc/5.3.0/bin:/usr/lib64/qt-3.3/bin:/opt/intel/advisor_2017.1.3.510716/bin64:/opt/intel/vtune_amplifier_xe_2017.3.0.510739/bin64:/opt/intel/inspector_2017.1.3.510645/bin64:/opt/intel/itac/2017.3.030/intel64/bin:/opt/intel//itac/2017.3.030/intel64/bin:/opt/intel//clck/2017.2.019/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/bin/intel64:/opt/intel/compilers_and_libraries_2017.4.196/linux/mpi/intel64/bin:/opt/intel/debugger_2017/gdb/intel64_mic/bin:/opt/packages/slurm/17.02.5/bin:/opt/packages/allocations:/opt/packages/interact/bin:/usr/lib64/ccache:/usr/local/bin:/bin:/usr/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/puppet/bin:/opt/packages/slash2/psc/sbin:/opt/intel/parallel_studio_xe_2017.4.056/bin:/opt/puppetlabs/bin:/home/kchen8/.local/bin:/home/kchen8/bin
++ export PATH
++ '[' -z '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ '[' x '!=' x ']'
+++ basename /opt/packages/keras/keras_2.0.4/kerasEnv
++ PS1='(kerasEnv) '
++ export PS1
++ alias pydoc
++ '[' -n /bin/bash ']'
++ hash -r
+ python main.py --e usokin.train_usokin-500g-scaled-2L-adam-ae
Using TensorFlow backend.
Train on 553 samples, validate on 69 samples
Epoch 1/100
1s - loss: 0.5919 - val_loss: 0.5331
Epoch 2/100
0s - loss: 0.5194 - val_loss: 0.4981
Epoch 3/100
0s - loss: 0.4930 - val_loss: 0.4808
Epoch 4/100
0s - loss: 0.4796 - val_loss: 0.4752
Epoch 5/100
0s - loss: 0.4726 - val_loss: 0.4717
Epoch 6/100
0s - loss: 0.4678 - val_loss: 0.4687
Epoch 7/100
0s - loss: 0.4642 - val_loss: 0.4660
Epoch 8/100
0s - loss: 0.4607 - val_loss: 0.4645
Epoch 9/100
0s - loss: 0.4584 - val_loss: 0.4629
Epoch 10/100
0s - loss: 0.4564 - val_loss: 0.4618
Epoch 11/100
0s - loss: 0.4541 - val_loss: 0.4603
Epoch 12/100
0s - loss: 0.4516 - val_loss: 0.4598
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:47:06,141 - 0_UsokinAE_350-300_150_elu|Fold #1 Loss = 0.459813
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5924 - val_loss: 0.5298
Epoch 2/100
0s - loss: 0.5172 - val_loss: 0.4946
Epoch 3/100
0s - loss: 0.4896 - val_loss: 0.4781
Epoch 4/100
0s - loss: 0.4773 - val_loss: 0.4715
Epoch 5/100
0s - loss: 0.4711 - val_loss: 0.4677
Epoch 6/100
0s - loss: 0.4663 - val_loss: 0.4640
Epoch 7/100
0s - loss: 0.4620 - val_loss: 0.4611
Epoch 8/100
0s - loss: 0.4582 - val_loss: 0.4592
Epoch 9/100
0s - loss: 0.4552 - val_loss: 0.4576
Epoch 10/100
0s - loss: 0.4524 - val_loss: 0.4559
Epoch 11/100
0s - loss: 0.4495 - val_loss: 0.4550
Epoch 12/100
0s - loss: 0.4468 - val_loss: 0.4535
Epoch 13/100
0s - loss: 0.4438 - val_loss: 0.4521
Epoch 14/100
0s - loss: 0.4408 - val_loss: 0.4516
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4499
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:47:15,454 - 0_UsokinAE_350-300_150_elu|Fold #2 Loss = 0.449906
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5881 - val_loss: 0.5380
Epoch 2/100
0s - loss: 0.5167 - val_loss: 0.5063
Epoch 3/100
0s - loss: 0.4895 - val_loss: 0.4899
Epoch 4/100
0s - loss: 0.4766 - val_loss: 0.4849
Epoch 5/100
0s - loss: 0.4708 - val_loss: 0.4799
Epoch 6/100
0s - loss: 0.4653 - val_loss: 0.4762
Epoch 7/100
0s - loss: 0.4606 - val_loss: 0.4734
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4718
Epoch 9/100
0s - loss: 0.4542 - val_loss: 0.4695
Epoch 10/100
0s - loss: 0.4515 - val_loss: 0.4684
Epoch 11/100
0s - loss: 0.4488 - val_loss: 0.4670
Epoch 12/100
0s - loss: 0.4461 - val_loss: 0.4668
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:47:23,221 - 0_UsokinAE_350-300_150_elu|Fold #3 Loss = 0.466794
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5871 - val_loss: 0.5292
Epoch 2/100
0s - loss: 0.5181 - val_loss: 0.4995
Epoch 3/100
0s - loss: 0.4916 - val_loss: 0.4813
Epoch 4/100
0s - loss: 0.4773 - val_loss: 0.4727
Epoch 5/100
0s - loss: 0.4700 - val_loss: 0.4684
Epoch 6/100
0s - loss: 0.4651 - val_loss: 0.4655
Epoch 7/100
0s - loss: 0.4610 - val_loss: 0.4641
Epoch 8/100
0s - loss: 0.4580 - val_loss: 0.4610
Epoch 9/100
0s - loss: 0.4550 - val_loss: 0.4590
Epoch 10/100
0s - loss: 0.4524 - val_loss: 0.4573
Epoch 11/100
0s - loss: 0.4498 - val_loss: 0.4561
Epoch 12/100
0s - loss: 0.4470 - val_loss: 0.4552
Epoch 13/100
0s - loss: 0.4447 - val_loss: 0.4536
Epoch 14/100
0s - loss: 0.4423 - val_loss: 0.4526
Epoch 15/100
0s - loss: 0.4393 - val_loss: 0.4518
Epoch 16/100
0s - loss: 0.4369 - val_loss: 0.4500
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:47:33,016 - 0_UsokinAE_350-300_150_elu|Fold #4 Loss = 0.449959
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5922 - val_loss: 0.5326
Epoch 2/100
0s - loss: 0.5154 - val_loss: 0.5014
Epoch 3/100
0s - loss: 0.4888 - val_loss: 0.4849
Epoch 4/100
0s - loss: 0.4776 - val_loss: 0.4802
Epoch 5/100
0s - loss: 0.4722 - val_loss: 0.4753
Epoch 6/100
0s - loss: 0.4669 - val_loss: 0.4714
Epoch 7/100
0s - loss: 0.4625 - val_loss: 0.4686
Epoch 8/100
0s - loss: 0.4586 - val_loss: 0.4661
Epoch 9/100
0s - loss: 0.4555 - val_loss: 0.4644
Epoch 10/100
0s - loss: 0.4529 - val_loss: 0.4626
Epoch 11/100
0s - loss: 0.4501 - val_loss: 0.4608
Epoch 12/100
0s - loss: 0.4471 - val_loss: 0.4598
Epoch 13/100
0s - loss: 0.4442 - val_loss: 0.4586
Epoch 14/100
0s - loss: 0.4415 - val_loss: 0.4573
Epoch 15/100
0s - loss: 0.4386 - val_loss: 0.4567
Epoch 16/100
0s - loss: 0.4358 - val_loss: 0.4562
Epoch 17/100
0s - loss: 0.4329 - val_loss: 0.4561
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:47:43,425 - 0_UsokinAE_350-300_150_elu|Fold #5 Loss = 0.456066
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5865 - val_loss: 0.5301
Epoch 2/100
0s - loss: 0.5170 - val_loss: 0.4918
Epoch 3/100
0s - loss: 0.4901 - val_loss: 0.4773
Epoch 4/100
0s - loss: 0.4797 - val_loss: 0.4699
Epoch 5/100
0s - loss: 0.4732 - val_loss: 0.4654
Epoch 6/100
0s - loss: 0.4688 - val_loss: 0.4626
Epoch 7/100
0s - loss: 0.4644 - val_loss: 0.4583
Epoch 8/100
0s - loss: 0.4608 - val_loss: 0.4564
Epoch 9/100
0s - loss: 0.4573 - val_loss: 0.4545
Epoch 10/100
0s - loss: 0.4543 - val_loss: 0.4526
Epoch 11/100
0s - loss: 0.4516 - val_loss: 0.4515
Epoch 12/100
0s - loss: 0.4490 - val_loss: 0.4504
Epoch 13/100
0s - loss: 0.4465 - val_loss: 0.4493
Epoch 14/100
0s - loss: 0.4441 - val_loss: 0.4498
Epoch 15/100
0s - loss: 0.4421 - val_loss: 0.4483
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:47:52,784 - 0_UsokinAE_350-300_150_elu|Fold #6 Loss = 0.448305
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5872 - val_loss: 0.5411
Epoch 2/100
0s - loss: 0.5143 - val_loss: 0.5118
Epoch 3/100
0s - loss: 0.4863 - val_loss: 0.4963
Epoch 4/100
0s - loss: 0.4740 - val_loss: 0.4900
Epoch 5/100
0s - loss: 0.4678 - val_loss: 0.4852
Epoch 6/100
0s - loss: 0.4633 - val_loss: 0.4819
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4794
Epoch 8/100
0s - loss: 0.4559 - val_loss: 0.4786
Epoch 9/100
0s - loss: 0.4533 - val_loss: 0.4768
Epoch 10/100
0s - loss: 0.4502 - val_loss: 0.4749
Epoch 11/100
0s - loss: 0.4476 - val_loss: 0.4746
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4724
Epoch 13/100
0s - loss: 0.4413 - val_loss: 0.4715
Epoch 14/100
0s - loss: 0.4386 - val_loss: 0.4709
Epoch 15/100
0s - loss: 0.4355 - val_loss: 0.4693
Epoch 16/100
0s - loss: 0.4325 - val_loss: 0.4686
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:02,603 - 0_UsokinAE_350-300_150_elu|Fold #7 Loss = 0.468564
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5865 - val_loss: 0.5286
Epoch 2/100
0s - loss: 0.5175 - val_loss: 0.4954
Epoch 3/100
0s - loss: 0.4896 - val_loss: 0.4775
Epoch 4/100
0s - loss: 0.4774 - val_loss: 0.4705
Epoch 5/100
0s - loss: 0.4714 - val_loss: 0.4653
Epoch 6/100
0s - loss: 0.4659 - val_loss: 0.4610
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4576
Epoch 8/100
0s - loss: 0.4573 - val_loss: 0.4557
Epoch 9/100
0s - loss: 0.4546 - val_loss: 0.4548
Epoch 10/100
0s - loss: 0.4522 - val_loss: 0.4537
Epoch 11/100
0s - loss: 0.4494 - val_loss: 0.4525
Epoch 12/100
0s - loss: 0.4467 - val_loss: 0.4512
Epoch 13/100
0s - loss: 0.4436 - val_loss: 0.4498
Epoch 14/100
0s - loss: 0.4409 - val_loss: 0.4485
Epoch 15/100
0s - loss: 0.4386 - val_loss: 0.4489
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:11,875 - 0_UsokinAE_350-300_150_elu|Fold #8 Loss = 0.448948
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5911 - val_loss: 0.5334
Epoch 2/100
0s - loss: 0.5168 - val_loss: 0.5028
Epoch 3/100
0s - loss: 0.4899 - val_loss: 0.4866
Epoch 4/100
0s - loss: 0.4769 - val_loss: 0.4800
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4762
Epoch 6/100
0s - loss: 0.4648 - val_loss: 0.4726
Epoch 7/100
0s - loss: 0.4602 - val_loss: 0.4697
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4674
Epoch 9/100
0s - loss: 0.4538 - val_loss: 0.4664
Epoch 10/100
0s - loss: 0.4514 - val_loss: 0.4652
Epoch 11/100
0s - loss: 0.4490 - val_loss: 0.4637
Epoch 12/100
0s - loss: 0.4463 - val_loss: 0.4627
Epoch 13/100
0s - loss: 0.4434 - val_loss: 0.4661
Epoch 14/100
0s - loss: 0.4419 - val_loss: 0.4606
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4594
Epoch 16/100
0s - loss: 0.4353 - val_loss: 0.4586
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:21,689 - 0_UsokinAE_350-300_150_elu|Fold #9 Loss = 0.458609
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5861 - val_loss: 0.5344
Epoch 2/100
0s - loss: 0.5175 - val_loss: 0.4988
Epoch 3/100
0s - loss: 0.4887 - val_loss: 0.4769
Epoch 4/100
0s - loss: 0.4759 - val_loss: 0.4697
Epoch 5/100
0s - loss: 0.4695 - val_loss: 0.4645
Epoch 6/100
0s - loss: 0.4646 - val_loss: 0.4614
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4588
Epoch 8/100
0s - loss: 0.4577 - val_loss: 0.4567
Epoch 9/100
0s - loss: 0.4544 - val_loss: 0.4549
Epoch 10/100
0s - loss: 0.4517 - val_loss: 0.4538
Epoch 11/100
0s - loss: 0.4491 - val_loss: 0.4523
Epoch 12/100
0s - loss: 0.4462 - val_loss: 0.4510
Epoch 13/100
0s - loss: 0.4434 - val_loss: 0.4498
Epoch 14/100
0s - loss: 0.4410 - val_loss: 0.4497
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4474
Epoch 16/100
0s - loss: 0.4352 - val_loss: 0.4473
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:31,443 - 0_UsokinAE_350-300_150_elu|Fold #10 Loss = 0.447294
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:31,444 - 0_UsokinAE_350-300_150_elu|Avg Validation Loss = 0.455426
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.6163 - val_loss: 0.5462
Epoch 2/100
0s - loss: 0.5403 - val_loss: 0.5259
Epoch 3/100
0s - loss: 0.5185 - val_loss: 0.5052
Epoch 4/100
0s - loss: 0.5004 - val_loss: 0.4920
Epoch 5/100
0s - loss: 0.4905 - val_loss: 0.4839
Epoch 6/100
0s - loss: 0.4826 - val_loss: 0.4799
Epoch 7/100
0s - loss: 0.4784 - val_loss: 0.4771
Epoch 8/100
0s - loss: 0.4754 - val_loss: 0.4754
Epoch 9/100
0s - loss: 0.4733 - val_loss: 0.4740
Epoch 10/100
0s - loss: 0.4712 - val_loss: 0.4713
Epoch 11/100
0s - loss: 0.4687 - val_loss: 0.4703
Epoch 12/100
0s - loss: 0.4662 - val_loss: 0.4691
Epoch 13/100
0s - loss: 0.4639 - val_loss: 0.4690
Epoch 14/100
0s - loss: 0.4628 - val_loss: 0.4665
Epoch 15/100
0s - loss: 0.4609 - val_loss: 0.4664
Epoch 16/100
0s - loss: 0.4600 - val_loss: 0.4654
Epoch 17/100
0s - loss: 0.4578 - val_loss: 0.4643
Epoch 18/100
0s - loss: 0.4563 - val_loss: 0.4632
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:42,264 - 1_UsokinAE_450-250_50_relu|Fold #1 Loss = 0.463190
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6137 - val_loss: 0.5459
Epoch 2/100
0s - loss: 0.5416 - val_loss: 0.5266
Epoch 3/100
0s - loss: 0.5222 - val_loss: 0.5081
Epoch 4/100
0s - loss: 0.5035 - val_loss: 0.4905
Epoch 5/100
0s - loss: 0.4895 - val_loss: 0.4799
Epoch 6/100
0s - loss: 0.4808 - val_loss: 0.4763
Epoch 7/100
0s - loss: 0.4768 - val_loss: 0.4727
Epoch 8/100
0s - loss: 0.4735 - val_loss: 0.4711
Epoch 9/100
0s - loss: 0.4713 - val_loss: 0.4693
Epoch 10/100
0s - loss: 0.4688 - val_loss: 0.4679
Epoch 11/100
0s - loss: 0.4665 - val_loss: 0.4669
Epoch 12/100
0s - loss: 0.4648 - val_loss: 0.4661
Epoch 13/100
0s - loss: 0.4630 - val_loss: 0.4635
Epoch 14/100
0s - loss: 0.4606 - val_loss: 0.4625
Epoch 15/100
0s - loss: 0.4584 - val_loss: 0.4611
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:48:51,614 - 1_UsokinAE_450-250_50_relu|Fold #2 Loss = 0.461054
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6079 - val_loss: 0.5483
Epoch 2/100
0s - loss: 0.5392 - val_loss: 0.5376
Epoch 3/100
0s - loss: 0.5245 - val_loss: 0.5229
Epoch 4/100
0s - loss: 0.5052 - val_loss: 0.5034
Epoch 5/100
0s - loss: 0.4875 - val_loss: 0.4911
Epoch 6/100
0s - loss: 0.4785 - val_loss: 0.4869
Epoch 7/100
0s - loss: 0.4738 - val_loss: 0.4849
Epoch 8/100
0s - loss: 0.4705 - val_loss: 0.4825
Epoch 9/100
0s - loss: 0.4674 - val_loss: 0.4804
Epoch 10/100
0s - loss: 0.4644 - val_loss: 0.4778
Epoch 11/100
0s - loss: 0.4617 - val_loss: 0.4765
Epoch 12/100
0s - loss: 0.4595 - val_loss: 0.4757
Epoch 13/100
0s - loss: 0.4575 - val_loss: 0.4739
Epoch 14/100
0s - loss: 0.4557 - val_loss: 0.4729
Epoch 15/100
0s - loss: 0.4540 - val_loss: 0.4720
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:49:00,812 - 1_UsokinAE_450-250_50_relu|Fold #3 Loss = 0.471996
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6152 - val_loss: 0.5455
Epoch 2/100
0s - loss: 0.5414 - val_loss: 0.5274
Epoch 3/100
0s - loss: 0.5219 - val_loss: 0.5097
Epoch 4/100
0s - loss: 0.5067 - val_loss: 0.4969
Epoch 5/100
0s - loss: 0.4904 - val_loss: 0.4821
Epoch 6/100
0s - loss: 0.4794 - val_loss: 0.4786
Epoch 7/100
0s - loss: 0.4754 - val_loss: 0.4753
Epoch 8/100
0s - loss: 0.4725 - val_loss: 0.4738
Epoch 9/100
0s - loss: 0.4701 - val_loss: 0.4723
Epoch 10/100
0s - loss: 0.4680 - val_loss: 0.4705
Epoch 11/100
0s - loss: 0.4660 - val_loss: 0.4694
Epoch 12/100
0s - loss: 0.4640 - val_loss: 0.4683
Epoch 13/100
0s - loss: 0.4626 - val_loss: 0.4683
Epoch 14/100
0s - loss: 0.4607 - val_loss: 0.4657
Epoch 15/100
0s - loss: 0.4589 - val_loss: 0.4646
Epoch 16/100
0s - loss: 0.4569 - val_loss: 0.4633
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:49:10,633 - 1_UsokinAE_450-250_50_relu|Fold #4 Loss = 0.463292
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.6185 - val_loss: 0.5487
Epoch 2/100
0s - loss: 0.5396 - val_loss: 0.5285
Epoch 3/100
0s - loss: 0.5159 - val_loss: 0.5062
Epoch 4/100
0s - loss: 0.4942 - val_loss: 0.4898
Epoch 5/100
0s - loss: 0.4809 - val_loss: 0.4836
Epoch 6/100
0s - loss: 0.4761 - val_loss: 0.4801
Epoch 7/100
0s - loss: 0.4736 - val_loss: 0.4791
Epoch 8/100
0s - loss: 0.4714 - val_loss: 0.4770
Epoch 9/100
0s - loss: 0.4686 - val_loss: 0.4748
Epoch 10/100
0s - loss: 0.4665 - val_loss: 0.4730
Epoch 11/100
0s - loss: 0.4634 - val_loss: 0.4710
Epoch 12/100
0s - loss: 0.4611 - val_loss: 0.4697
Epoch 13/100
0s - loss: 0.4591 - val_loss: 0.4690
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4672
Epoch 15/100
0s - loss: 0.4556 - val_loss: 0.4661
Epoch 16/100
0s - loss: 0.4538 - val_loss: 0.4652
Epoch 17/100
0s - loss: 0.4520 - val_loss: 0.4645
Epoch 18/100
0s - loss: 0.4507 - val_loss: 0.4641
Epoch 19/100
0s - loss: 0.4492 - val_loss: 0.4640
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:49:21,957 - 1_UsokinAE_450-250_50_relu|Fold #5 Loss = 0.463965
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.6080 - val_loss: 0.5435
Epoch 2/100
0s - loss: 0.5424 - val_loss: 0.5320
Epoch 3/100
0s - loss: 0.5306 - val_loss: 0.5185
Epoch 4/100
0s - loss: 0.5154 - val_loss: 0.4941
Epoch 5/100
0s - loss: 0.4926 - val_loss: 0.4767
Epoch 6/100
0s - loss: 0.4813 - val_loss: 0.4720
Epoch 7/100
0s - loss: 0.4773 - val_loss: 0.4701
Epoch 8/100
0s - loss: 0.4750 - val_loss: 0.4681
Epoch 9/100
0s - loss: 0.4727 - val_loss: 0.4660
Epoch 10/100
0s - loss: 0.4702 - val_loss: 0.4642
Epoch 11/100
0s - loss: 0.4678 - val_loss: 0.4628
Epoch 12/100
0s - loss: 0.4654 - val_loss: 0.4611
Epoch 13/100
0s - loss: 0.4636 - val_loss: 0.4597
Epoch 14/100
0s - loss: 0.4621 - val_loss: 0.4600
Epoch 15/100
0s - loss: 0.4608 - val_loss: 0.4579
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:49:31,179 - 1_UsokinAE_450-250_50_relu|Fold #6 Loss = 0.457947
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6140 - val_loss: 0.5568
Epoch 2/100
0s - loss: 0.5389 - val_loss: 0.5370
Epoch 3/100
0s - loss: 0.5159 - val_loss: 0.5213
Epoch 4/100
0s - loss: 0.4996 - val_loss: 0.5060
Epoch 5/100
0s - loss: 0.4838 - val_loss: 0.4976
Epoch 6/100
0s - loss: 0.4761 - val_loss: 0.4940
Epoch 7/100
0s - loss: 0.4728 - val_loss: 0.4925
Epoch 8/100
0s - loss: 0.4706 - val_loss: 0.4898
Epoch 9/100
0s - loss: 0.4681 - val_loss: 0.4877
Epoch 10/100
0s - loss: 0.4655 - val_loss: 0.4846
Epoch 11/100
0s - loss: 0.4629 - val_loss: 0.4833
Epoch 12/100
0s - loss: 0.4607 - val_loss: 0.4816
Epoch 13/100
0s - loss: 0.4588 - val_loss: 0.4811
Epoch 14/100
0s - loss: 0.4571 - val_loss: 0.4797
Epoch 15/100
0s - loss: 0.4552 - val_loss: 0.4784
Epoch 16/100
0s - loss: 0.4536 - val_loss: 0.4783
Epoch 17/100
0s - loss: 0.4523 - val_loss: 0.4777
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:49:41,525 - 1_UsokinAE_450-250_50_relu|Fold #7 Loss = 0.477701
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6145 - val_loss: 0.5503
Epoch 2/100
0s - loss: 0.5418 - val_loss: 0.5324
Epoch 3/100
0s - loss: 0.5235 - val_loss: 0.5079
Epoch 4/100
0s - loss: 0.5039 - val_loss: 0.4922
Epoch 5/100
0s - loss: 0.4892 - val_loss: 0.4802
Epoch 6/100
0s - loss: 0.4810 - val_loss: 0.4757
Epoch 7/100
0s - loss: 0.4770 - val_loss: 0.4730
Epoch 8/100
0s - loss: 0.4746 - val_loss: 0.4710
Epoch 9/100
0s - loss: 0.4723 - val_loss: 0.4690
Epoch 10/100
0s - loss: 0.4701 - val_loss: 0.4667
Epoch 11/100
0s - loss: 0.4676 - val_loss: 0.4651
Epoch 12/100
0s - loss: 0.4655 - val_loss: 0.4630
Epoch 13/100
0s - loss: 0.4629 - val_loss: 0.4611
Epoch 14/100
0s - loss: 0.4608 - val_loss: 0.4598
Epoch 15/100
0s - loss: 0.4589 - val_loss: 0.4593
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:49:50,839 - 1_UsokinAE_450-250_50_relu|Fold #8 Loss = 0.459257
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6051 - val_loss: 0.5490
Epoch 2/100
0s - loss: 0.5422 - val_loss: 0.5333
Epoch 3/100
0s - loss: 0.5246 - val_loss: 0.5156
Epoch 4/100
0s - loss: 0.5027 - val_loss: 0.4980
Epoch 5/100
0s - loss: 0.4859 - val_loss: 0.4875
Epoch 6/100
0s - loss: 0.4780 - val_loss: 0.4836
Epoch 7/100
0s - loss: 0.4742 - val_loss: 0.4815
Epoch 8/100
0s - loss: 0.4719 - val_loss: 0.4800
Epoch 9/100
0s - loss: 0.4694 - val_loss: 0.4785
Epoch 10/100
0s - loss: 0.4673 - val_loss: 0.4762
Epoch 11/100
0s - loss: 0.4649 - val_loss: 0.4745
Epoch 12/100
0s - loss: 0.4628 - val_loss: 0.4739
Epoch 13/100
0s - loss: 0.4611 - val_loss: 0.4746
Epoch 14/100
0s - loss: 0.4605 - val_loss: 0.4726
Epoch 15/100
0s - loss: 0.4584 - val_loss: 0.4714
Epoch 16/100
0s - loss: 0.4568 - val_loss: 0.4695
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:00,593 - 1_UsokinAE_450-250_50_relu|Fold #9 Loss = 0.469502
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.6085 - val_loss: 0.5491
Epoch 2/100
0s - loss: 0.5394 - val_loss: 0.5286
Epoch 3/100
0s - loss: 0.5189 - val_loss: 0.5055
Epoch 4/100
0s - loss: 0.4983 - val_loss: 0.4851
Epoch 5/100
0s - loss: 0.4832 - val_loss: 0.4759
Epoch 6/100
0s - loss: 0.4771 - val_loss: 0.4729
Epoch 7/100
0s - loss: 0.4742 - val_loss: 0.4702
Epoch 8/100
0s - loss: 0.4714 - val_loss: 0.4683
Epoch 9/100
0s - loss: 0.4689 - val_loss: 0.4667
Epoch 10/100
0s - loss: 0.4662 - val_loss: 0.4642
Epoch 11/100
0s - loss: 0.4641 - val_loss: 0.4629
Epoch 12/100
0s - loss: 0.4620 - val_loss: 0.4614
Epoch 13/100
0s - loss: 0.4599 - val_loss: 0.4597
Epoch 14/100
0s - loss: 0.4580 - val_loss: 0.4592
Epoch 15/100
0s - loss: 0.4563 - val_loss: 0.4579
Epoch 16/100
0s - loss: 0.4546 - val_loss: 0.4572
Epoch 17/100
0s - loss: 0.4534 - val_loss: 0.4568
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:11,008 - 1_UsokinAE_450-250_50_relu|Fold #10 Loss = 0.456772
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:11,008 - 1_UsokinAE_450-250_50_relu|Avg Validation Loss = 0.464468
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.6106 - val_loss: 0.5439
Epoch 2/100
0s - loss: 0.5382 - val_loss: 0.5228
Epoch 3/100
0s - loss: 0.5173 - val_loss: 0.5023
Epoch 4/100
0s - loss: 0.4985 - val_loss: 0.4885
Epoch 5/100
0s - loss: 0.4862 - val_loss: 0.4804
Epoch 6/100
0s - loss: 0.4795 - val_loss: 0.4780
Epoch 7/100
0s - loss: 0.4761 - val_loss: 0.4782
Epoch 8/100
0s - loss: 0.4753 - val_loss: 0.4732
Epoch 9/100
0s - loss: 0.4720 - val_loss: 0.4712
Epoch 10/100
0s - loss: 0.4700 - val_loss: 0.4723
Epoch 11/100
0s - loss: 0.4682 - val_loss: 0.4689
Epoch 12/100
0s - loss: 0.4654 - val_loss: 0.4688
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:18,693 - 2_UsokinAE_350-300_200_relu|Fold #1 Loss = 0.468816
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6245 - val_loss: 0.5446
Epoch 2/100
0s - loss: 0.5392 - val_loss: 0.5240
Epoch 3/100
0s - loss: 0.5213 - val_loss: 0.5064
Epoch 4/100
0s - loss: 0.5007 - val_loss: 0.4872
Epoch 5/100
0s - loss: 0.4850 - val_loss: 0.4772
Epoch 6/100
0s - loss: 0.4778 - val_loss: 0.4734
Epoch 7/100
0s - loss: 0.4745 - val_loss: 0.4714
Epoch 8/100
0s - loss: 0.4719 - val_loss: 0.4692
Epoch 9/100
0s - loss: 0.4687 - val_loss: 0.4667
Epoch 10/100
0s - loss: 0.4659 - val_loss: 0.4656
Epoch 11/100
0s - loss: 0.4636 - val_loss: 0.4642
Epoch 12/100
0s - loss: 0.4612 - val_loss: 0.4632
Epoch 13/100
0s - loss: 0.4593 - val_loss: 0.4616
Epoch 14/100
0s - loss: 0.4572 - val_loss: 0.4604
Epoch 15/100
0s - loss: 0.4553 - val_loss: 0.4594
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:28,005 - 2_UsokinAE_350-300_200_relu|Fold #2 Loss = 0.459377
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6126 - val_loss: 0.5527
Epoch 2/100
0s - loss: 0.5374 - val_loss: 0.5322
Epoch 3/100
0s - loss: 0.5179 - val_loss: 0.5126
Epoch 4/100
0s - loss: 0.4944 - val_loss: 0.4955
Epoch 5/100
0s - loss: 0.4808 - val_loss: 0.4900
Epoch 6/100
0s - loss: 0.4752 - val_loss: 0.4866
Epoch 7/100
0s - loss: 0.4719 - val_loss: 0.4843
Epoch 8/100
0s - loss: 0.4690 - val_loss: 0.4825
Epoch 9/100
0s - loss: 0.4659 - val_loss: 0.4808
Epoch 10/100
0s - loss: 0.4632 - val_loss: 0.4796
Epoch 11/100
0s - loss: 0.4612 - val_loss: 0.4771
Epoch 12/100
0s - loss: 0.4588 - val_loss: 0.4760
Epoch 13/100
0s - loss: 0.4569 - val_loss: 0.4752
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:36,363 - 2_UsokinAE_350-300_200_relu|Fold #3 Loss = 0.475237
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6071 - val_loss: 0.5410
Epoch 2/100
0s - loss: 0.5352 - val_loss: 0.5218
Epoch 3/100
0s - loss: 0.5157 - val_loss: 0.5003
Epoch 4/100
0s - loss: 0.4944 - val_loss: 0.4856
Epoch 5/100
0s - loss: 0.4826 - val_loss: 0.4791
Epoch 6/100
0s - loss: 0.4773 - val_loss: 0.4770
Epoch 7/100
0s - loss: 0.4737 - val_loss: 0.4747
Epoch 8/100
0s - loss: 0.4708 - val_loss: 0.4719
Epoch 9/100
0s - loss: 0.4675 - val_loss: 0.4700
Epoch 10/100
0s - loss: 0.4650 - val_loss: 0.4691
Epoch 11/100
0s - loss: 0.4631 - val_loss: 0.4676
Epoch 12/100
0s - loss: 0.4609 - val_loss: 0.4658
Epoch 13/100
0s - loss: 0.4591 - val_loss: 0.4651
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:44,707 - 2_UsokinAE_350-300_200_relu|Fold #4 Loss = 0.465123
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.6164 - val_loss: 0.5488
Epoch 2/100
0s - loss: 0.5401 - val_loss: 0.5320
Epoch 3/100
0s - loss: 0.5233 - val_loss: 0.5153
Epoch 4/100
0s - loss: 0.5029 - val_loss: 0.4949
Epoch 5/100
0s - loss: 0.4848 - val_loss: 0.4837
Epoch 6/100
0s - loss: 0.4773 - val_loss: 0.4815
Epoch 7/100
0s - loss: 0.4745 - val_loss: 0.4781
Epoch 8/100
0s - loss: 0.4723 - val_loss: 0.4771
Epoch 9/100
0s - loss: 0.4702 - val_loss: 0.4748
Epoch 10/100
0s - loss: 0.4678 - val_loss: 0.4736
Epoch 11/100
0s - loss: 0.4650 - val_loss: 0.4720
Epoch 12/100
0s - loss: 0.4622 - val_loss: 0.4698
Epoch 13/100
0s - loss: 0.4595 - val_loss: 0.4683
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4667
Epoch 15/100
0s - loss: 0.4556 - val_loss: 0.4656
Epoch 16/100
0s - loss: 0.4538 - val_loss: 0.4651
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:50:54,681 - 2_UsokinAE_350-300_200_relu|Fold #5 Loss = 0.465141
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.6175 - val_loss: 0.5451
Epoch 2/100
0s - loss: 0.5419 - val_loss: 0.5258
Epoch 3/100
0s - loss: 0.5225 - val_loss: 0.5051
Epoch 4/100
0s - loss: 0.5021 - val_loss: 0.4842
Epoch 5/100
0s - loss: 0.4851 - val_loss: 0.4744
Epoch 6/100
0s - loss: 0.4784 - val_loss: 0.4707
Epoch 7/100
0s - loss: 0.4756 - val_loss: 0.4691
Epoch 8/100
0s - loss: 0.4728 - val_loss: 0.4668
Epoch 9/100
0s - loss: 0.4704 - val_loss: 0.4646
Epoch 10/100
0s - loss: 0.4682 - val_loss: 0.4619
Epoch 11/100
0s - loss: 0.4653 - val_loss: 0.4612
Epoch 12/100
0s - loss: 0.4628 - val_loss: 0.4603
Epoch 13/100
0s - loss: 0.4607 - val_loss: 0.4580
Epoch 14/100
0s - loss: 0.4589 - val_loss: 0.4576
Epoch 15/100
0s - loss: 0.4569 - val_loss: 0.4567
Epoch 16/100
0s - loss: 0.4557 - val_loss: 0.4564
Epoch 17/100
0s - loss: 0.4547 - val_loss: 0.4569
Epoch 18/100
0s - loss: 0.4541 - val_loss: 0.4555
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:51:05,686 - 2_UsokinAE_350-300_200_relu|Fold #6 Loss = 0.455511
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6147 - val_loss: 0.5573
Epoch 2/100
0s - loss: 0.5372 - val_loss: 0.5389
Epoch 3/100
0s - loss: 0.5203 - val_loss: 0.5243
Epoch 4/100
0s - loss: 0.5014 - val_loss: 0.5068
Epoch 5/100
0s - loss: 0.4844 - val_loss: 0.4977
Epoch 6/100
0s - loss: 0.4763 - val_loss: 0.4939
Epoch 7/100
0s - loss: 0.4731 - val_loss: 0.4926
Epoch 8/100
0s - loss: 0.4708 - val_loss: 0.4902
Epoch 9/100
0s - loss: 0.4682 - val_loss: 0.4881
Epoch 10/100
0s - loss: 0.4658 - val_loss: 0.4857
Epoch 11/100
0s - loss: 0.4626 - val_loss: 0.4835
Epoch 12/100
0s - loss: 0.4601 - val_loss: 0.4821
Epoch 13/100
0s - loss: 0.4587 - val_loss: 0.4812
Epoch 14/100
0s - loss: 0.4561 - val_loss: 0.4791
Epoch 15/100
0s - loss: 0.4543 - val_loss: 0.4788
Epoch 16/100
0s - loss: 0.4527 - val_loss: 0.4777
Epoch 17/100
0s - loss: 0.4508 - val_loss: 0.4766
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:51:16,117 - 2_UsokinAE_350-300_200_relu|Fold #7 Loss = 0.476642
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6109 - val_loss: 0.5457
Epoch 2/100
0s - loss: 0.5386 - val_loss: 0.5251
Epoch 3/100
0s - loss: 0.5222 - val_loss: 0.5094
Epoch 4/100
0s - loss: 0.5026 - val_loss: 0.4870
Epoch 5/100
0s - loss: 0.4847 - val_loss: 0.4761
Epoch 6/100
0s - loss: 0.4777 - val_loss: 0.4728
Epoch 7/100
0s - loss: 0.4749 - val_loss: 0.4701
Epoch 8/100
0s - loss: 0.4722 - val_loss: 0.4681
Epoch 9/100
0s - loss: 0.4696 - val_loss: 0.4650
Epoch 10/100
0s - loss: 0.4665 - val_loss: 0.4634
Epoch 11/100
0s - loss: 0.4641 - val_loss: 0.4617
Epoch 12/100
0s - loss: 0.4619 - val_loss: 0.4600
Epoch 13/100
0s - loss: 0.4602 - val_loss: 0.4593
Epoch 14/100
0s - loss: 0.4583 - val_loss: 0.4587
Epoch 15/100
0s - loss: 0.4565 - val_loss: 0.4572
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:51:25,572 - 2_UsokinAE_350-300_200_relu|Fold #8 Loss = 0.457230
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6193 - val_loss: 0.5481
Epoch 2/100
0s - loss: 0.5399 - val_loss: 0.5304
Epoch 3/100
0s - loss: 0.5207 - val_loss: 0.5119
Epoch 4/100
0s - loss: 0.5005 - val_loss: 0.4953
Epoch 5/100
0s - loss: 0.4832 - val_loss: 0.4857
Epoch 6/100
0s - loss: 0.4766 - val_loss: 0.4836
Epoch 7/100
0s - loss: 0.4739 - val_loss: 0.4810
Epoch 8/100
0s - loss: 0.4704 - val_loss: 0.4795
Epoch 9/100
0s - loss: 0.4683 - val_loss: 0.4775
Epoch 10/100
0s - loss: 0.4658 - val_loss: 0.4754
Epoch 11/100
0s - loss: 0.4631 - val_loss: 0.4738
Epoch 12/100
0s - loss: 0.4608 - val_loss: 0.4720
Epoch 13/100
0s - loss: 0.4590 - val_loss: 0.4711
Epoch 14/100
0s - loss: 0.4573 - val_loss: 0.4703
Epoch 15/100
0s - loss: 0.4553 - val_loss: 0.4691
Epoch 16/100
0s - loss: 0.4538 - val_loss: 0.4697
Epoch 17/100
0s - loss: 0.4524 - val_loss: 0.4673
Epoch 18/100
0s - loss: 0.4501 - val_loss: 0.4673
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:51:36,428 - 2_UsokinAE_350-300_200_relu|Fold #9 Loss = 0.467344
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.6123 - val_loss: 0.5501
Epoch 2/100
0s - loss: 0.5367 - val_loss: 0.5273
Epoch 3/100
0s - loss: 0.5164 - val_loss: 0.5078
Epoch 4/100
0s - loss: 0.5002 - val_loss: 0.4875
Epoch 5/100
0s - loss: 0.4850 - val_loss: 0.4767
Epoch 6/100
0s - loss: 0.4775 - val_loss: 0.4728
Epoch 7/100
0s - loss: 0.4745 - val_loss: 0.4712
Epoch 8/100
0s - loss: 0.4715 - val_loss: 0.4682
Epoch 9/100
0s - loss: 0.4688 - val_loss: 0.4659
Epoch 10/100
0s - loss: 0.4658 - val_loss: 0.4650
Epoch 11/100
0s - loss: 0.4635 - val_loss: 0.4632
Epoch 12/100
0s - loss: 0.4613 - val_loss: 0.4617
Epoch 13/100
0s - loss: 0.4592 - val_loss: 0.4599
Epoch 14/100
0s - loss: 0.4569 - val_loss: 0.4591
Epoch 15/100
0s - loss: 0.4552 - val_loss: 0.4583
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:51:45,936 - 2_UsokinAE_350-300_200_relu|Fold #10 Loss = 0.458345
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:51:45,937 - 2_UsokinAE_350-300_200_relu|Avg Validation Loss = 0.464877
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6819 - val_loss: 0.7272
Epoch 2/100
0s - loss: 0.6116 - val_loss: 0.7335
Epoch 3/100
0s - loss: 0.5394 - val_loss: 0.7036
Epoch 4/100
0s - loss: 0.4987 - val_loss: 0.5893
Epoch 5/100
0s - loss: 0.4882 - val_loss: 0.6121
Epoch 6/100
0s - loss: 0.4842 - val_loss: 0.5378
Epoch 7/100
0s - loss: 0.4761 - val_loss: 0.5255
Epoch 8/100
0s - loss: 0.4729 - val_loss: 0.5101
Epoch 9/100
0s - loss: 0.4709 - val_loss: 0.4935
Epoch 10/100
0s - loss: 0.4727 - val_loss: 0.4932
Epoch 11/100
0s - loss: 0.4701 - val_loss: 0.4850
Epoch 12/100
0s - loss: 0.4703 - val_loss: 0.4852
Epoch 13/100
0s - loss: 0.4665 - val_loss: 0.4813
Epoch 14/100
0s - loss: 0.4635 - val_loss: 0.4796
Epoch 15/100
0s - loss: 0.4652 - val_loss: 0.4759
Epoch 16/100
0s - loss: 0.4648 - val_loss: 0.4758
Epoch 17/100
0s - loss: 0.4617 - val_loss: 0.4720
Epoch 18/100
0s - loss: 0.4598 - val_loss: 0.4705
Epoch 19/100
0s - loss: 0.4592 - val_loss: 0.4679
Epoch 20/100
0s - loss: 0.4577 - val_loss: 0.4683
Epoch 21/100
0s - loss: 0.4611 - val_loss: 0.4721
Epoch 22/100
0s - loss: 0.4599 - val_loss: 0.4700
Epoch 23/100
0s - loss: 0.4567 - val_loss: 0.4694
Epoch 24/100
0s - loss: 0.4549 - val_loss: 0.4675
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:52:03,921 - 3_UsokinAE_350-300_100_tanh_BN|Fold #1 Loss = 0.467507
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6804 - val_loss: 0.7351
Epoch 2/100
0s - loss: 0.6000 - val_loss: 0.7522
Epoch 3/100
0s - loss: 0.5202 - val_loss: 0.6581
Epoch 4/100
0s - loss: 0.4874 - val_loss: 0.6151
Epoch 5/100
0s - loss: 0.4779 - val_loss: 0.5415
Epoch 6/100
0s - loss: 0.4733 - val_loss: 0.5279
Epoch 7/100
0s - loss: 0.4705 - val_loss: 0.5269
Epoch 8/100
0s - loss: 0.4711 - val_loss: 0.5135
Epoch 9/100
0s - loss: 0.4749 - val_loss: 0.5117
Epoch 10/100
0s - loss: 0.4693 - val_loss: 0.5144
Epoch 11/100
0s - loss: 0.4661 - val_loss: 0.4883
Epoch 12/100
0s - loss: 0.4625 - val_loss: 0.4830
Epoch 13/100
0s - loss: 0.4608 - val_loss: 0.4793
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4720
Epoch 15/100
0s - loss: 0.4579 - val_loss: 0.4694
Epoch 16/100
0s - loss: 0.4580 - val_loss: 0.4672
Epoch 17/100
0s - loss: 0.4551 - val_loss: 0.4656
Epoch 18/100
0s - loss: 0.4538 - val_loss: 0.4625
Epoch 19/100
0s - loss: 0.4536 - val_loss: 0.4625
Epoch 20/100
0s - loss: 0.4505 - val_loss: 0.4595
Epoch 21/100
0s - loss: 0.4492 - val_loss: 0.4603
Epoch 22/100
0s - loss: 0.4479 - val_loss: 0.4595
Epoch 23/100
0s - loss: 0.4462 - val_loss: 0.4587
Epoch 24/100
0s - loss: 0.4469 - val_loss: 0.4591
Epoch 25/100
0s - loss: 0.4465 - val_loss: 0.4600
Epoch 26/100
0s - loss: 0.4449 - val_loss: 0.4604
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:52:23,053 - 3_UsokinAE_350-300_100_tanh_BN|Fold #2 Loss = 0.460361
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6804 - val_loss: 0.7206
Epoch 2/100
0s - loss: 0.6122 - val_loss: 0.6939
Epoch 3/100
0s - loss: 0.5290 - val_loss: 0.7009
Epoch 4/100
0s - loss: 0.4890 - val_loss: 0.6396
Epoch 5/100
0s - loss: 0.4768 - val_loss: 0.6041
Epoch 6/100
0s - loss: 0.4709 - val_loss: 0.5449
Epoch 7/100
0s - loss: 0.4680 - val_loss: 0.5265
Epoch 8/100
0s - loss: 0.4682 - val_loss: 0.5121
Epoch 9/100
0s - loss: 0.4655 - val_loss: 0.4977
Epoch 10/100
0s - loss: 0.4608 - val_loss: 0.4971
Epoch 11/100
0s - loss: 0.4584 - val_loss: 0.4948
Epoch 12/100
0s - loss: 0.4556 - val_loss: 0.4891
Epoch 13/100
0s - loss: 0.4539 - val_loss: 0.4854
Epoch 14/100
0s - loss: 0.4544 - val_loss: 0.4848
Epoch 15/100
0s - loss: 0.4541 - val_loss: 0.4810
Epoch 16/100
0s - loss: 0.4579 - val_loss: 0.4868
Epoch 17/100
0s - loss: 0.4535 - val_loss: 0.4772
Epoch 18/100
0s - loss: 0.4512 - val_loss: 0.4756
Epoch 19/100
0s - loss: 0.4475 - val_loss: 0.4738
Epoch 20/100
0s - loss: 0.4456 - val_loss: 0.4725
Epoch 21/100
0s - loss: 0.4449 - val_loss: 0.4716
Epoch 22/100
0s - loss: 0.4419 - val_loss: 0.4710
Epoch 23/100
0s - loss: 0.4404 - val_loss: 0.4707
Epoch 24/100
0s - loss: 0.4391 - val_loss: 0.4711
Epoch 25/100
0s - loss: 0.4380 - val_loss: 0.4718
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:52:42,483 - 3_UsokinAE_350-300_100_tanh_BN|Fold #3 Loss = 0.471770
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6823 - val_loss: 0.7342
Epoch 2/100
0s - loss: 0.6105 - val_loss: 0.7356
Epoch 3/100
0s - loss: 0.5303 - val_loss: 0.7646
Epoch 4/100
0s - loss: 0.5004 - val_loss: 0.6796
Epoch 5/100
0s - loss: 0.4879 - val_loss: 0.5658
Epoch 6/100
0s - loss: 0.4807 - val_loss: 0.5314
Epoch 7/100
0s - loss: 0.4724 - val_loss: 0.5119
Epoch 8/100
0s - loss: 0.4685 - val_loss: 0.5021
Epoch 9/100
0s - loss: 0.4668 - val_loss: 0.5121
Epoch 10/100
0s - loss: 0.4630 - val_loss: 0.4973
Epoch 11/100
0s - loss: 0.4621 - val_loss: 0.4826
Epoch 12/100
0s - loss: 0.4610 - val_loss: 0.4779
Epoch 13/100
0s - loss: 0.4594 - val_loss: 0.4750
Epoch 14/100
0s - loss: 0.4578 - val_loss: 0.4709
Epoch 15/100
0s - loss: 0.4551 - val_loss: 0.4695
Epoch 16/100
0s - loss: 0.4546 - val_loss: 0.4685
Epoch 17/100
0s - loss: 0.4521 - val_loss: 0.4650
Epoch 18/100
0s - loss: 0.4513 - val_loss: 0.4650
Epoch 19/100
0s - loss: 0.4500 - val_loss: 0.4635
Epoch 20/100
0s - loss: 0.4485 - val_loss: 0.4623
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:52:58,630 - 3_UsokinAE_350-300_100_tanh_BN|Fold #4 Loss = 0.462348
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6791 - val_loss: 0.7227
Epoch 2/100
0s - loss: 0.6017 - val_loss: 0.7291
Epoch 3/100
0s - loss: 0.5232 - val_loss: 0.8078
Epoch 4/100
0s - loss: 0.4894 - val_loss: 0.6656
Epoch 5/100
0s - loss: 0.4793 - val_loss: 0.5825
Epoch 6/100
0s - loss: 0.4777 - val_loss: 0.5277
Epoch 7/100
0s - loss: 0.4716 - val_loss: 0.5291
Epoch 8/100
0s - loss: 0.4687 - val_loss: 0.5093
Epoch 9/100
0s - loss: 0.4690 - val_loss: 0.4953
Epoch 10/100
0s - loss: 0.4660 - val_loss: 0.4887
Epoch 11/100
0s - loss: 0.4622 - val_loss: 0.4916
Epoch 12/100
0s - loss: 0.4610 - val_loss: 0.4830
Epoch 13/100
0s - loss: 0.4585 - val_loss: 0.4783
Epoch 14/100
0s - loss: 0.4542 - val_loss: 0.4738
Epoch 15/100
0s - loss: 0.4530 - val_loss: 0.4729
Epoch 16/100
0s - loss: 0.4518 - val_loss: 0.4710
Epoch 17/100
0s - loss: 0.4493 - val_loss: 0.4693
Epoch 18/100
0s - loss: 0.4480 - val_loss: 0.4664
Epoch 19/100
0s - loss: 0.4468 - val_loss: 0.4665
Epoch 20/100
0s - loss: 0.4445 - val_loss: 0.4656
Epoch 21/100
0s - loss: 0.4426 - val_loss: 0.4644
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:53:15,294 - 3_UsokinAE_350-300_100_tanh_BN|Fold #5 Loss = 0.464379
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6814 - val_loss: 0.7255
Epoch 2/100
0s - loss: 0.6074 - val_loss: 0.7022
Epoch 3/100
0s - loss: 0.5313 - val_loss: 0.7058
Epoch 4/100
0s - loss: 0.4920 - val_loss: 0.6126
Epoch 5/100
0s - loss: 0.4814 - val_loss: 0.5372
Epoch 6/100
0s - loss: 0.4740 - val_loss: 0.5594
Epoch 7/100
0s - loss: 0.4699 - val_loss: 0.5060
Epoch 8/100
0s - loss: 0.4667 - val_loss: 0.5070
Epoch 9/100
0s - loss: 0.4648 - val_loss: 0.4956
Epoch 10/100
0s - loss: 0.4729 - val_loss: 0.4890
Epoch 11/100
0s - loss: 0.4666 - val_loss: 0.5024
Epoch 12/100
0s - loss: 0.4640 - val_loss: 0.4730
Epoch 13/100
0s - loss: 0.4631 - val_loss: 0.4682
Epoch 14/100
0s - loss: 0.4633 - val_loss: 0.4833
Epoch 15/100
0s - loss: 0.4596 - val_loss: 0.4773
Epoch 16/100
0s - loss: 0.4581 - val_loss: 0.4668
Epoch 17/100
0s - loss: 0.4548 - val_loss: 0.4652
Epoch 18/100
0s - loss: 0.4593 - val_loss: 0.4646
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:53:30,203 - 3_UsokinAE_350-300_100_tanh_BN|Fold #6 Loss = 0.464619
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6791 - val_loss: 0.7318
Epoch 2/100
0s - loss: 0.6045 - val_loss: 0.7569
Epoch 3/100
0s - loss: 0.5218 - val_loss: 0.6639
Epoch 4/100
0s - loss: 0.4908 - val_loss: 0.6833
Epoch 5/100
0s - loss: 0.4877 - val_loss: 0.6258
Epoch 6/100
0s - loss: 0.4808 - val_loss: 0.5872
Epoch 7/100
0s - loss: 0.4729 - val_loss: 0.5637
Epoch 8/100
0s - loss: 0.4685 - val_loss: 0.5348
Epoch 9/100
0s - loss: 0.4670 - val_loss: 0.5134
Epoch 10/100
0s - loss: 0.4627 - val_loss: 0.5051
Epoch 11/100
0s - loss: 0.4620 - val_loss: 0.4969
Epoch 12/100
0s - loss: 0.4582 - val_loss: 0.4965
Epoch 13/100
0s - loss: 0.4565 - val_loss: 0.4923
Epoch 14/100
0s - loss: 0.4565 - val_loss: 0.4903
Epoch 15/100
0s - loss: 0.4575 - val_loss: 0.4921
Epoch 16/100
0s - loss: 0.4541 - val_loss: 0.4873
Epoch 17/100
0s - loss: 0.4515 - val_loss: 0.4841
Epoch 18/100
0s - loss: 0.4509 - val_loss: 0.4834
Epoch 19/100
0s - loss: 0.4497 - val_loss: 0.4829
Epoch 20/100
0s - loss: 0.4483 - val_loss: 0.4838
Epoch 21/100
0s - loss: 0.4481 - val_loss: 0.4813
Epoch 22/100
0s - loss: 0.4466 - val_loss: 0.4802
Epoch 23/100
0s - loss: 0.4443 - val_loss: 0.4794
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:53:47,989 - 3_UsokinAE_350-300_100_tanh_BN|Fold #7 Loss = 0.479448
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6787 - val_loss: 0.7355
Epoch 2/100
0s - loss: 0.6002 - val_loss: 0.7338
Epoch 3/100
0s - loss: 0.5190 - val_loss: 0.6800
Epoch 4/100
0s - loss: 0.4879 - val_loss: 0.6775
Epoch 5/100
0s - loss: 0.4787 - val_loss: 0.5682
Epoch 6/100
0s - loss: 0.4727 - val_loss: 0.5559
Epoch 7/100
0s - loss: 0.4678 - val_loss: 0.5363
Epoch 8/100
0s - loss: 0.4643 - val_loss: 0.4958
Epoch 9/100
0s - loss: 0.4629 - val_loss: 0.4908
Epoch 10/100
0s - loss: 0.4613 - val_loss: 0.4906
Epoch 11/100
0s - loss: 0.4614 - val_loss: 0.4757
Epoch 12/100
0s - loss: 0.4655 - val_loss: 0.4817
Epoch 13/100
0s - loss: 0.4615 - val_loss: 0.4754
Epoch 14/100
0s - loss: 0.4590 - val_loss: 0.4771
Epoch 15/100
0s - loss: 0.4566 - val_loss: 0.4715
Epoch 16/100
0s - loss: 0.4528 - val_loss: 0.4704
Epoch 17/100
0s - loss: 0.4520 - val_loss: 0.4648
Epoch 18/100
0s - loss: 0.4499 - val_loss: 0.4636
Epoch 19/100
0s - loss: 0.4483 - val_loss: 0.4606
Epoch 20/100
0s - loss: 0.4478 - val_loss: 0.4601
Epoch 21/100
0s - loss: 0.4462 - val_loss: 0.4579
Epoch 22/100
0s - loss: 0.4452 - val_loss: 0.4573
Epoch 23/100
0s - loss: 0.4436 - val_loss: 0.4570
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:54:05,847 - 3_UsokinAE_350-300_100_tanh_BN|Fold #8 Loss = 0.456952
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6816 - val_loss: 0.7305
Epoch 2/100
0s - loss: 0.6047 - val_loss: 0.7178
Epoch 3/100
0s - loss: 0.5242 - val_loss: 0.7395
Epoch 4/100
0s - loss: 0.4886 - val_loss: 0.6720
Epoch 5/100
0s - loss: 0.4793 - val_loss: 0.6278
Epoch 6/100
0s - loss: 0.4773 - val_loss: 0.6201
Epoch 7/100
0s - loss: 0.4736 - val_loss: 0.5684
Epoch 8/100
0s - loss: 0.4697 - val_loss: 0.5305
Epoch 9/100
0s - loss: 0.4662 - val_loss: 0.5063
Epoch 10/100
0s - loss: 0.4621 - val_loss: 0.5072
Epoch 11/100
0s - loss: 0.4622 - val_loss: 0.5100
Epoch 12/100
0s - loss: 0.4630 - val_loss: 0.5174
Epoch 13/100
0s - loss: 0.4586 - val_loss: 0.4976
Epoch 14/100
0s - loss: 0.4559 - val_loss: 0.4897
Epoch 15/100
0s - loss: 0.4546 - val_loss: 0.4856
Epoch 16/100
0s - loss: 0.4542 - val_loss: 0.4788
Epoch 17/100
0s - loss: 0.4567 - val_loss: 0.4768
Epoch 18/100
0s - loss: 0.4526 - val_loss: 0.4754
Epoch 19/100
0s - loss: 0.4496 - val_loss: 0.4725
Epoch 20/100
0s - loss: 0.4482 - val_loss: 0.4716
Epoch 21/100
0s - loss: 0.4465 - val_loss: 0.4678
Epoch 22/100
0s - loss: 0.4446 - val_loss: 0.4670
Epoch 23/100
0s - loss: 0.4429 - val_loss: 0.4661
Epoch 24/100
0s - loss: 0.4426 - val_loss: 0.4666
Epoch 25/100
0s - loss: 0.4409 - val_loss: 0.4665
Epoch 26/100
0s - loss: 0.4395 - val_loss: 0.4658
Epoch 27/100
0s - loss: 0.4384 - val_loss: 0.4666
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:54:25,591 - 3_UsokinAE_350-300_100_tanh_BN|Fold #9 Loss = 0.466614
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6836 - val_loss: 0.7241
Epoch 2/100
0s - loss: 0.6140 - val_loss: 0.6942
Epoch 3/100
0s - loss: 0.5307 - val_loss: 0.6348
Epoch 4/100
0s - loss: 0.4935 - val_loss: 0.6457
Epoch 5/100
0s - loss: 0.4775 - val_loss: 0.6735
Epoch 6/100
0s - loss: 0.4732 - val_loss: 0.5913
Epoch 7/100
0s - loss: 0.4662 - val_loss: 0.5197
Epoch 8/100
0s - loss: 0.4633 - val_loss: 0.4981
Epoch 9/100
0s - loss: 0.4609 - val_loss: 0.4926
Epoch 10/100
0s - loss: 0.4644 - val_loss: 0.4847
Epoch 11/100
0s - loss: 0.4636 - val_loss: 0.5266
Epoch 12/100
0s - loss: 0.4598 - val_loss: 0.5046
Epoch 13/100
0s - loss: 0.4577 - val_loss: 0.4719
Epoch 14/100
0s - loss: 0.4560 - val_loss: 0.4652
Epoch 15/100
0s - loss: 0.4536 - val_loss: 0.4632
Epoch 16/100
0s - loss: 0.4514 - val_loss: 0.4635
Epoch 17/100
0s - loss: 0.4500 - val_loss: 0.4622
Epoch 18/100
0s - loss: 0.4483 - val_loss: 0.4593
Epoch 19/100
0s - loss: 0.4458 - val_loss: 0.4582
Epoch 20/100
0s - loss: 0.4447 - val_loss: 0.4566
Epoch 21/100
0s - loss: 0.4434 - val_loss: 0.4560
Epoch 22/100
0s - loss: 0.4413 - val_loss: 0.4551
Epoch 23/100
0s - loss: 0.4400 - val_loss: 0.4546
Epoch 24/100
0s - loss: 0.4394 - val_loss: 0.4547
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:54:43,847 - 3_UsokinAE_350-300_100_tanh_BN|Fold #10 Loss = 0.454711
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:54:43,847 - 3_UsokinAE_350-300_100_tanh_BN|Avg Validation Loss = 0.464871
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6805 - val_loss: 0.7206
Epoch 2/100
0s - loss: 0.6218 - val_loss: 0.7005
Epoch 3/100
0s - loss: 0.5499 - val_loss: 0.6869
Epoch 4/100
0s - loss: 0.5005 - val_loss: 0.6197
Epoch 5/100
0s - loss: 0.4823 - val_loss: 0.6433
Epoch 6/100
0s - loss: 0.4813 - val_loss: 0.5281
Epoch 7/100
0s - loss: 0.4808 - val_loss: 0.5536
Epoch 8/100
0s - loss: 0.4785 - val_loss: 0.5220
Epoch 9/100
0s - loss: 0.4732 - val_loss: 0.4985
Epoch 10/100
0s - loss: 0.4731 - val_loss: 0.4941
Epoch 11/100
0s - loss: 0.4710 - val_loss: 0.4864
Epoch 12/100
0s - loss: 0.4683 - val_loss: 0.4840
Epoch 13/100
0s - loss: 0.4681 - val_loss: 0.4886
Epoch 14/100
0s - loss: 0.4664 - val_loss: 0.4824
Epoch 15/100
0s - loss: 0.4647 - val_loss: 0.4753
Epoch 16/100
0s - loss: 0.4634 - val_loss: 0.4742
Epoch 17/100
0s - loss: 0.4626 - val_loss: 0.4724
Epoch 18/100
0s - loss: 0.4605 - val_loss: 0.4717
Epoch 19/100
0s - loss: 0.4619 - val_loss: 0.4768
Epoch 20/100
0s - loss: 0.4639 - val_loss: 0.4777
Epoch 21/100
0s - loss: 0.4605 - val_loss: 0.4726
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:55:00,319 - 4_UsokinAE_400-250_50_tanh_BN|Fold #1 Loss = 0.472588
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6776 - val_loss: 0.7261
Epoch 2/100
0s - loss: 0.6091 - val_loss: 0.7207
Epoch 3/100
0s - loss: 0.5245 - val_loss: 0.7032
Epoch 4/100
0s - loss: 0.4880 - val_loss: 0.8408
Epoch 5/100
0s - loss: 0.4818 - val_loss: 0.5723
Epoch 6/100
0s - loss: 0.4720 - val_loss: 0.5849
Epoch 7/100
0s - loss: 0.4712 - val_loss: 0.5231
Epoch 8/100
0s - loss: 0.4703 - val_loss: 0.5397
Epoch 9/100
0s - loss: 0.4675 - val_loss: 0.5106
Epoch 10/100
0s - loss: 0.4662 - val_loss: 0.4884
Epoch 11/100
0s - loss: 0.4672 - val_loss: 0.4837
Epoch 12/100
0s - loss: 0.4664 - val_loss: 0.4918
Epoch 13/100
0s - loss: 0.4624 - val_loss: 0.4796
Epoch 14/100
0s - loss: 0.4610 - val_loss: 0.4743
Epoch 15/100
0s - loss: 0.4575 - val_loss: 0.4730
Epoch 16/100
0s - loss: 0.4551 - val_loss: 0.4672
Epoch 17/100
0s - loss: 0.4540 - val_loss: 0.4660
Epoch 18/100
0s - loss: 0.4539 - val_loss: 0.4639
Epoch 19/100
0s - loss: 0.4512 - val_loss: 0.4639
Epoch 20/100
0s - loss: 0.4496 - val_loss: 0.4620
Epoch 21/100
0s - loss: 0.4489 - val_loss: 0.4626
Epoch 22/100
0s - loss: 0.4478 - val_loss: 0.4619
Epoch 23/100
0s - loss: 0.4467 - val_loss: 0.4607
Epoch 24/100
0s - loss: 0.4451 - val_loss: 0.4594
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:55:18,711 - 4_UsokinAE_400-250_50_tanh_BN|Fold #2 Loss = 0.459445
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6799 - val_loss: 0.7268
Epoch 2/100
0s - loss: 0.6086 - val_loss: 0.6884
Epoch 3/100
0s - loss: 0.5248 - val_loss: 0.8724
Epoch 4/100
0s - loss: 0.4864 - val_loss: 0.6681
Epoch 5/100
0s - loss: 0.4775 - val_loss: 0.5564
Epoch 6/100
0s - loss: 0.4741 - val_loss: 0.5259
Epoch 7/100
0s - loss: 0.4734 - val_loss: 0.5166
Epoch 8/100
0s - loss: 0.4763 - val_loss: 0.5571
Epoch 9/100
0s - loss: 0.4685 - val_loss: 0.5342
Epoch 10/100
0s - loss: 0.4638 - val_loss: 0.5066
Epoch 11/100
0s - loss: 0.4647 - val_loss: 0.4969
Epoch 12/100
0s - loss: 0.4629 - val_loss: 0.4911
Epoch 13/100
0s - loss: 0.4583 - val_loss: 0.4863
Epoch 14/100
0s - loss: 0.4575 - val_loss: 0.4834
Epoch 15/100
0s - loss: 0.4571 - val_loss: 0.4805
Epoch 16/100
0s - loss: 0.4553 - val_loss: 0.4803
Epoch 17/100
0s - loss: 0.4538 - val_loss: 0.4802
Epoch 18/100
0s - loss: 0.4530 - val_loss: 0.4785
Epoch 19/100
0s - loss: 0.4519 - val_loss: 0.4770
Epoch 20/100
0s - loss: 0.4550 - val_loss: 0.4811
Epoch 21/100
0s - loss: 0.4533 - val_loss: 0.4792
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:55:35,329 - 4_UsokinAE_400-250_50_tanh_BN|Fold #3 Loss = 0.479193
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6807 - val_loss: 0.7254
Epoch 2/100
0s - loss: 0.6134 - val_loss: 0.7007
Epoch 3/100
0s - loss: 0.5311 - val_loss: 0.7067
Epoch 4/100
0s - loss: 0.4940 - val_loss: 0.6344
Epoch 5/100
0s - loss: 0.4878 - val_loss: 0.6492
Epoch 6/100
0s - loss: 0.4790 - val_loss: 0.5649
Epoch 7/100
0s - loss: 0.4718 - val_loss: 0.5272
Epoch 8/100
0s - loss: 0.4670 - val_loss: 0.5123
Epoch 9/100
0s - loss: 0.4651 - val_loss: 0.5082
Epoch 10/100
0s - loss: 0.4628 - val_loss: 0.5073
Epoch 11/100
0s - loss: 0.4629 - val_loss: 0.4939
Epoch 12/100
0s - loss: 0.4601 - val_loss: 0.4890
Epoch 13/100
0s - loss: 0.4588 - val_loss: 0.4822
Epoch 14/100
0s - loss: 0.4562 - val_loss: 0.4796
Epoch 15/100
0s - loss: 0.4574 - val_loss: 0.4735
Epoch 16/100
0s - loss: 0.4563 - val_loss: 0.4700
Epoch 17/100
0s - loss: 0.4625 - val_loss: 0.4803
Epoch 18/100
0s - loss: 0.4627 - val_loss: 0.4917
Epoch 19/100
0s - loss: 0.4626 - val_loss: 0.4742
Epoch 20/100
0s - loss: 0.4565 - val_loss: 0.4686
Epoch 21/100
0s - loss: 0.4535 - val_loss: 0.4654
Epoch 22/100
0s - loss: 0.4521 - val_loss: 0.4647
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:55:52,651 - 4_UsokinAE_400-250_50_tanh_BN|Fold #4 Loss = 0.464686
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6791 - val_loss: 0.7241
Epoch 2/100
0s - loss: 0.6054 - val_loss: 0.7173
Epoch 3/100
0s - loss: 0.5224 - val_loss: 0.7930
Epoch 4/100
0s - loss: 0.4886 - val_loss: 0.5745
Epoch 5/100
0s - loss: 0.4840 - val_loss: 0.5713
Epoch 6/100
0s - loss: 0.4776 - val_loss: 0.5648
Epoch 7/100
0s - loss: 0.4689 - val_loss: 0.5361
Epoch 8/100
0s - loss: 0.4674 - val_loss: 0.5200
Epoch 9/100
0s - loss: 0.4710 - val_loss: 0.5094
Epoch 10/100
0s - loss: 0.4662 - val_loss: 0.4988
Epoch 11/100
0s - loss: 0.4626 - val_loss: 0.4929
Epoch 12/100
0s - loss: 0.4627 - val_loss: 0.4886
Epoch 13/100
0s - loss: 0.4589 - val_loss: 0.4847
Epoch 14/100
0s - loss: 0.4580 - val_loss: 0.4809
Epoch 15/100
0s - loss: 0.4565 - val_loss: 0.4745
Epoch 16/100
0s - loss: 0.4565 - val_loss: 0.4761
Epoch 17/100
0s - loss: 0.4553 - val_loss: 0.4734
Epoch 18/100
0s - loss: 0.4533 - val_loss: 0.4722
Epoch 19/100
0s - loss: 0.4533 - val_loss: 0.4715
Epoch 20/100
0s - loss: 0.4509 - val_loss: 0.4710
Epoch 21/100
0s - loss: 0.4498 - val_loss: 0.4689
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:56:09,542 - 4_UsokinAE_400-250_50_tanh_BN|Fold #5 Loss = 0.468899
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6792 - val_loss: 0.7204
Epoch 2/100
0s - loss: 0.6122 - val_loss: 0.7025
Epoch 3/100
0s - loss: 0.5312 - val_loss: 0.7338
Epoch 4/100
0s - loss: 0.4921 - val_loss: 0.5959
Epoch 5/100
0s - loss: 0.4824 - val_loss: 0.5555
Epoch 6/100
0s - loss: 0.4803 - val_loss: 0.5218
Epoch 7/100
0s - loss: 0.4761 - val_loss: 0.5177
Epoch 8/100
0s - loss: 0.4744 - val_loss: 0.5081
Epoch 9/100
0s - loss: 0.4715 - val_loss: 0.5156
Epoch 10/100
0s - loss: 0.4686 - val_loss: 0.4920
Epoch 11/100
0s - loss: 0.4648 - val_loss: 0.4767
Epoch 12/100
0s - loss: 0.4664 - val_loss: 0.4748
Epoch 13/100
0s - loss: 0.4686 - val_loss: 0.4741
Epoch 14/100
0s - loss: 0.4674 - val_loss: 0.4734
Epoch 15/100
0s - loss: 0.4643 - val_loss: 0.4713
Epoch 16/100
0s - loss: 0.4605 - val_loss: 0.4642
Epoch 17/100
0s - loss: 0.4601 - val_loss: 0.4625
Epoch 18/100
0s - loss: 0.4582 - val_loss: 0.4606
Epoch 19/100
0s - loss: 0.4585 - val_loss: 0.4610
Epoch 20/100
0s - loss: 0.4586 - val_loss: 0.4612
Epoch 21/100
0s - loss: 0.4564 - val_loss: 0.4600
Epoch 22/100
0s - loss: 0.4548 - val_loss: 0.4594
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:56:26,881 - 4_UsokinAE_400-250_50_tanh_BN|Fold #6 Loss = 0.459362
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6794 - val_loss: 0.7286
Epoch 2/100
0s - loss: 0.6076 - val_loss: 0.7402
Epoch 3/100
0s - loss: 0.5241 - val_loss: 0.7819
Epoch 4/100
0s - loss: 0.4829 - val_loss: 0.6667
Epoch 5/100
0s - loss: 0.4784 - val_loss: 0.5743
Epoch 6/100
0s - loss: 0.4735 - val_loss: 0.5536
Epoch 7/100
0s - loss: 0.4671 - val_loss: 0.5470
Epoch 8/100
0s - loss: 0.4670 - val_loss: 0.5232
Epoch 9/100
0s - loss: 0.4633 - val_loss: 0.5178
Epoch 10/100
0s - loss: 0.4614 - val_loss: 0.5120
Epoch 11/100
0s - loss: 0.4616 - val_loss: 0.5002
Epoch 12/100
0s - loss: 0.4599 - val_loss: 0.4932
Epoch 13/100
0s - loss: 0.4621 - val_loss: 0.4956
Epoch 14/100
0s - loss: 0.4598 - val_loss: 0.4919
Epoch 15/100
0s - loss: 0.4568 - val_loss: 0.4885
Epoch 16/100
0s - loss: 0.4548 - val_loss: 0.4870
Epoch 17/100
0s - loss: 0.4526 - val_loss: 0.4859
Epoch 18/100
0s - loss: 0.4533 - val_loss: 0.4847
Epoch 19/100
0s - loss: 0.4510 - val_loss: 0.4830
Epoch 20/100
0s - loss: 0.4497 - val_loss: 0.4827
Epoch 21/100
0s - loss: 0.4509 - val_loss: 0.4877
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:56:43,676 - 4_UsokinAE_400-250_50_tanh_BN|Fold #7 Loss = 0.487747
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6790 - val_loss: 0.7166
Epoch 2/100
0s - loss: 0.6067 - val_loss: 0.6893
Epoch 3/100
0s - loss: 0.5263 - val_loss: 0.6337
Epoch 4/100
0s - loss: 0.4897 - val_loss: 0.7744
Epoch 5/100
0s - loss: 0.4762 - val_loss: 0.5679
Epoch 6/100
0s - loss: 0.4777 - val_loss: 0.5448
Epoch 7/100
0s - loss: 0.4750 - val_loss: 0.5349
Epoch 8/100
0s - loss: 0.4683 - val_loss: 0.5186
Epoch 9/100
0s - loss: 0.4668 - val_loss: 0.5131
Epoch 10/100
0s - loss: 0.4689 - val_loss: 0.5023
Epoch 11/100
0s - loss: 0.4650 - val_loss: 0.4853
Epoch 12/100
0s - loss: 0.4623 - val_loss: 0.4843
Epoch 13/100
0s - loss: 0.4597 - val_loss: 0.4779
Epoch 14/100
0s - loss: 0.4582 - val_loss: 0.4742
Epoch 15/100
0s - loss: 0.4567 - val_loss: 0.4705
Epoch 16/100
0s - loss: 0.4556 - val_loss: 0.4670
Epoch 17/100
0s - loss: 0.4561 - val_loss: 0.4639
Epoch 18/100
0s - loss: 0.4535 - val_loss: 0.4624
Epoch 19/100
0s - loss: 0.4514 - val_loss: 0.4607
Epoch 20/100
0s - loss: 0.4512 - val_loss: 0.4608
Epoch 21/100
0s - loss: 0.4512 - val_loss: 0.4592
Epoch 22/100
0s - loss: 0.4487 - val_loss: 0.4589
Epoch 23/100
0s - loss: 0.4474 - val_loss: 0.4573
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:57:01,576 - 4_UsokinAE_400-250_50_tanh_BN|Fold #8 Loss = 0.457278
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6811 - val_loss: 0.7227
Epoch 2/100
0s - loss: 0.6152 - val_loss: 0.7033
Epoch 3/100
0s - loss: 0.5398 - val_loss: 0.7374
Epoch 4/100
0s - loss: 0.4931 - val_loss: 0.6125
Epoch 5/100
0s - loss: 0.4830 - val_loss: 0.5637
Epoch 6/100
0s - loss: 0.4758 - val_loss: 0.5480
Epoch 7/100
0s - loss: 0.4688 - val_loss: 0.5489
Epoch 8/100
0s - loss: 0.4689 - val_loss: 0.5177
Epoch 9/100
0s - loss: 0.4675 - val_loss: 0.5007
Epoch 10/100
0s - loss: 0.4652 - val_loss: 0.4976
Epoch 11/100
0s - loss: 0.4669 - val_loss: 0.4999
Epoch 12/100
0s - loss: 0.4638 - val_loss: 0.4954
Epoch 13/100
0s - loss: 0.4622 - val_loss: 0.4964
Epoch 14/100
0s - loss: 0.4590 - val_loss: 0.4859
Epoch 15/100
0s - loss: 0.4584 - val_loss: 0.4824
Epoch 16/100
0s - loss: 0.4573 - val_loss: 0.4815
Epoch 17/100
0s - loss: 0.4562 - val_loss: 0.4798
Epoch 18/100
0s - loss: 0.4549 - val_loss: 0.4760
Epoch 19/100
0s - loss: 0.4526 - val_loss: 0.4744
Epoch 20/100
0s - loss: 0.4519 - val_loss: 0.4726
Epoch 21/100
0s - loss: 0.4503 - val_loss: 0.4707
Epoch 22/100
0s - loss: 0.4497 - val_loss: 0.4698
Epoch 23/100
0s - loss: 0.4488 - val_loss: 0.4695
Epoch 24/100
0s - loss: 0.4486 - val_loss: 0.4690
Epoch 25/100
0s - loss: 0.4465 - val_loss: 0.4690
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:57:21,004 - 4_UsokinAE_400-250_50_tanh_BN|Fold #9 Loss = 0.468986
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6781 - val_loss: 0.7215
Epoch 2/100
0s - loss: 0.6068 - val_loss: 0.6897
Epoch 3/100
0s - loss: 0.5238 - val_loss: 0.6897
Epoch 4/100
0s - loss: 0.4888 - val_loss: 0.5400
Epoch 5/100
0s - loss: 0.4850 - val_loss: 0.5933
Epoch 6/100
0s - loss: 0.4767 - val_loss: 0.5758
Epoch 7/100
0s - loss: 0.4810 - val_loss: 0.5211
Epoch 8/100
0s - loss: 0.4735 - val_loss: 0.5140
Epoch 9/100
0s - loss: 0.4691 - val_loss: 0.5044
Epoch 10/100
0s - loss: 0.4640 - val_loss: 0.4893
Epoch 11/100
0s - loss: 0.4613 - val_loss: 0.4823
Epoch 12/100
0s - loss: 0.4591 - val_loss: 0.4758
Epoch 13/100
0s - loss: 0.4591 - val_loss: 0.4715
Epoch 14/100
0s - loss: 0.4604 - val_loss: 0.4752
Epoch 15/100
0s - loss: 0.4592 - val_loss: 0.4699
Epoch 16/100
0s - loss: 0.4564 - val_loss: 0.4661
Epoch 17/100
0s - loss: 0.4542 - val_loss: 0.4639
Epoch 18/100
0s - loss: 0.4542 - val_loss: 0.4623
Epoch 19/100
0s - loss: 0.4513 - val_loss: 0.4607
Epoch 20/100
0s - loss: 0.4507 - val_loss: 0.4620
Epoch 21/100
0s - loss: 0.4494 - val_loss: 0.4608
Epoch 22/100
0s - loss: 0.4477 - val_loss: 0.4596
Epoch 23/100
0s - loss: 0.4475 - val_loss: 0.4595
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:57:39,279 - 4_UsokinAE_400-250_50_tanh_BN|Fold #10 Loss = 0.459459
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:57:39,279 - 4_UsokinAE_400-250_50_tanh_BN|Avg Validation Loss = 0.467764
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6272 - val_loss: 0.6520
Epoch 2/100
0s - loss: 0.5124 - val_loss: 0.6343
Epoch 3/100
0s - loss: 0.4851 - val_loss: 0.6267
Epoch 4/100
0s - loss: 0.4742 - val_loss: 0.6088
Epoch 5/100
0s - loss: 0.4681 - val_loss: 0.5934
Epoch 6/100
0s - loss: 0.4643 - val_loss: 0.5812
Epoch 7/100
0s - loss: 0.4603 - val_loss: 0.5700
Epoch 8/100
0s - loss: 0.4576 - val_loss: 0.5531
Epoch 9/100
0s - loss: 0.4561 - val_loss: 0.5492
Epoch 10/100
0s - loss: 0.4533 - val_loss: 0.5433
Epoch 11/100
0s - loss: 0.4529 - val_loss: 0.5314
Epoch 12/100
0s - loss: 0.4505 - val_loss: 0.5200
Epoch 13/100
0s - loss: 0.4485 - val_loss: 0.5137
Epoch 14/100
0s - loss: 0.4473 - val_loss: 0.5017
Epoch 15/100
0s - loss: 0.4468 - val_loss: 0.5054
Epoch 16/100
0s - loss: 0.4451 - val_loss: 0.4932
Epoch 17/100
0s - loss: 0.4457 - val_loss: 0.4873
Epoch 18/100
0s - loss: 0.4436 - val_loss: 0.4868
Epoch 19/100
0s - loss: 0.4409 - val_loss: 0.4854
Epoch 20/100
0s - loss: 0.4403 - val_loss: 0.4839
Epoch 21/100
0s - loss: 0.4401 - val_loss: 0.4779
Epoch 22/100
0s - loss: 0.4394 - val_loss: 0.4795
Epoch 23/100
0s - loss: 0.4374 - val_loss: 0.4771
Epoch 24/100
0s - loss: 0.4360 - val_loss: 0.4739
Epoch 25/100
0s - loss: 0.4352 - val_loss: 0.4763
Epoch 26/100
0s - loss: 0.4342 - val_loss: 0.4777
Epoch 27/100
0s - loss: 0.4329 - val_loss: 0.4782
Epoch 28/100
0s - loss: 0.4331 - val_loss: 0.4777
Epoch 29/100
0s - loss: 0.4338 - val_loss: 0.4919
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:58:02,012 - 5_UsokinAE_400-250_100_relu_BN|Fold #1 Loss = 0.491861
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6199 - val_loss: 0.6475
Epoch 2/100
0s - loss: 0.5084 - val_loss: 0.6264
Epoch 3/100
0s - loss: 0.4818 - val_loss: 0.6221
Epoch 4/100
0s - loss: 0.4701 - val_loss: 0.6030
Epoch 5/100
0s - loss: 0.4637 - val_loss: 0.5948
Epoch 6/100
0s - loss: 0.4574 - val_loss: 0.5800
Epoch 7/100
0s - loss: 0.4540 - val_loss: 0.5698
Epoch 8/100
0s - loss: 0.4510 - val_loss: 0.5485
Epoch 9/100
0s - loss: 0.4476 - val_loss: 0.5418
Epoch 10/100
0s - loss: 0.4454 - val_loss: 0.5303
Epoch 11/100
0s - loss: 0.4422 - val_loss: 0.5142
Epoch 12/100
0s - loss: 0.4397 - val_loss: 0.5096
Epoch 13/100
0s - loss: 0.4373 - val_loss: 0.4974
Epoch 14/100
0s - loss: 0.4342 - val_loss: 0.4918
Epoch 15/100
0s - loss: 0.4322 - val_loss: 0.4848
Epoch 16/100
0s - loss: 0.4302 - val_loss: 0.4785
Epoch 17/100
0s - loss: 0.4270 - val_loss: 0.4766
Epoch 18/100
0s - loss: 0.4256 - val_loss: 0.4721
Epoch 19/100
0s - loss: 0.4230 - val_loss: 0.4690
Epoch 20/100
0s - loss: 0.4205 - val_loss: 0.4673
Epoch 21/100
0s - loss: 0.4189 - val_loss: 0.4630
Epoch 22/100
0s - loss: 0.4173 - val_loss: 0.4631
Epoch 23/100
0s - loss: 0.4157 - val_loss: 0.4630
Epoch 24/100
0s - loss: 0.4144 - val_loss: 0.4623
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:58:22,530 - 5_UsokinAE_400-250_100_relu_BN|Fold #2 Loss = 0.462326
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6202 - val_loss: 0.6435
Epoch 2/100
0s - loss: 0.5080 - val_loss: 0.6249
Epoch 3/100
0s - loss: 0.4802 - val_loss: 0.6154
Epoch 4/100
0s - loss: 0.4679 - val_loss: 0.6074
Epoch 5/100
0s - loss: 0.4621 - val_loss: 0.5991
Epoch 6/100
0s - loss: 0.4579 - val_loss: 0.5840
Epoch 7/100
0s - loss: 0.4538 - val_loss: 0.5795
Epoch 8/100
0s - loss: 0.4504 - val_loss: 0.5594
Epoch 9/100
0s - loss: 0.4470 - val_loss: 0.5524
Epoch 10/100
0s - loss: 0.4441 - val_loss: 0.5317
Epoch 11/100
0s - loss: 0.4414 - val_loss: 0.5206
Epoch 12/100
0s - loss: 0.4388 - val_loss: 0.5193
Epoch 13/100
0s - loss: 0.4362 - val_loss: 0.5051
Epoch 14/100
0s - loss: 0.4346 - val_loss: 0.5057
Epoch 15/100
0s - loss: 0.4324 - val_loss: 0.5007
Epoch 16/100
0s - loss: 0.4297 - val_loss: 0.4932
Epoch 17/100
0s - loss: 0.4281 - val_loss: 0.4886
Epoch 18/100
0s - loss: 0.4264 - val_loss: 0.4832
Epoch 19/100
0s - loss: 0.4243 - val_loss: 0.4833
Epoch 20/100
0s - loss: 0.4220 - val_loss: 0.4804
Epoch 21/100
0s - loss: 0.4195 - val_loss: 0.4816
Epoch 22/100
0s - loss: 0.4186 - val_loss: 0.4785
Epoch 23/100
0s - loss: 0.4169 - val_loss: 0.4786
Epoch 24/100
0s - loss: 0.4145 - val_loss: 0.4759
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:58:42,335 - 5_UsokinAE_400-250_100_relu_BN|Fold #3 Loss = 0.475851
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6222 - val_loss: 0.6425
Epoch 2/100
0s - loss: 0.5084 - val_loss: 0.6313
Epoch 3/100
0s - loss: 0.4818 - val_loss: 0.6199
Epoch 4/100
0s - loss: 0.4712 - val_loss: 0.6084
Epoch 5/100
0s - loss: 0.4644 - val_loss: 0.5952
Epoch 6/100
0s - loss: 0.4584 - val_loss: 0.5835
Epoch 7/100
0s - loss: 0.4547 - val_loss: 0.5674
Epoch 8/100
0s - loss: 0.4508 - val_loss: 0.5570
Epoch 9/100
0s - loss: 0.4483 - val_loss: 0.5425
Epoch 10/100
0s - loss: 0.4455 - val_loss: 0.5352
Epoch 11/100
0s - loss: 0.4428 - val_loss: 0.5173
Epoch 12/100
0s - loss: 0.4414 - val_loss: 0.5067
Epoch 13/100
0s - loss: 0.4396 - val_loss: 0.5050
Epoch 14/100
0s - loss: 0.4354 - val_loss: 0.4954
Epoch 15/100
0s - loss: 0.4332 - val_loss: 0.4855
Epoch 16/100
0s - loss: 0.4308 - val_loss: 0.4849
Epoch 17/100
0s - loss: 0.4279 - val_loss: 0.4812
Epoch 18/100
0s - loss: 0.4263 - val_loss: 0.4770
Epoch 19/100
0s - loss: 0.4235 - val_loss: 0.4775
Epoch 20/100
0s - loss: 0.4211 - val_loss: 0.4710
Epoch 21/100
0s - loss: 0.4208 - val_loss: 0.4676
Epoch 22/100
0s - loss: 0.4180 - val_loss: 0.4664
Epoch 23/100
0s - loss: 0.4156 - val_loss: 0.4661
Epoch 24/100
0s - loss: 0.4149 - val_loss: 0.4637
Epoch 25/100
0s - loss: 0.4134 - val_loss: 0.4666
Epoch 26/100
0s - loss: 0.4112 - val_loss: 0.4650
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:59:03,533 - 5_UsokinAE_400-250_100_relu_BN|Fold #4 Loss = 0.464987
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6226 - val_loss: 0.6554
Epoch 2/100
0s - loss: 0.5109 - val_loss: 0.6295
Epoch 3/100
0s - loss: 0.4817 - val_loss: 0.6205
Epoch 4/100
0s - loss: 0.4700 - val_loss: 0.6095
Epoch 5/100
0s - loss: 0.4637 - val_loss: 0.6032
Epoch 6/100
0s - loss: 0.4587 - val_loss: 0.5872
Epoch 7/100
0s - loss: 0.4544 - val_loss: 0.5706
Epoch 8/100
0s - loss: 0.4502 - val_loss: 0.5576
Epoch 9/100
0s - loss: 0.4467 - val_loss: 0.5437
Epoch 10/100
0s - loss: 0.4440 - val_loss: 0.5298
Epoch 11/100
0s - loss: 0.4408 - val_loss: 0.5202
Epoch 12/100
0s - loss: 0.4377 - val_loss: 0.5099
Epoch 13/100
0s - loss: 0.4356 - val_loss: 0.5049
Epoch 14/100
0s - loss: 0.4336 - val_loss: 0.4958
Epoch 15/100
0s - loss: 0.4308 - val_loss: 0.4922
Epoch 16/100
0s - loss: 0.4280 - val_loss: 0.4865
Epoch 17/100
0s - loss: 0.4272 - val_loss: 0.4798
Epoch 18/100
0s - loss: 0.4245 - val_loss: 0.4799
Epoch 19/100
0s - loss: 0.4215 - val_loss: 0.4770
Epoch 20/100
0s - loss: 0.4202 - val_loss: 0.4727
Epoch 21/100
0s - loss: 0.4179 - val_loss: 0.4723
Epoch 22/100
0s - loss: 0.4157 - val_loss: 0.4708
Epoch 23/100
0s - loss: 0.4132 - val_loss: 0.4700
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:59:23,118 - 5_UsokinAE_400-250_100_relu_BN|Fold #5 Loss = 0.469981
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6268 - val_loss: 0.6511
Epoch 2/100
0s - loss: 0.5123 - val_loss: 0.6300
Epoch 3/100
0s - loss: 0.4846 - val_loss: 0.6217
Epoch 4/100
0s - loss: 0.4756 - val_loss: 0.6095
Epoch 5/100
0s - loss: 0.4679 - val_loss: 0.5965
Epoch 6/100
0s - loss: 0.4628 - val_loss: 0.5876
Epoch 7/100
0s - loss: 0.4582 - val_loss: 0.5679
Epoch 8/100
0s - loss: 0.4543 - val_loss: 0.5573
Epoch 9/100
0s - loss: 0.4522 - val_loss: 0.5400
Epoch 10/100
0s - loss: 0.4498 - val_loss: 0.5324
Epoch 11/100
0s - loss: 0.4466 - val_loss: 0.5191
Epoch 12/100
0s - loss: 0.4441 - val_loss: 0.5084
Epoch 13/100
0s - loss: 0.4432 - val_loss: 0.4984
Epoch 14/100
0s - loss: 0.4401 - val_loss: 0.4882
Epoch 15/100
0s - loss: 0.4403 - val_loss: 0.4836
Epoch 16/100
0s - loss: 0.4372 - val_loss: 0.4811
Epoch 17/100
0s - loss: 0.4345 - val_loss: 0.4713
Epoch 18/100
0s - loss: 0.4323 - val_loss: 0.4699
Epoch 19/100
0s - loss: 0.4323 - val_loss: 0.4679
Epoch 20/100
0s - loss: 0.4304 - val_loss: 0.4646
Epoch 21/100
0s - loss: 0.4277 - val_loss: 0.4623
Epoch 22/100
0s - loss: 0.4263 - val_loss: 0.4618
Epoch 23/100
0s - loss: 0.4250 - val_loss: 0.4623
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 20:59:42,449 - 5_UsokinAE_400-250_100_relu_BN|Fold #6 Loss = 0.462268
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6224 - val_loss: 0.6598
Epoch 2/100
0s - loss: 0.5079 - val_loss: 0.6358
Epoch 3/100
0s - loss: 0.4806 - val_loss: 0.6183
Epoch 4/100
0s - loss: 0.4700 - val_loss: 0.6022
Epoch 5/100
0s - loss: 0.4630 - val_loss: 0.5879
Epoch 6/100
0s - loss: 0.4572 - val_loss: 0.5801
Epoch 7/100
0s - loss: 0.4532 - val_loss: 0.5671
Epoch 8/100
0s - loss: 0.4514 - val_loss: 0.5564
Epoch 9/100
0s - loss: 0.4469 - val_loss: 0.5450
Epoch 10/100
0s - loss: 0.4432 - val_loss: 0.5390
Epoch 11/100
0s - loss: 0.4401 - val_loss: 0.5241
Epoch 12/100
0s - loss: 0.4376 - val_loss: 0.5193
Epoch 13/100
0s - loss: 0.4348 - val_loss: 0.5133
Epoch 14/100
0s - loss: 0.4316 - val_loss: 0.5054
Epoch 15/100
0s - loss: 0.4295 - val_loss: 0.5019
Epoch 16/100
0s - loss: 0.4292 - val_loss: 0.5003
Epoch 17/100
0s - loss: 0.4278 - val_loss: 0.4962
Epoch 18/100
0s - loss: 0.4243 - val_loss: 0.4923
Epoch 19/100
0s - loss: 0.4218 - val_loss: 0.4878
Epoch 20/100
0s - loss: 0.4196 - val_loss: 0.4892
Epoch 21/100
0s - loss: 0.4171 - val_loss: 0.4877
Epoch 22/100
0s - loss: 0.4166 - val_loss: 0.4871
Epoch 23/100
0s - loss: 0.4150 - val_loss: 0.4869
Epoch 24/100
0s - loss: 0.4141 - val_loss: 0.4820
Epoch 25/100
0s - loss: 0.4111 - val_loss: 0.4827
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:00:03,185 - 5_UsokinAE_400-250_100_relu_BN|Fold #7 Loss = 0.482708
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6197 - val_loss: 0.6563
Epoch 2/100
0s - loss: 0.5099 - val_loss: 0.6378
Epoch 3/100
0s - loss: 0.4825 - val_loss: 0.6238
Epoch 4/100
0s - loss: 0.4715 - val_loss: 0.6125
Epoch 5/100
0s - loss: 0.4647 - val_loss: 0.5953
Epoch 6/100
0s - loss: 0.4598 - val_loss: 0.5768
Epoch 7/100
0s - loss: 0.4548 - val_loss: 0.5626
Epoch 8/100
0s - loss: 0.4511 - val_loss: 0.5503
Epoch 9/100
0s - loss: 0.4489 - val_loss: 0.5373
Epoch 10/100
0s - loss: 0.4456 - val_loss: 0.5244
Epoch 11/100
0s - loss: 0.4431 - val_loss: 0.5119
Epoch 12/100
0s - loss: 0.4403 - val_loss: 0.5046
Epoch 13/100
0s - loss: 0.4377 - val_loss: 0.4928
Epoch 14/100
0s - loss: 0.4352 - val_loss: 0.4873
Epoch 15/100
0s - loss: 0.4330 - val_loss: 0.4816
Epoch 16/100
0s - loss: 0.4302 - val_loss: 0.4794
Epoch 17/100
0s - loss: 0.4292 - val_loss: 0.4710
Epoch 18/100
0s - loss: 0.4276 - val_loss: 0.4707
Epoch 19/100
0s - loss: 0.4245 - val_loss: 0.4644
Epoch 20/100
0s - loss: 0.4228 - val_loss: 0.4601
Epoch 21/100
0s - loss: 0.4204 - val_loss: 0.4606
Epoch 22/100
0s - loss: 0.4189 - val_loss: 0.4594
Epoch 23/100
0s - loss: 0.4166 - val_loss: 0.4573
Epoch 24/100
0s - loss: 0.4153 - val_loss: 0.4590
Epoch 25/100
0s - loss: 0.4133 - val_loss: 0.4575
Epoch 26/100
0s - loss: 0.4104 - val_loss: 0.4593
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:00:23,966 - 5_UsokinAE_400-250_100_relu_BN|Fold #8 Loss = 0.459287
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6305 - val_loss: 0.6466
Epoch 2/100
0s - loss: 0.5095 - val_loss: 0.6243
Epoch 3/100
0s - loss: 0.4814 - val_loss: 0.6136
Epoch 4/100
0s - loss: 0.4698 - val_loss: 0.6051
Epoch 5/100
0s - loss: 0.4639 - val_loss: 0.5913
Epoch 6/100
0s - loss: 0.4581 - val_loss: 0.5858
Epoch 7/100
0s - loss: 0.4544 - val_loss: 0.5711
Epoch 8/100
0s - loss: 0.4514 - val_loss: 0.5606
Epoch 9/100
0s - loss: 0.4480 - val_loss: 0.5497
Epoch 10/100
0s - loss: 0.4445 - val_loss: 0.5395
Epoch 11/100
0s - loss: 0.4421 - val_loss: 0.5268
Epoch 12/100
0s - loss: 0.4397 - val_loss: 0.5137
Epoch 13/100
0s - loss: 0.4373 - val_loss: 0.5088
Epoch 14/100
0s - loss: 0.4355 - val_loss: 0.4970
Epoch 15/100
0s - loss: 0.4324 - val_loss: 0.4946
Epoch 16/100
0s - loss: 0.4300 - val_loss: 0.4872
Epoch 17/100
0s - loss: 0.4271 - val_loss: 0.4836
Epoch 18/100
0s - loss: 0.4261 - val_loss: 0.4837
Epoch 19/100
0s - loss: 0.4239 - val_loss: 0.4767
Epoch 20/100
0s - loss: 0.4214 - val_loss: 0.4744
Epoch 21/100
0s - loss: 0.4186 - val_loss: 0.4750
Epoch 22/100
0s - loss: 0.4171 - val_loss: 0.4732
Epoch 23/100
0s - loss: 0.4149 - val_loss: 0.4749
Epoch 24/100
0s - loss: 0.4132 - val_loss: 0.4713
Epoch 25/100
0s - loss: 0.4120 - val_loss: 0.4715
Epoch 26/100
0s - loss: 0.4110 - val_loss: 0.4736
Epoch 27/100
0s - loss: 0.4097 - val_loss: 0.4745
Epoch 28/100
0s - loss: 0.4085 - val_loss: 0.4729
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:00:44,974 - 5_UsokinAE_400-250_100_relu_BN|Fold #9 Loss = 0.472882
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6250 - val_loss: 0.6475
Epoch 2/100
0s - loss: 0.5088 - val_loss: 0.6266
Epoch 3/100
0s - loss: 0.4826 - val_loss: 0.6108
Epoch 4/100
0s - loss: 0.4706 - val_loss: 0.5988
Epoch 5/100
0s - loss: 0.4633 - val_loss: 0.5850
Epoch 6/100
0s - loss: 0.4593 - val_loss: 0.5731
Epoch 7/100
0s - loss: 0.4544 - val_loss: 0.5614
Epoch 8/100
0s - loss: 0.4512 - val_loss: 0.5462
Epoch 9/100
0s - loss: 0.4484 - val_loss: 0.5367
Epoch 10/100
0s - loss: 0.4457 - val_loss: 0.5255
Epoch 11/100
0s - loss: 0.4424 - val_loss: 0.5162
Epoch 12/100
0s - loss: 0.4399 - val_loss: 0.5061
Epoch 13/100
0s - loss: 0.4374 - val_loss: 0.5028
Epoch 14/100
0s - loss: 0.4348 - val_loss: 0.4937
Epoch 15/100
0s - loss: 0.4329 - val_loss: 0.4858
Epoch 16/100
0s - loss: 0.4298 - val_loss: 0.4801
Epoch 17/100
0s - loss: 0.4288 - val_loss: 0.4767
Epoch 18/100
0s - loss: 0.4258 - val_loss: 0.4754
Epoch 19/100
0s - loss: 0.4232 - val_loss: 0.4673
Epoch 20/100
0s - loss: 0.4217 - val_loss: 0.4694
Epoch 21/100
0s - loss: 0.4199 - val_loss: 0.4645
Epoch 22/100
0s - loss: 0.4175 - val_loss: 0.4633
Epoch 23/100
0s - loss: 0.4156 - val_loss: 0.4623
Epoch 24/100
0s - loss: 0.4137 - val_loss: 0.4617
Epoch 25/100
0s - loss: 0.4114 - val_loss: 0.4616
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:04,382 - 5_UsokinAE_400-250_100_relu_BN|Fold #10 Loss = 0.461642
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:04,383 - 5_UsokinAE_400-250_100_relu_BN|Avg Validation Loss = 0.470379
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.6202 - val_loss: 0.5491
Epoch 2/100
0s - loss: 0.5443 - val_loss: 0.5338
Epoch 3/100
0s - loss: 0.5307 - val_loss: 0.5219
Epoch 4/100
0s - loss: 0.5172 - val_loss: 0.5060
Epoch 5/100
0s - loss: 0.5008 - val_loss: 0.4908
Epoch 6/100
0s - loss: 0.4873 - val_loss: 0.4813
Epoch 7/100
0s - loss: 0.4803 - val_loss: 0.4793
Epoch 8/100
0s - loss: 0.4768 - val_loss: 0.4753
Epoch 9/100
0s - loss: 0.4743 - val_loss: 0.4740
Epoch 10/100
0s - loss: 0.4718 - val_loss: 0.4724
Epoch 11/100
0s - loss: 0.4697 - val_loss: 0.4715
Epoch 12/100
0s - loss: 0.4676 - val_loss: 0.4719
Epoch 13/100
0s - loss: 0.4668 - val_loss: 0.4689
Epoch 14/100
0s - loss: 0.4639 - val_loss: 0.4675
Epoch 15/100
0s - loss: 0.4617 - val_loss: 0.4660
Epoch 16/100
0s - loss: 0.4594 - val_loss: 0.4647
Epoch 17/100
0s - loss: 0.4578 - val_loss: 0.4646
Epoch 18/100
0s - loss: 0.4566 - val_loss: 0.4642
Epoch 19/100
0s - loss: 0.4556 - val_loss: 0.4626
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:15,861 - 6_UsokinAE_350-250_50_relu|Fold #1 Loss = 0.462568
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6169 - val_loss: 0.5507
Epoch 2/100
0s - loss: 0.5435 - val_loss: 0.5305
Epoch 3/100
0s - loss: 0.5288 - val_loss: 0.5146
Epoch 4/100
0s - loss: 0.5131 - val_loss: 0.4993
Epoch 5/100
0s - loss: 0.4980 - val_loss: 0.4878
Epoch 6/100
0s - loss: 0.4873 - val_loss: 0.4809
Epoch 7/100
0s - loss: 0.4796 - val_loss: 0.4757
Epoch 8/100
0s - loss: 0.4756 - val_loss: 0.4729
Epoch 9/100
0s - loss: 0.4731 - val_loss: 0.4713
Epoch 10/100
0s - loss: 0.4703 - val_loss: 0.4693
Epoch 11/100
0s - loss: 0.4682 - val_loss: 0.4684
Epoch 12/100
0s - loss: 0.4659 - val_loss: 0.4664
Epoch 13/100
0s - loss: 0.4642 - val_loss: 0.4656
Epoch 14/100
0s - loss: 0.4628 - val_loss: 0.4650
Epoch 15/100
0s - loss: 0.4614 - val_loss: 0.4640
Epoch 16/100
0s - loss: 0.4602 - val_loss: 0.4633
Epoch 17/100
0s - loss: 0.4584 - val_loss: 0.4620
Epoch 18/100
0s - loss: 0.4570 - val_loss: 0.4618
Epoch 19/100
0s - loss: 0.4556 - val_loss: 0.4606
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:27,275 - 6_UsokinAE_350-250_50_relu|Fold #2 Loss = 0.460611
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6273 - val_loss: 0.5543
Epoch 2/100
0s - loss: 0.5449 - val_loss: 0.5424
Epoch 3/100
0s - loss: 0.5304 - val_loss: 0.5282
Epoch 4/100
0s - loss: 0.5120 - val_loss: 0.5097
Epoch 5/100
0s - loss: 0.4942 - val_loss: 0.4979
Epoch 6/100
0s - loss: 0.4836 - val_loss: 0.4903
Epoch 7/100
0s - loss: 0.4768 - val_loss: 0.4873
Epoch 8/100
0s - loss: 0.4737 - val_loss: 0.4856
Epoch 9/100
0s - loss: 0.4714 - val_loss: 0.4835
Epoch 10/100
0s - loss: 0.4689 - val_loss: 0.4820
Epoch 11/100
0s - loss: 0.4664 - val_loss: 0.4808
Epoch 12/100
0s - loss: 0.4644 - val_loss: 0.4799
Epoch 13/100
0s - loss: 0.4630 - val_loss: 0.4787
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:35,484 - 6_UsokinAE_350-250_50_relu|Fold #3 Loss = 0.478690
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6195 - val_loss: 0.5484
Epoch 2/100
0s - loss: 0.5423 - val_loss: 0.5284
Epoch 3/100
0s - loss: 0.5228 - val_loss: 0.5116
Epoch 4/100
0s - loss: 0.5079 - val_loss: 0.4987
Epoch 5/100
0s - loss: 0.4939 - val_loss: 0.4851
Epoch 6/100
0s - loss: 0.4819 - val_loss: 0.4789
Epoch 7/100
0s - loss: 0.4764 - val_loss: 0.4771
Epoch 8/100
0s - loss: 0.4735 - val_loss: 0.4746
Epoch 9/100
0s - loss: 0.4710 - val_loss: 0.4726
Epoch 10/100
0s - loss: 0.4684 - val_loss: 0.4695
Epoch 11/100
0s - loss: 0.4656 - val_loss: 0.4679
Epoch 12/100
0s - loss: 0.4632 - val_loss: 0.4662
Epoch 13/100
0s - loss: 0.4610 - val_loss: 0.4645
Epoch 14/100
0s - loss: 0.4589 - val_loss: 0.4631
Epoch 15/100
0s - loss: 0.4571 - val_loss: 0.4624
Epoch 16/100
0s - loss: 0.4554 - val_loss: 0.4616
Epoch 17/100
0s - loss: 0.4542 - val_loss: 0.4612
Epoch 18/100
0s - loss: 0.4530 - val_loss: 0.4605
Epoch 19/100
0s - loss: 0.4520 - val_loss: 0.4608
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:46,738 - 6_UsokinAE_350-250_50_relu|Fold #4 Loss = 0.460838
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.6124 - val_loss: 0.5502
Epoch 2/100
0s - loss: 0.5396 - val_loss: 0.5303
Epoch 3/100
0s - loss: 0.5221 - val_loss: 0.5146
Epoch 4/100
0s - loss: 0.5026 - val_loss: 0.4968
Epoch 5/100
0s - loss: 0.4854 - val_loss: 0.4868
Epoch 6/100
0s - loss: 0.4778 - val_loss: 0.4813
Epoch 7/100
0s - loss: 0.4745 - val_loss: 0.4788
Epoch 8/100
0s - loss: 0.4720 - val_loss: 0.4771
Epoch 9/100
0s - loss: 0.4692 - val_loss: 0.4748
Epoch 10/100
0s - loss: 0.4666 - val_loss: 0.4727
Epoch 11/100
0s - loss: 0.4642 - val_loss: 0.4715
Epoch 12/100
0s - loss: 0.4624 - val_loss: 0.4702
Epoch 13/100
0s - loss: 0.4608 - val_loss: 0.4692
Epoch 14/100
0s - loss: 0.4596 - val_loss: 0.4683
Epoch 15/100
0s - loss: 0.4578 - val_loss: 0.4675
Epoch 16/100
0s - loss: 0.4561 - val_loss: 0.4663
Epoch 17/100
0s - loss: 0.4547 - val_loss: 0.4656
Epoch 18/100
0s - loss: 0.4532 - val_loss: 0.4651
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:01:57,557 - 6_UsokinAE_350-250_50_relu|Fold #5 Loss = 0.465141
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.6206 - val_loss: 0.5472
Epoch 2/100
0s - loss: 0.5437 - val_loss: 0.5296
Epoch 3/100
0s - loss: 0.5274 - val_loss: 0.5103
Epoch 4/100
0s - loss: 0.5098 - val_loss: 0.4924
Epoch 5/100
0s - loss: 0.4929 - val_loss: 0.4763
Epoch 6/100
0s - loss: 0.4816 - val_loss: 0.4712
Epoch 7/100
0s - loss: 0.4771 - val_loss: 0.4694
Epoch 8/100
0s - loss: 0.4746 - val_loss: 0.4672
Epoch 9/100
0s - loss: 0.4723 - val_loss: 0.4654
Epoch 10/100
0s - loss: 0.4699 - val_loss: 0.4636
Epoch 11/100
0s - loss: 0.4672 - val_loss: 0.4619
Epoch 12/100
0s - loss: 0.4648 - val_loss: 0.4605
Epoch 13/100
0s - loss: 0.4632 - val_loss: 0.4591
Epoch 14/100
0s - loss: 0.4608 - val_loss: 0.4580
Epoch 15/100
0s - loss: 0.4591 - val_loss: 0.4561
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:02:06,742 - 6_UsokinAE_350-250_50_relu|Fold #6 Loss = 0.456070
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6202 - val_loss: 0.5587
Epoch 2/100
0s - loss: 0.5418 - val_loss: 0.5460
Epoch 3/100
0s - loss: 0.5254 - val_loss: 0.5292
Epoch 4/100
0s - loss: 0.5057 - val_loss: 0.5109
Epoch 5/100
0s - loss: 0.4892 - val_loss: 0.5010
Epoch 6/100
0s - loss: 0.4797 - val_loss: 0.4955
Epoch 7/100
0s - loss: 0.4748 - val_loss: 0.4934
Epoch 8/100
0s - loss: 0.4726 - val_loss: 0.4929
Epoch 9/100
0s - loss: 0.4704 - val_loss: 0.4902
Epoch 10/100
0s - loss: 0.4687 - val_loss: 0.4885
Epoch 11/100
0s - loss: 0.4668 - val_loss: 0.4873
Epoch 12/100
0s - loss: 0.4644 - val_loss: 0.4844
Epoch 13/100
0s - loss: 0.4619 - val_loss: 0.4830
Epoch 14/100
0s - loss: 0.4595 - val_loss: 0.4812
Epoch 15/100
0s - loss: 0.4576 - val_loss: 0.4808
Epoch 16/100
0s - loss: 0.4565 - val_loss: 0.4797
Epoch 17/100
0s - loss: 0.4546 - val_loss: 0.4786
Epoch 18/100
0s - loss: 0.4532 - val_loss: 0.4782
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:02:17,602 - 6_UsokinAE_350-250_50_relu|Fold #7 Loss = 0.478155
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6118 - val_loss: 0.5485
Epoch 2/100
0s - loss: 0.5434 - val_loss: 0.5328
Epoch 3/100
0s - loss: 0.5267 - val_loss: 0.5135
Epoch 4/100
0s - loss: 0.5063 - val_loss: 0.4935
Epoch 5/100
0s - loss: 0.4891 - val_loss: 0.4812
Epoch 6/100
0s - loss: 0.4804 - val_loss: 0.4758
Epoch 7/100
0s - loss: 0.4760 - val_loss: 0.4724
Epoch 8/100
0s - loss: 0.4729 - val_loss: 0.4694
Epoch 9/100
0s - loss: 0.4700 - val_loss: 0.4669
Epoch 10/100
0s - loss: 0.4674 - val_loss: 0.4649
Epoch 11/100
0s - loss: 0.4651 - val_loss: 0.4630
Epoch 12/100
0s - loss: 0.4629 - val_loss: 0.4618
Epoch 13/100
0s - loss: 0.4611 - val_loss: 0.4606
Epoch 14/100
0s - loss: 0.4592 - val_loss: 0.4598
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:02:26,368 - 6_UsokinAE_350-250_50_relu|Fold #8 Loss = 0.459829
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6114 - val_loss: 0.5469
Epoch 2/100
0s - loss: 0.5399 - val_loss: 0.5302
Epoch 3/100
0s - loss: 0.5221 - val_loss: 0.5138
Epoch 4/100
0s - loss: 0.5033 - val_loss: 0.4981
Epoch 5/100
0s - loss: 0.4871 - val_loss: 0.4881
Epoch 6/100
0s - loss: 0.4785 - val_loss: 0.4835
Epoch 7/100
0s - loss: 0.4749 - val_loss: 0.4824
Epoch 8/100
0s - loss: 0.4724 - val_loss: 0.4804
Epoch 9/100
0s - loss: 0.4699 - val_loss: 0.4785
Epoch 10/100
0s - loss: 0.4674 - val_loss: 0.4762
Epoch 11/100
0s - loss: 0.4650 - val_loss: 0.4751
Epoch 12/100
0s - loss: 0.4625 - val_loss: 0.4729
Epoch 13/100
0s - loss: 0.4605 - val_loss: 0.4721
Epoch 14/100
0s - loss: 0.4586 - val_loss: 0.4711
Epoch 15/100
0s - loss: 0.4567 - val_loss: 0.4698
Epoch 16/100
0s - loss: 0.4551 - val_loss: 0.4686
Epoch 17/100
0s - loss: 0.4539 - val_loss: 0.4678
Epoch 18/100
0s - loss: 0.4525 - val_loss: 0.4679
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:02:36,991 - 6_UsokinAE_350-250_50_relu|Fold #9 Loss = 0.467900
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.6142 - val_loss: 0.5524
Epoch 2/100
0s - loss: 0.5427 - val_loss: 0.5348
Epoch 3/100
0s - loss: 0.5278 - val_loss: 0.5203
Epoch 4/100
0s - loss: 0.5115 - val_loss: 0.5034
Epoch 5/100
0s - loss: 0.4949 - val_loss: 0.4907
Epoch 6/100
0s - loss: 0.4849 - val_loss: 0.4802
Epoch 7/100
0s - loss: 0.4784 - val_loss: 0.4753
Epoch 8/100
0s - loss: 0.4749 - val_loss: 0.4718
Epoch 9/100
0s - loss: 0.4719 - val_loss: 0.4688
Epoch 10/100
0s - loss: 0.4691 - val_loss: 0.4669
Epoch 11/100
0s - loss: 0.4665 - val_loss: 0.4651
Epoch 12/100
0s - loss: 0.4645 - val_loss: 0.4640
Epoch 13/100
0s - loss: 0.4628 - val_loss: 0.4632
Epoch 14/100
0s - loss: 0.4615 - val_loss: 0.4627
Epoch 15/100
0s - loss: 0.4607 - val_loss: 0.4619
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:02:46,175 - 6_UsokinAE_350-250_50_relu|Fold #10 Loss = 0.461860
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:02:46,175 - 6_UsokinAE_350-250_50_relu|Avg Validation Loss = 0.465166
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6782 - val_loss: 0.7185
Epoch 2/100
0s - loss: 0.6079 - val_loss: 0.7161
Epoch 3/100
0s - loss: 0.5273 - val_loss: 0.6597
Epoch 4/100
0s - loss: 0.4981 - val_loss: 0.7550
Epoch 5/100
0s - loss: 0.4833 - val_loss: 0.5993
Epoch 6/100
0s - loss: 0.4813 - val_loss: 0.5670
Epoch 7/100
0s - loss: 0.4803 - val_loss: 0.6699
Epoch 8/100
0s - loss: 0.4821 - val_loss: 0.5111
Epoch 9/100
0s - loss: 0.4826 - val_loss: 0.5249
Epoch 10/100
0s - loss: 0.4738 - val_loss: 0.5029
Epoch 11/100
0s - loss: 0.4728 - val_loss: 0.4965
Epoch 12/100
0s - loss: 0.4699 - val_loss: 0.4930
Epoch 13/100
0s - loss: 0.4754 - val_loss: 0.4905
Epoch 14/100
0s - loss: 0.4695 - val_loss: 0.4885
Epoch 15/100
0s - loss: 0.4662 - val_loss: 0.4806
Epoch 16/100
0s - loss: 0.4652 - val_loss: 0.4766
Epoch 17/100
0s - loss: 0.4642 - val_loss: 0.4751
Epoch 18/100
0s - loss: 0.4633 - val_loss: 0.4764
Epoch 19/100
0s - loss: 0.4628 - val_loss: 0.4746
Epoch 20/100
0s - loss: 0.4630 - val_loss: 0.4739
Epoch 21/100
0s - loss: 0.4631 - val_loss: 0.4754
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:03:02,929 - 7_UsokinAE_400-300_50_tanh_BN|Fold #1 Loss = 0.475394
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6804 - val_loss: 0.7209
Epoch 2/100
0s - loss: 0.6024 - val_loss: 0.6916
Epoch 3/100
0s - loss: 0.5203 - val_loss: 0.7150
Epoch 4/100
0s - loss: 0.4912 - val_loss: 0.6841
Epoch 5/100
0s - loss: 0.4825 - val_loss: 0.5875
Epoch 6/100
0s - loss: 0.4769 - val_loss: 0.5652
Epoch 7/100
0s - loss: 0.4734 - val_loss: 0.5270
Epoch 8/100
0s - loss: 0.4700 - val_loss: 0.5450
Epoch 9/100
0s - loss: 0.4681 - val_loss: 0.5126
Epoch 10/100
0s - loss: 0.4689 - val_loss: 0.5039
Epoch 11/100
0s - loss: 0.4654 - val_loss: 0.4919
Epoch 12/100
0s - loss: 0.4647 - val_loss: 0.4812
Epoch 13/100
0s - loss: 0.4621 - val_loss: 0.4809
Epoch 14/100
0s - loss: 0.4605 - val_loss: 0.4728
Epoch 15/100
0s - loss: 0.4573 - val_loss: 0.4683
Epoch 16/100
0s - loss: 0.4564 - val_loss: 0.4677
Epoch 17/100
0s - loss: 0.4558 - val_loss: 0.4659
Epoch 18/100
0s - loss: 0.4550 - val_loss: 0.4633
Epoch 19/100
0s - loss: 0.4544 - val_loss: 0.4627
Epoch 20/100
0s - loss: 0.4525 - val_loss: 0.4621
Epoch 21/100
0s - loss: 0.4520 - val_loss: 0.4618
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:03:19,792 - 7_UsokinAE_400-300_50_tanh_BN|Fold #2 Loss = 0.461813
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6799 - val_loss: 0.7215
Epoch 2/100
0s - loss: 0.6050 - val_loss: 0.7442
Epoch 3/100
0s - loss: 0.5184 - val_loss: 0.7619
Epoch 4/100
0s - loss: 0.4901 - val_loss: 0.6353
Epoch 5/100
0s - loss: 0.4804 - val_loss: 0.5963
Epoch 6/100
0s - loss: 0.4734 - val_loss: 0.5895
Epoch 7/100
0s - loss: 0.4686 - val_loss: 0.5341
Epoch 8/100
0s - loss: 0.4670 - val_loss: 0.5211
Epoch 9/100
0s - loss: 0.4635 - val_loss: 0.5024
Epoch 10/100
0s - loss: 0.4620 - val_loss: 0.5149
Epoch 11/100
0s - loss: 0.4595 - val_loss: 0.4935
Epoch 12/100
0s - loss: 0.4582 - val_loss: 0.4872
Epoch 13/100
0s - loss: 0.4576 - val_loss: 0.4859
Epoch 14/100
0s - loss: 0.4553 - val_loss: 0.4842
Epoch 15/100
0s - loss: 0.4543 - val_loss: 0.4823
Epoch 16/100
0s - loss: 0.4562 - val_loss: 0.4861
Epoch 17/100
0s - loss: 0.4544 - val_loss: 0.4805
Epoch 18/100
0s - loss: 0.4516 - val_loss: 0.4774
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:03:34,820 - 7_UsokinAE_400-300_50_tanh_BN|Fold #3 Loss = 0.477376
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6797 - val_loss: 0.7224
Epoch 2/100
0s - loss: 0.6010 - val_loss: 0.7217
Epoch 3/100
0s - loss: 0.5152 - val_loss: 0.6968
Epoch 4/100
0s - loss: 0.4884 - val_loss: 0.6003
Epoch 5/100
0s - loss: 0.4809 - val_loss: 0.5774
Epoch 6/100
0s - loss: 0.4711 - val_loss: 0.5362
Epoch 7/100
0s - loss: 0.4707 - val_loss: 0.5171
Epoch 8/100
0s - loss: 0.4671 - val_loss: 0.5109
Epoch 9/100
0s - loss: 0.4659 - val_loss: 0.4992
Epoch 10/100
0s - loss: 0.4625 - val_loss: 0.4919
Epoch 11/100
0s - loss: 0.4607 - val_loss: 0.4833
Epoch 12/100
0s - loss: 0.4582 - val_loss: 0.4818
Epoch 13/100
0s - loss: 0.4561 - val_loss: 0.4774
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4740
Epoch 15/100
0s - loss: 0.4557 - val_loss: 0.4729
Epoch 16/100
0s - loss: 0.4534 - val_loss: 0.4687
Epoch 17/100
0s - loss: 0.4527 - val_loss: 0.4690
Epoch 18/100
0s - loss: 0.4506 - val_loss: 0.4681
Epoch 19/100
0s - loss: 0.4495 - val_loss: 0.4660
Epoch 20/100
0s - loss: 0.4479 - val_loss: 0.4649
Epoch 21/100
0s - loss: 0.4476 - val_loss: 0.4648
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:03:51,849 - 7_UsokinAE_400-300_50_tanh_BN|Fold #4 Loss = 0.464769
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6760 - val_loss: 0.7188
Epoch 2/100
0s - loss: 0.5966 - val_loss: 0.7020
Epoch 3/100
0s - loss: 0.5179 - val_loss: 0.7264
Epoch 4/100
0s - loss: 0.4883 - val_loss: 0.5951
Epoch 5/100
0s - loss: 0.4803 - val_loss: 0.6295
Epoch 6/100
0s - loss: 0.4875 - val_loss: 0.5603
Epoch 7/100
0s - loss: 0.4773 - val_loss: 0.5597
Epoch 8/100
0s - loss: 0.4726 - val_loss: 0.5202
Epoch 9/100
0s - loss: 0.4688 - val_loss: 0.4994
Epoch 10/100
0s - loss: 0.4644 - val_loss: 0.4927
Epoch 11/100
0s - loss: 0.4630 - val_loss: 0.4848
Epoch 12/100
0s - loss: 0.4608 - val_loss: 0.4800
Epoch 13/100
0s - loss: 0.4591 - val_loss: 0.4785
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4750
Epoch 15/100
0s - loss: 0.4584 - val_loss: 0.4788
Epoch 16/100
0s - loss: 0.4559 - val_loss: 0.4733
Epoch 17/100
0s - loss: 0.4550 - val_loss: 0.4716
Epoch 18/100
0s - loss: 0.4548 - val_loss: 0.4717
Epoch 19/100
0s - loss: 0.4531 - val_loss: 0.4707
Epoch 20/100
0s - loss: 0.4506 - val_loss: 0.4683
Epoch 21/100
0s - loss: 0.4496 - val_loss: 0.4677
Epoch 22/100
0s - loss: 0.4476 - val_loss: 0.4665
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:04:09,295 - 7_UsokinAE_400-300_50_tanh_BN|Fold #5 Loss = 0.466468
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6792 - val_loss: 0.7133
Epoch 2/100
0s - loss: 0.6055 - val_loss: 0.7273
Epoch 3/100
0s - loss: 0.5258 - val_loss: 0.6894
Epoch 4/100
0s - loss: 0.4908 - val_loss: 0.6315
Epoch 5/100
0s - loss: 0.4856 - val_loss: 0.5446
Epoch 6/100
0s - loss: 0.4821 - val_loss: 0.5514
Epoch 7/100
0s - loss: 0.4790 - val_loss: 0.5221
Epoch 8/100
0s - loss: 0.4747 - val_loss: 0.5055
Epoch 9/100
0s - loss: 0.4752 - val_loss: 0.4955
Epoch 10/100
0s - loss: 0.4717 - val_loss: 0.5021
Epoch 11/100
0s - loss: 0.4689 - val_loss: 0.4830
Epoch 12/100
0s - loss: 0.4660 - val_loss: 0.4776
Epoch 13/100
0s - loss: 0.4646 - val_loss: 0.4753
Epoch 14/100
0s - loss: 0.4626 - val_loss: 0.4709
Epoch 15/100
0s - loss: 0.4691 - val_loss: 0.4699
Epoch 16/100
0s - loss: 0.4642 - val_loss: 0.4682
Epoch 17/100
0s - loss: 0.4621 - val_loss: 0.4675
Epoch 18/100
0s - loss: 0.4621 - val_loss: 0.4652
Epoch 19/100
0s - loss: 0.4592 - val_loss: 0.4617
Epoch 20/100
0s - loss: 0.4587 - val_loss: 0.4612
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:04:25,587 - 7_UsokinAE_400-300_50_tanh_BN|Fold #6 Loss = 0.461200
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6802 - val_loss: 0.7156
Epoch 2/100
0s - loss: 0.6007 - val_loss: 0.7162
Epoch 3/100
0s - loss: 0.5211 - val_loss: 0.7246
Epoch 4/100
0s - loss: 0.4869 - val_loss: 0.6476
Epoch 5/100
0s - loss: 0.4847 - val_loss: 0.5384
Epoch 6/100
0s - loss: 0.4717 - val_loss: 0.5753
Epoch 7/100
0s - loss: 0.4685 - val_loss: 0.5419
Epoch 8/100
0s - loss: 0.4641 - val_loss: 0.5204
Epoch 9/100
0s - loss: 0.4619 - val_loss: 0.5106
Epoch 10/100
0s - loss: 0.4626 - val_loss: 0.5038
Epoch 11/100
0s - loss: 0.4641 - val_loss: 0.5293
Epoch 12/100
0s - loss: 0.4595 - val_loss: 0.5034
Epoch 13/100
0s - loss: 0.4598 - val_loss: 0.5021
Epoch 14/100
0s - loss: 0.4599 - val_loss: 0.4980
Epoch 15/100
0s - loss: 0.4584 - val_loss: 0.4965
Epoch 16/100
0s - loss: 0.4566 - val_loss: 0.4926
Epoch 17/100
0s - loss: 0.4582 - val_loss: 0.4918
Epoch 18/100
0s - loss: 0.4574 - val_loss: 0.4896
Epoch 19/100
0s - loss: 0.4528 - val_loss: 0.4873
Epoch 20/100
0s - loss: 0.4545 - val_loss: 0.4862
Epoch 21/100
0s - loss: 0.4520 - val_loss: 0.4872
Epoch 22/100
0s - loss: 0.4491 - val_loss: 0.4853
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:04:42,941 - 7_UsokinAE_400-300_50_tanh_BN|Fold #7 Loss = 0.485261
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6825 - val_loss: 0.7191
Epoch 2/100
0s - loss: 0.6044 - val_loss: 0.7044
Epoch 3/100
0s - loss: 0.5215 - val_loss: 0.6240
Epoch 4/100
0s - loss: 0.4884 - val_loss: 0.6206
Epoch 5/100
0s - loss: 0.4833 - val_loss: 0.5814
Epoch 6/100
0s - loss: 0.4775 - val_loss: 0.5462
Epoch 7/100
0s - loss: 0.4714 - val_loss: 0.5250
Epoch 8/100
0s - loss: 0.4673 - val_loss: 0.5125
Epoch 9/100
0s - loss: 0.4673 - val_loss: 0.4909
Epoch 10/100
0s - loss: 0.4656 - val_loss: 0.4829
Epoch 11/100
0s - loss: 0.4644 - val_loss: 0.4787
Epoch 12/100
0s - loss: 0.4614 - val_loss: 0.4766
Epoch 13/100
0s - loss: 0.4590 - val_loss: 0.4733
Epoch 14/100
0s - loss: 0.4567 - val_loss: 0.4674
Epoch 15/100
0s - loss: 0.4548 - val_loss: 0.4654
Epoch 16/100
0s - loss: 0.4539 - val_loss: 0.4642
Epoch 17/100
0s - loss: 0.4539 - val_loss: 0.4629
Epoch 18/100
0s - loss: 0.4521 - val_loss: 0.4618
Epoch 19/100
0s - loss: 0.4516 - val_loss: 0.4592
Epoch 20/100
0s - loss: 0.4509 - val_loss: 0.4602
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:04:59,265 - 7_UsokinAE_400-300_50_tanh_BN|Fold #8 Loss = 0.460203
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6769 - val_loss: 0.7175
Epoch 2/100
0s - loss: 0.6012 - val_loss: 0.7178
Epoch 3/100
0s - loss: 0.5197 - val_loss: 0.8111
Epoch 4/100
0s - loss: 0.4841 - val_loss: 0.7477
Epoch 5/100
0s - loss: 0.4754 - val_loss: 0.6057
Epoch 6/100
0s - loss: 0.4725 - val_loss: 0.5486
Epoch 7/100
0s - loss: 0.4712 - val_loss: 0.5766
Epoch 8/100
0s - loss: 0.4671 - val_loss: 0.5115
Epoch 9/100
0s - loss: 0.4633 - val_loss: 0.5153
Epoch 10/100
0s - loss: 0.4604 - val_loss: 0.4924
Epoch 11/100
0s - loss: 0.4580 - val_loss: 0.4910
Epoch 12/100
0s - loss: 0.4588 - val_loss: 0.4864
Epoch 13/100
0s - loss: 0.4589 - val_loss: 0.4847
Epoch 14/100
0s - loss: 0.4597 - val_loss: 0.4859
Epoch 15/100
0s - loss: 0.4586 - val_loss: 0.4849
Epoch 16/100
0s - loss: 0.4562 - val_loss: 0.4816
Epoch 17/100
0s - loss: 0.4548 - val_loss: 0.4780
Epoch 18/100
0s - loss: 0.4546 - val_loss: 0.4751
Epoch 19/100
0s - loss: 0.4533 - val_loss: 0.4751
Epoch 20/100
0s - loss: 0.4503 - val_loss: 0.4733
Epoch 21/100
0s - loss: 0.4490 - val_loss: 0.4713
Epoch 22/100
0s - loss: 0.4489 - val_loss: 0.4720
Epoch 23/100
0s - loss: 0.4479 - val_loss: 0.4708
Epoch 24/100
0s - loss: 0.4458 - val_loss: 0.4710
Epoch 25/100
0s - loss: 0.4460 - val_loss: 0.4733
Epoch 26/100
0s - loss: 0.4454 - val_loss: 0.4728
Epoch 27/100
0s - loss: 0.4426 - val_loss: 0.4704
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:05:19,090 - 7_UsokinAE_400-300_50_tanh_BN|Fold #9 Loss = 0.470370
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6809 - val_loss: 0.7164
Epoch 2/100
0s - loss: 0.6054 - val_loss: 0.6828
Epoch 3/100
0s - loss: 0.5293 - val_loss: 0.6291
Epoch 4/100
0s - loss: 0.4882 - val_loss: 0.5938
Epoch 5/100
0s - loss: 0.4798 - val_loss: 0.5419
Epoch 6/100
0s - loss: 0.4760 - val_loss: 0.5358
Epoch 7/100
0s - loss: 0.4791 - val_loss: 0.5326
Epoch 8/100
0s - loss: 0.4734 - val_loss: 0.5477
Epoch 9/100
0s - loss: 0.4693 - val_loss: 0.5418
Epoch 10/100
0s - loss: 0.4694 - val_loss: 0.4908
Epoch 11/100
0s - loss: 0.4648 - val_loss: 0.4871
Epoch 12/100
0s - loss: 0.4630 - val_loss: 0.4799
Epoch 13/100
0s - loss: 0.4611 - val_loss: 0.4759
Epoch 14/100
0s - loss: 0.4641 - val_loss: 0.4719
Epoch 15/100
0s - loss: 0.4601 - val_loss: 0.4707
Epoch 16/100
0s - loss: 0.4572 - val_loss: 0.4650
Epoch 17/100
0s - loss: 0.4562 - val_loss: 0.4626
Epoch 18/100
0s - loss: 0.4540 - val_loss: 0.4611
Epoch 19/100
0s - loss: 0.4536 - val_loss: 0.4608
Epoch 20/100
0s - loss: 0.4522 - val_loss: 0.4594
Epoch 21/100
0s - loss: 0.4513 - val_loss: 0.4585
Epoch 22/100
0s - loss: 0.4499 - val_loss: 0.4583
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:05:36,597 - 7_UsokinAE_400-300_50_tanh_BN|Fold #10 Loss = 0.458270
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:05:36,597 - 7_UsokinAE_400-300_50_tanh_BN|Avg Validation Loss = 0.468112
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5885 - val_loss: 0.5329
Epoch 2/100
0s - loss: 0.5187 - val_loss: 0.4948
Epoch 3/100
0s - loss: 0.4903 - val_loss: 0.4810
Epoch 4/100
0s - loss: 0.4791 - val_loss: 0.4755
Epoch 5/100
0s - loss: 0.4734 - val_loss: 0.4713
Epoch 6/100
0s - loss: 0.4681 - val_loss: 0.4695
Epoch 7/100
0s - loss: 0.4645 - val_loss: 0.4657
Epoch 8/100
0s - loss: 0.4608 - val_loss: 0.4632
Epoch 9/100
0s - loss: 0.4585 - val_loss: 0.4681
Epoch 10/100
0s - loss: 0.4588 - val_loss: 0.4626
Epoch 11/100
0s - loss: 0.4548 - val_loss: 0.4609
Epoch 12/100
0s - loss: 0.4530 - val_loss: 0.4593
Epoch 13/100
0s - loss: 0.4509 - val_loss: 0.4590
Epoch 14/100
0s - loss: 0.4483 - val_loss: 0.4572
Epoch 15/100
0s - loss: 0.4464 - val_loss: 0.4570
Epoch 16/100
0s - loss: 0.4445 - val_loss: 0.4570
Epoch 17/100
0s - loss: 0.4426 - val_loss: 0.4551
Epoch 18/100
0s - loss: 0.4403 - val_loss: 0.4534
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:05:47,544 - 8_UsokinAE_400-250_100_elu|Fold #1 Loss = 0.453364
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5904 - val_loss: 0.5241
Epoch 2/100
0s - loss: 0.5143 - val_loss: 0.4942
Epoch 3/100
0s - loss: 0.4901 - val_loss: 0.4786
Epoch 4/100
0s - loss: 0.4783 - val_loss: 0.4714
Epoch 5/100
0s - loss: 0.4714 - val_loss: 0.4678
Epoch 6/100
0s - loss: 0.4665 - val_loss: 0.4643
Epoch 7/100
0s - loss: 0.4622 - val_loss: 0.4609
Epoch 8/100
0s - loss: 0.4587 - val_loss: 0.4588
Epoch 9/100
0s - loss: 0.4561 - val_loss: 0.4567
Epoch 10/100
0s - loss: 0.4537 - val_loss: 0.4560
Epoch 11/100
0s - loss: 0.4514 - val_loss: 0.4550
Epoch 12/100
0s - loss: 0.4487 - val_loss: 0.4538
Epoch 13/100
0s - loss: 0.4461 - val_loss: 0.4527
Epoch 14/100
0s - loss: 0.4436 - val_loss: 0.4515
Epoch 15/100
0s - loss: 0.4411 - val_loss: 0.4511
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:05:56,959 - 8_UsokinAE_400-250_100_elu|Fold #2 Loss = 0.451102
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5918 - val_loss: 0.5370
Epoch 2/100
0s - loss: 0.5171 - val_loss: 0.5047
Epoch 3/100
0s - loss: 0.4891 - val_loss: 0.4922
Epoch 4/100
0s - loss: 0.4780 - val_loss: 0.4851
Epoch 5/100
0s - loss: 0.4708 - val_loss: 0.4815
Epoch 6/100
0s - loss: 0.4659 - val_loss: 0.4772
Epoch 7/100
0s - loss: 0.4619 - val_loss: 0.4751
Epoch 8/100
0s - loss: 0.4586 - val_loss: 0.4730
Epoch 9/100
0s - loss: 0.4556 - val_loss: 0.4716
Epoch 10/100
0s - loss: 0.4526 - val_loss: 0.4693
Epoch 11/100
0s - loss: 0.4499 - val_loss: 0.4682
Epoch 12/100
0s - loss: 0.4477 - val_loss: 0.4677
Epoch 13/100
0s - loss: 0.4453 - val_loss: 0.4661
Epoch 14/100
0s - loss: 0.4428 - val_loss: 0.4654
Epoch 15/100
0s - loss: 0.4407 - val_loss: 0.4645
Epoch 16/100
0s - loss: 0.4383 - val_loss: 0.4638
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:06:06,970 - 8_UsokinAE_400-250_100_elu|Fold #3 Loss = 0.463804
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5839 - val_loss: 0.5246
Epoch 2/100
0s - loss: 0.5145 - val_loss: 0.4977
Epoch 3/100
0s - loss: 0.4897 - val_loss: 0.4789
Epoch 4/100
0s - loss: 0.4766 - val_loss: 0.4730
Epoch 5/100
0s - loss: 0.4707 - val_loss: 0.4685
Epoch 6/100
0s - loss: 0.4660 - val_loss: 0.4662
Epoch 7/100
0s - loss: 0.4618 - val_loss: 0.4626
Epoch 8/100
0s - loss: 0.4584 - val_loss: 0.4610
Epoch 9/100
0s - loss: 0.4555 - val_loss: 0.4591
Epoch 10/100
0s - loss: 0.4527 - val_loss: 0.4579
Epoch 11/100
0s - loss: 0.4504 - val_loss: 0.4575
Epoch 12/100
0s - loss: 0.4477 - val_loss: 0.4549
Epoch 13/100
0s - loss: 0.4450 - val_loss: 0.4546
Epoch 14/100
0s - loss: 0.4426 - val_loss: 0.4537
Epoch 15/100
0s - loss: 0.4402 - val_loss: 0.4517
Epoch 16/100
0s - loss: 0.4376 - val_loss: 0.4508
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:06:16,853 - 8_UsokinAE_400-250_100_elu|Fold #4 Loss = 0.450846
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5881 - val_loss: 0.5349
Epoch 2/100
0s - loss: 0.5170 - val_loss: 0.5000
Epoch 3/100
0s - loss: 0.4885 - val_loss: 0.4841
Epoch 4/100
0s - loss: 0.4765 - val_loss: 0.4775
Epoch 5/100
0s - loss: 0.4698 - val_loss: 0.4735
Epoch 6/100
0s - loss: 0.4649 - val_loss: 0.4700
Epoch 7/100
0s - loss: 0.4612 - val_loss: 0.4675
Epoch 8/100
0s - loss: 0.4580 - val_loss: 0.4656
Epoch 9/100
0s - loss: 0.4550 - val_loss: 0.4635
Epoch 10/100
0s - loss: 0.4522 - val_loss: 0.4624
Epoch 11/100
0s - loss: 0.4502 - val_loss: 0.4609
Epoch 12/100
0s - loss: 0.4473 - val_loss: 0.4596
Epoch 13/100
0s - loss: 0.4443 - val_loss: 0.4585
Epoch 14/100
0s - loss: 0.4418 - val_loss: 0.4582
Epoch 15/100
0s - loss: 0.4391 - val_loss: 0.4571
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:06:26,270 - 8_UsokinAE_400-250_100_elu|Fold #5 Loss = 0.457140
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5910 - val_loss: 0.5290
Epoch 2/100
0s - loss: 0.5192 - val_loss: 0.4939
Epoch 3/100
0s - loss: 0.4919 - val_loss: 0.4754
Epoch 4/100
0s - loss: 0.4794 - val_loss: 0.4684
Epoch 5/100
0s - loss: 0.4736 - val_loss: 0.4654
Epoch 6/100
0s - loss: 0.4695 - val_loss: 0.4621
Epoch 7/100
0s - loss: 0.4653 - val_loss: 0.4587
Epoch 8/100
0s - loss: 0.4614 - val_loss: 0.4561
Epoch 9/100
0s - loss: 0.4580 - val_loss: 0.4544
Epoch 10/100
0s - loss: 0.4556 - val_loss: 0.4533
Epoch 11/100
0s - loss: 0.4535 - val_loss: 0.4533
Epoch 12/100
0s - loss: 0.4514 - val_loss: 0.4509
Epoch 13/100
0s - loss: 0.4488 - val_loss: 0.4508
Epoch 14/100
0s - loss: 0.4468 - val_loss: 0.4501
Epoch 15/100
0s - loss: 0.4441 - val_loss: 0.4483
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:06:35,558 - 8_UsokinAE_400-250_100_elu|Fold #6 Loss = 0.448313
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5879 - val_loss: 0.5402
Epoch 2/100
0s - loss: 0.5117 - val_loss: 0.5094
Epoch 3/100
0s - loss: 0.4859 - val_loss: 0.4969
Epoch 4/100
0s - loss: 0.4750 - val_loss: 0.4914
Epoch 5/100
0s - loss: 0.4697 - val_loss: 0.4865
Epoch 6/100
0s - loss: 0.4652 - val_loss: 0.4833
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4795
Epoch 8/100
0s - loss: 0.4571 - val_loss: 0.4776
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4755
Epoch 10/100
0s - loss: 0.4508 - val_loss: 0.4743
Epoch 11/100
0s - loss: 0.4484 - val_loss: 0.4741
Epoch 12/100
0s - loss: 0.4458 - val_loss: 0.4725
Epoch 13/100
0s - loss: 0.4435 - val_loss: 0.4714
Epoch 14/100
0s - loss: 0.4413 - val_loss: 0.4707
Epoch 15/100
0s - loss: 0.4385 - val_loss: 0.4695
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:06:44,941 - 8_UsokinAE_400-250_100_elu|Fold #7 Loss = 0.469508
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5930 - val_loss: 0.5352
Epoch 2/100
0s - loss: 0.5207 - val_loss: 0.4999
Epoch 3/100
0s - loss: 0.4923 - val_loss: 0.4815
Epoch 4/100
0s - loss: 0.4796 - val_loss: 0.4729
Epoch 5/100
0s - loss: 0.4731 - val_loss: 0.4685
Epoch 6/100
0s - loss: 0.4682 - val_loss: 0.4636
Epoch 7/100
0s - loss: 0.4638 - val_loss: 0.4597
Epoch 8/100
0s - loss: 0.4598 - val_loss: 0.4566
Epoch 9/100
0s - loss: 0.4568 - val_loss: 0.4555
Epoch 10/100
0s - loss: 0.4548 - val_loss: 0.4537
Epoch 11/100
0s - loss: 0.4523 - val_loss: 0.4529
Epoch 12/100
0s - loss: 0.4500 - val_loss: 0.4517
Epoch 13/100
0s - loss: 0.4473 - val_loss: 0.4513
Epoch 14/100
0s - loss: 0.4454 - val_loss: 0.4496
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:06:53,849 - 8_UsokinAE_400-250_100_elu|Fold #8 Loss = 0.449627
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5877 - val_loss: 0.5349
Epoch 2/100
0s - loss: 0.5170 - val_loss: 0.5005
Epoch 3/100
0s - loss: 0.4886 - val_loss: 0.4860
Epoch 4/100
0s - loss: 0.4770 - val_loss: 0.4798
Epoch 5/100
0s - loss: 0.4705 - val_loss: 0.4758
Epoch 6/100
0s - loss: 0.4662 - val_loss: 0.4727
Epoch 7/100
0s - loss: 0.4621 - val_loss: 0.4702
Epoch 8/100
0s - loss: 0.4586 - val_loss: 0.4685
Epoch 9/100
0s - loss: 0.4555 - val_loss: 0.4663
Epoch 10/100
0s - loss: 0.4527 - val_loss: 0.4656
Epoch 11/100
0s - loss: 0.4504 - val_loss: 0.4641
Epoch 12/100
0s - loss: 0.4479 - val_loss: 0.4630
Epoch 13/100
0s - loss: 0.4453 - val_loss: 0.4622
Epoch 14/100
0s - loss: 0.4427 - val_loss: 0.4613
Epoch 15/100
0s - loss: 0.4402 - val_loss: 0.4606
Epoch 16/100
0s - loss: 0.4382 - val_loss: 0.4601
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:03,925 - 8_UsokinAE_400-250_100_elu|Fold #9 Loss = 0.460126
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5858 - val_loss: 0.5361
Epoch 2/100
0s - loss: 0.5192 - val_loss: 0.5006
Epoch 3/100
0s - loss: 0.4905 - val_loss: 0.4782
Epoch 4/100
0s - loss: 0.4775 - val_loss: 0.4704
Epoch 5/100
0s - loss: 0.4710 - val_loss: 0.4658
Epoch 6/100
0s - loss: 0.4660 - val_loss: 0.4627
Epoch 7/100
0s - loss: 0.4621 - val_loss: 0.4600
Epoch 8/100
0s - loss: 0.4590 - val_loss: 0.4577
Epoch 9/100
0s - loss: 0.4563 - val_loss: 0.4563
Epoch 10/100
0s - loss: 0.4537 - val_loss: 0.4540
Epoch 11/100
0s - loss: 0.4511 - val_loss: 0.4543
Epoch 12/100
0s - loss: 0.4490 - val_loss: 0.4520
Epoch 13/100
0s - loss: 0.4464 - val_loss: 0.4512
Epoch 14/100
0s - loss: 0.4440 - val_loss: 0.4502
Epoch 15/100
0s - loss: 0.4414 - val_loss: 0.4490
Epoch 16/100
0s - loss: 0.4390 - val_loss: 0.4483
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:13,762 - 8_UsokinAE_400-250_100_elu|Fold #10 Loss = 0.448334
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:13,762 - 8_UsokinAE_400-250_100_elu|Avg Validation Loss = 0.455216
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5957 - val_loss: 0.5399
Epoch 2/100
0s - loss: 0.5377 - val_loss: 0.5242
Epoch 3/100
0s - loss: 0.5194 - val_loss: 0.5041
Epoch 4/100
0s - loss: 0.5001 - val_loss: 0.4881
Epoch 5/100
0s - loss: 0.4860 - val_loss: 0.4802
Epoch 6/100
0s - loss: 0.4802 - val_loss: 0.4776
Epoch 7/100
0s - loss: 0.4777 - val_loss: 0.4766
Epoch 8/100
0s - loss: 0.4758 - val_loss: 0.4738
Epoch 9/100
0s - loss: 0.4725 - val_loss: 0.4721
Epoch 10/100
0s - loss: 0.4699 - val_loss: 0.4709
Epoch 11/100
0s - loss: 0.4675 - val_loss: 0.4700
Epoch 12/100
0s - loss: 0.4656 - val_loss: 0.4685
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:21,650 - 9_UsokinAE_450-250_100_tanh|Fold #1 Loss = 0.468468
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5915 - val_loss: 0.5355
Epoch 2/100
0s - loss: 0.5342 - val_loss: 0.5164
Epoch 3/100
0s - loss: 0.5126 - val_loss: 0.4972
Epoch 4/100
0s - loss: 0.4938 - val_loss: 0.4812
Epoch 5/100
0s - loss: 0.4823 - val_loss: 0.4764
Epoch 6/100
0s - loss: 0.4771 - val_loss: 0.4723
Epoch 7/100
0s - loss: 0.4737 - val_loss: 0.4687
Epoch 8/100
0s - loss: 0.4697 - val_loss: 0.4661
Epoch 9/100
0s - loss: 0.4669 - val_loss: 0.4643
Epoch 10/100
0s - loss: 0.4647 - val_loss: 0.4634
Epoch 11/100
0s - loss: 0.4631 - val_loss: 0.4616
Epoch 12/100
0s - loss: 0.4607 - val_loss: 0.4596
Epoch 13/100
0s - loss: 0.4583 - val_loss: 0.4588
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:30,016 - 9_UsokinAE_450-250_100_tanh|Fold #2 Loss = 0.458761
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5944 - val_loss: 0.5457
Epoch 2/100
0s - loss: 0.5334 - val_loss: 0.5261
Epoch 3/100
0s - loss: 0.5107 - val_loss: 0.5057
Epoch 4/100
0s - loss: 0.4904 - val_loss: 0.4929
Epoch 5/100
0s - loss: 0.4793 - val_loss: 0.4889
Epoch 6/100
0s - loss: 0.4752 - val_loss: 0.4848
Epoch 7/100
0s - loss: 0.4718 - val_loss: 0.4823
Epoch 8/100
0s - loss: 0.4694 - val_loss: 0.4805
Epoch 9/100
0s - loss: 0.4671 - val_loss: 0.4791
Epoch 10/100
0s - loss: 0.4646 - val_loss: 0.4771
Epoch 11/100
0s - loss: 0.4621 - val_loss: 0.4753
Epoch 12/100
0s - loss: 0.4595 - val_loss: 0.4732
Epoch 13/100
0s - loss: 0.4573 - val_loss: 0.4715
Epoch 14/100
0s - loss: 0.4554 - val_loss: 0.4706
Epoch 15/100
0s - loss: 0.4540 - val_loss: 0.4700
Epoch 16/100
0s - loss: 0.4524 - val_loss: 0.4697
Epoch 17/100
0s - loss: 0.4512 - val_loss: 0.4686
Epoch 18/100
0s - loss: 0.4499 - val_loss: 0.4699
Epoch 19/100
0s - loss: 0.4491 - val_loss: 0.4684
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:41,668 - 9_UsokinAE_450-250_100_tanh|Fold #3 Loss = 0.468426
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5872 - val_loss: 0.5371
Epoch 2/100
0s - loss: 0.5345 - val_loss: 0.5193
Epoch 3/100
0s - loss: 0.5109 - val_loss: 0.4945
Epoch 4/100
0s - loss: 0.4882 - val_loss: 0.4801
Epoch 5/100
0s - loss: 0.4793 - val_loss: 0.4769
Epoch 6/100
0s - loss: 0.4762 - val_loss: 0.4745
Epoch 7/100
0s - loss: 0.4733 - val_loss: 0.4734
Epoch 8/100
0s - loss: 0.4708 - val_loss: 0.4707
Epoch 9/100
0s - loss: 0.4683 - val_loss: 0.4683
Epoch 10/100
0s - loss: 0.4656 - val_loss: 0.4674
Epoch 11/100
0s - loss: 0.4640 - val_loss: 0.4649
Epoch 12/100
0s - loss: 0.4615 - val_loss: 0.4629
Epoch 13/100
0s - loss: 0.4588 - val_loss: 0.4608
Epoch 14/100
0s - loss: 0.4564 - val_loss: 0.4600
Epoch 15/100
0s - loss: 0.4552 - val_loss: 0.4594
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:51,289 - 9_UsokinAE_450-250_100_tanh|Fold #4 Loss = 0.459393
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5841 - val_loss: 0.5394
Epoch 2/100
0s - loss: 0.5274 - val_loss: 0.5171
Epoch 3/100
0s - loss: 0.5047 - val_loss: 0.4973
Epoch 4/100
0s - loss: 0.4877 - val_loss: 0.4869
Epoch 5/100
0s - loss: 0.4798 - val_loss: 0.4807
Epoch 6/100
0s - loss: 0.4749 - val_loss: 0.4775
Epoch 7/100
0s - loss: 0.4721 - val_loss: 0.4750
Epoch 8/100
0s - loss: 0.4687 - val_loss: 0.4730
Epoch 9/100
0s - loss: 0.4660 - val_loss: 0.4713
Epoch 10/100
0s - loss: 0.4638 - val_loss: 0.4699
Epoch 11/100
0s - loss: 0.4618 - val_loss: 0.4679
Epoch 12/100
0s - loss: 0.4596 - val_loss: 0.4662
Epoch 13/100
0s - loss: 0.4578 - val_loss: 0.4659
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:07:59,816 - 9_UsokinAE_450-250_100_tanh|Fold #5 Loss = 0.465935
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5348
Epoch 2/100
0s - loss: 0.5320 - val_loss: 0.5111
Epoch 3/100
0s - loss: 0.5086 - val_loss: 0.4895
Epoch 4/100
0s - loss: 0.4903 - val_loss: 0.4752
Epoch 5/100
0s - loss: 0.4812 - val_loss: 0.4720
Epoch 6/100
0s - loss: 0.4767 - val_loss: 0.4675
Epoch 7/100
0s - loss: 0.4735 - val_loss: 0.4659
Epoch 8/100
0s - loss: 0.4709 - val_loss: 0.4645
Epoch 9/100
0s - loss: 0.4683 - val_loss: 0.4619
Epoch 10/100
0s - loss: 0.4662 - val_loss: 0.4610
Epoch 11/100
0s - loss: 0.4645 - val_loss: 0.4592
Epoch 12/100
0s - loss: 0.4620 - val_loss: 0.4569
Epoch 13/100
0s - loss: 0.4602 - val_loss: 0.4562
Epoch 14/100
0s - loss: 0.4591 - val_loss: 0.4560
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:08,906 - 9_UsokinAE_450-250_100_tanh|Fold #6 Loss = 0.455950
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5904 - val_loss: 0.5554
Epoch 2/100
0s - loss: 0.5356 - val_loss: 0.5370
Epoch 3/100
0s - loss: 0.5110 - val_loss: 0.5108
Epoch 4/100
0s - loss: 0.4909 - val_loss: 0.5000
Epoch 5/100
0s - loss: 0.4800 - val_loss: 0.4955
Epoch 6/100
0s - loss: 0.4752 - val_loss: 0.4924
Epoch 7/100
0s - loss: 0.4716 - val_loss: 0.4885
Epoch 8/100
0s - loss: 0.4681 - val_loss: 0.4862
Epoch 9/100
0s - loss: 0.4654 - val_loss: 0.4837
Epoch 10/100
0s - loss: 0.4627 - val_loss: 0.4823
Epoch 11/100
0s - loss: 0.4608 - val_loss: 0.4807
Epoch 12/100
0s - loss: 0.4587 - val_loss: 0.4796
Epoch 13/100
0s - loss: 0.4568 - val_loss: 0.4787
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:17,532 - 9_UsokinAE_450-250_100_tanh|Fold #7 Loss = 0.478664
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5924 - val_loss: 0.5341
Epoch 2/100
0s - loss: 0.5298 - val_loss: 0.5123
Epoch 3/100
0s - loss: 0.5078 - val_loss: 0.4934
Epoch 4/100
0s - loss: 0.4907 - val_loss: 0.4816
Epoch 5/100
0s - loss: 0.4815 - val_loss: 0.4728
Epoch 6/100
0s - loss: 0.4768 - val_loss: 0.4700
Epoch 7/100
0s - loss: 0.4733 - val_loss: 0.4664
Epoch 8/100
0s - loss: 0.4703 - val_loss: 0.4636
Epoch 9/100
0s - loss: 0.4671 - val_loss: 0.4612
Epoch 10/100
0s - loss: 0.4646 - val_loss: 0.4588
Epoch 11/100
0s - loss: 0.4621 - val_loss: 0.4571
Epoch 12/100
0s - loss: 0.4603 - val_loss: 0.4560
Epoch 13/100
0s - loss: 0.4584 - val_loss: 0.4553
Epoch 14/100
0s - loss: 0.4568 - val_loss: 0.4539
Epoch 15/100
0s - loss: 0.4551 - val_loss: 0.4531
Epoch 16/100
0s - loss: 0.4536 - val_loss: 0.4522
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:27,720 - 9_UsokinAE_450-250_100_tanh|Fold #8 Loss = 0.452187
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5917 - val_loss: 0.5434
Epoch 2/100
0s - loss: 0.5373 - val_loss: 0.5280
Epoch 3/100
0s - loss: 0.5156 - val_loss: 0.5029
Epoch 4/100
0s - loss: 0.4908 - val_loss: 0.4874
Epoch 5/100
0s - loss: 0.4804 - val_loss: 0.4826
Epoch 6/100
0s - loss: 0.4756 - val_loss: 0.4806
Epoch 7/100
0s - loss: 0.4741 - val_loss: 0.4791
Epoch 8/100
0s - loss: 0.4700 - val_loss: 0.4762
Epoch 9/100
0s - loss: 0.4670 - val_loss: 0.4738
Epoch 10/100
0s - loss: 0.4640 - val_loss: 0.4718
Epoch 11/100
0s - loss: 0.4618 - val_loss: 0.4706
Epoch 12/100
0s - loss: 0.4597 - val_loss: 0.4697
Epoch 13/100
0s - loss: 0.4578 - val_loss: 0.4688
Epoch 14/100
0s - loss: 0.4564 - val_loss: 0.4681
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:36,807 - 9_UsokinAE_450-250_100_tanh|Fold #9 Loss = 0.468084
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5859 - val_loss: 0.5423
Epoch 2/100
0s - loss: 0.5356 - val_loss: 0.5246
Epoch 3/100
0s - loss: 0.5150 - val_loss: 0.5028
Epoch 4/100
0s - loss: 0.4947 - val_loss: 0.4845
Epoch 5/100
0s - loss: 0.4814 - val_loss: 0.4744
Epoch 6/100
0s - loss: 0.4757 - val_loss: 0.4702
Epoch 7/100
0s - loss: 0.4719 - val_loss: 0.4677
Epoch 8/100
0s - loss: 0.4689 - val_loss: 0.4655
Epoch 9/100
0s - loss: 0.4668 - val_loss: 0.4636
Epoch 10/100
0s - loss: 0.4643 - val_loss: 0.4619
Epoch 11/100
0s - loss: 0.4622 - val_loss: 0.4598
Epoch 12/100
0s - loss: 0.4604 - val_loss: 0.4595
Epoch 13/100
0s - loss: 0.4585 - val_loss: 0.4575
Epoch 14/100
0s - loss: 0.4568 - val_loss: 0.4567
Epoch 15/100
0s - loss: 0.4553 - val_loss: 0.4557
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:46,482 - 9_UsokinAE_450-250_100_tanh|Fold #10 Loss = 0.455732
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:46,483 - 9_UsokinAE_450-250_100_tanh|Avg Validation Loss = 0.463160
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5987 - val_loss: 0.5384
Epoch 2/100
0s - loss: 0.5378 - val_loss: 0.5283
Epoch 3/100
0s - loss: 0.5216 - val_loss: 0.5063
Epoch 4/100
0s - loss: 0.5025 - val_loss: 0.4929
Epoch 5/100
0s - loss: 0.4919 - val_loss: 0.4848
Epoch 6/100
0s - loss: 0.4851 - val_loss: 0.4803
Epoch 7/100
0s - loss: 0.4808 - val_loss: 0.4785
Epoch 8/100
0s - loss: 0.4779 - val_loss: 0.4770
Epoch 9/100
0s - loss: 0.4759 - val_loss: 0.4772
Epoch 10/100
0s - loss: 0.4752 - val_loss: 0.4749
Epoch 11/100
0s - loss: 0.4724 - val_loss: 0.4739
Epoch 12/100
0s - loss: 0.4703 - val_loss: 0.4722
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:08:54,237 - 10_UsokinAE_350-300_50_tanh|Fold #1 Loss = 0.472166
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6003 - val_loss: 0.5358
Epoch 2/100
0s - loss: 0.5377 - val_loss: 0.5244
Epoch 3/100
0s - loss: 0.5231 - val_loss: 0.5099
Epoch 4/100
0s - loss: 0.5098 - val_loss: 0.4966
Epoch 5/100
0s - loss: 0.4937 - val_loss: 0.4814
Epoch 6/100
0s - loss: 0.4823 - val_loss: 0.4761
Epoch 7/100
0s - loss: 0.4785 - val_loss: 0.4750
Epoch 8/100
0s - loss: 0.4764 - val_loss: 0.4730
Epoch 9/100
0s - loss: 0.4746 - val_loss: 0.4704
Epoch 10/100
0s - loss: 0.4726 - val_loss: 0.4689
Epoch 11/100
0s - loss: 0.4706 - val_loss: 0.4675
Epoch 12/100
0s - loss: 0.4689 - val_loss: 0.4662
Epoch 13/100
0s - loss: 0.4672 - val_loss: 0.4649
Epoch 14/100
0s - loss: 0.4655 - val_loss: 0.4643
Epoch 15/100
0s - loss: 0.4641 - val_loss: 0.4623
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:03,576 - 10_UsokinAE_350-300_50_tanh|Fold #2 Loss = 0.462261
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5973 - val_loss: 0.5481
Epoch 2/100
0s - loss: 0.5381 - val_loss: 0.5355
Epoch 3/100
0s - loss: 0.5218 - val_loss: 0.5159
Epoch 4/100
0s - loss: 0.5025 - val_loss: 0.5037
Epoch 5/100
0s - loss: 0.4934 - val_loss: 0.4989
Epoch 6/100
0s - loss: 0.4873 - val_loss: 0.4932
Epoch 7/100
0s - loss: 0.4804 - val_loss: 0.4882
Epoch 8/100
0s - loss: 0.4753 - val_loss: 0.4849
Epoch 9/100
0s - loss: 0.4720 - val_loss: 0.4835
Epoch 10/100
0s - loss: 0.4699 - val_loss: 0.4817
Epoch 11/100
0s - loss: 0.4674 - val_loss: 0.4792
Epoch 12/100
0s - loss: 0.4652 - val_loss: 0.4780
Epoch 13/100
0s - loss: 0.4636 - val_loss: 0.4782
Epoch 14/100
0s - loss: 0.4623 - val_loss: 0.4757
Epoch 15/100
0s - loss: 0.4605 - val_loss: 0.4749
Epoch 16/100
0s - loss: 0.4587 - val_loss: 0.4738
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:13,229 - 10_UsokinAE_350-300_50_tanh|Fold #3 Loss = 0.473759
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6004 - val_loss: 0.5385
Epoch 2/100
0s - loss: 0.5351 - val_loss: 0.5209
Epoch 3/100
0s - loss: 0.5185 - val_loss: 0.5096
Epoch 4/100
0s - loss: 0.5056 - val_loss: 0.4947
Epoch 5/100
0s - loss: 0.4898 - val_loss: 0.4830
Epoch 6/100
0s - loss: 0.4813 - val_loss: 0.4795
Epoch 7/100
0s - loss: 0.4785 - val_loss: 0.4767
Epoch 8/100
0s - loss: 0.4754 - val_loss: 0.4753
Epoch 9/100
0s - loss: 0.4732 - val_loss: 0.4747
Epoch 10/100
0s - loss: 0.4716 - val_loss: 0.4731
Epoch 11/100
0s - loss: 0.4702 - val_loss: 0.4726
Epoch 12/100
0s - loss: 0.4689 - val_loss: 0.4712
Epoch 13/100
0s - loss: 0.4677 - val_loss: 0.4700
Epoch 14/100
0s - loss: 0.4666 - val_loss: 0.4694
Epoch 15/100
0s - loss: 0.4649 - val_loss: 0.4676
Epoch 16/100
0s - loss: 0.4633 - val_loss: 0.4665
Epoch 17/100
0s - loss: 0.4617 - val_loss: 0.4651
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:23,421 - 10_UsokinAE_350-300_50_tanh|Fold #4 Loss = 0.465146
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5977 - val_loss: 0.5446
Epoch 2/100
0s - loss: 0.5395 - val_loss: 0.5359
Epoch 3/100
0s - loss: 0.5279 - val_loss: 0.5200
Epoch 4/100
0s - loss: 0.5112 - val_loss: 0.5063
Epoch 5/100
0s - loss: 0.4986 - val_loss: 0.4962
Epoch 6/100
0s - loss: 0.4892 - val_loss: 0.4880
Epoch 7/100
0s - loss: 0.4814 - val_loss: 0.4818
Epoch 8/100
0s - loss: 0.4770 - val_loss: 0.4818
Epoch 9/100
0s - loss: 0.4744 - val_loss: 0.4788
Epoch 10/100
0s - loss: 0.4722 - val_loss: 0.4762
Epoch 11/100
0s - loss: 0.4701 - val_loss: 0.4752
Epoch 12/100
0s - loss: 0.4686 - val_loss: 0.4744
Epoch 13/100
0s - loss: 0.4673 - val_loss: 0.4728
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:31,531 - 10_UsokinAE_350-300_50_tanh|Fold #5 Loss = 0.472813
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.6053 - val_loss: 0.5376
Epoch 2/100
0s - loss: 0.5379 - val_loss: 0.5227
Epoch 3/100
0s - loss: 0.5222 - val_loss: 0.5051
Epoch 4/100
0s - loss: 0.5059 - val_loss: 0.4880
Epoch 5/100
0s - loss: 0.4907 - val_loss: 0.4788
Epoch 6/100
0s - loss: 0.4827 - val_loss: 0.4713
Epoch 7/100
0s - loss: 0.4779 - val_loss: 0.4687
Epoch 8/100
0s - loss: 0.4752 - val_loss: 0.4664
Epoch 9/100
0s - loss: 0.4731 - val_loss: 0.4649
Epoch 10/100
0s - loss: 0.4705 - val_loss: 0.4633
Epoch 11/100
0s - loss: 0.4688 - val_loss: 0.4623
Epoch 12/100
0s - loss: 0.4673 - val_loss: 0.4615
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:39,244 - 10_UsokinAE_350-300_50_tanh|Fold #6 Loss = 0.461480
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6005 - val_loss: 0.5545
Epoch 2/100
0s - loss: 0.5358 - val_loss: 0.5419
Epoch 3/100
0s - loss: 0.5201 - val_loss: 0.5243
Epoch 4/100
0s - loss: 0.5055 - val_loss: 0.5119
Epoch 5/100
0s - loss: 0.4952 - val_loss: 0.5061
Epoch 6/100
0s - loss: 0.4876 - val_loss: 0.4994
Epoch 7/100
0s - loss: 0.4795 - val_loss: 0.4952
Epoch 8/100
0s - loss: 0.4747 - val_loss: 0.4919
Epoch 9/100
0s - loss: 0.4718 - val_loss: 0.4901
Epoch 10/100
0s - loss: 0.4698 - val_loss: 0.4884
Epoch 11/100
0s - loss: 0.4682 - val_loss: 0.4869
Epoch 12/100
0s - loss: 0.4664 - val_loss: 0.4854
Epoch 13/100
0s - loss: 0.4644 - val_loss: 0.4836
Epoch 14/100
0s - loss: 0.4625 - val_loss: 0.4821
Epoch 15/100
0s - loss: 0.4605 - val_loss: 0.4811
Epoch 16/100
0s - loss: 0.4591 - val_loss: 0.4808
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:49,085 - 10_UsokinAE_350-300_50_tanh|Fold #7 Loss = 0.480777
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5980 - val_loss: 0.5355
Epoch 2/100
0s - loss: 0.5356 - val_loss: 0.5197
Epoch 3/100
0s - loss: 0.5128 - val_loss: 0.4984
Epoch 4/100
0s - loss: 0.4970 - val_loss: 0.4879
Epoch 5/100
0s - loss: 0.4882 - val_loss: 0.4796
Epoch 6/100
0s - loss: 0.4811 - val_loss: 0.4733
Epoch 7/100
0s - loss: 0.4777 - val_loss: 0.4717
Epoch 8/100
0s - loss: 0.4751 - val_loss: 0.4677
Epoch 9/100
0s - loss: 0.4726 - val_loss: 0.4660
Epoch 10/100
0s - loss: 0.4704 - val_loss: 0.4641
Epoch 11/100
0s - loss: 0.4682 - val_loss: 0.4622
Epoch 12/100
0s - loss: 0.4663 - val_loss: 0.4610
Epoch 13/100
0s - loss: 0.4646 - val_loss: 0.4593
Epoch 14/100
0s - loss: 0.4627 - val_loss: 0.4583
Epoch 15/100
0s - loss: 0.4610 - val_loss: 0.4569
Epoch 16/100
0s - loss: 0.4592 - val_loss: 0.4560
Epoch 17/100
0s - loss: 0.4578 - val_loss: 0.4547
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:09:59,468 - 10_UsokinAE_350-300_50_tanh|Fold #8 Loss = 0.454703
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6013 - val_loss: 0.5388
Epoch 2/100
0s - loss: 0.5269 - val_loss: 0.5174
Epoch 3/100
0s - loss: 0.5054 - val_loss: 0.4995
Epoch 4/100
0s - loss: 0.4896 - val_loss: 0.4883
Epoch 5/100
0s - loss: 0.4811 - val_loss: 0.4836
Epoch 6/100
0s - loss: 0.4766 - val_loss: 0.4811
Epoch 7/100
0s - loss: 0.4737 - val_loss: 0.4795
Epoch 8/100
0s - loss: 0.4713 - val_loss: 0.4777
Epoch 9/100
0s - loss: 0.4688 - val_loss: 0.4758
Epoch 10/100
0s - loss: 0.4668 - val_loss: 0.4745
Epoch 11/100
0s - loss: 0.4651 - val_loss: 0.4733
Epoch 12/100
0s - loss: 0.4636 - val_loss: 0.4725
Epoch 13/100
0s - loss: 0.4622 - val_loss: 0.4715
Epoch 14/100
0s - loss: 0.4603 - val_loss: 0.4700
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:08,292 - 10_UsokinAE_350-300_50_tanh|Fold #9 Loss = 0.469995
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5994 - val_loss: 0.5408
Epoch 2/100
0s - loss: 0.5325 - val_loss: 0.5222
Epoch 3/100
0s - loss: 0.5149 - val_loss: 0.5059
Epoch 4/100
0s - loss: 0.4992 - val_loss: 0.4903
Epoch 5/100
0s - loss: 0.4861 - val_loss: 0.4786
Epoch 6/100
0s - loss: 0.4799 - val_loss: 0.4735
Epoch 7/100
0s - loss: 0.4765 - val_loss: 0.4715
Epoch 8/100
0s - loss: 0.4739 - val_loss: 0.4686
Epoch 9/100
0s - loss: 0.4715 - val_loss: 0.4673
Epoch 10/100
0s - loss: 0.4695 - val_loss: 0.4657
Epoch 11/100
0s - loss: 0.4673 - val_loss: 0.4644
Epoch 12/100
0s - loss: 0.4655 - val_loss: 0.4629
Epoch 13/100
0s - loss: 0.4642 - val_loss: 0.4629
Epoch 14/100
0s - loss: 0.4635 - val_loss: 0.4613
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:17,076 - 10_UsokinAE_350-300_50_tanh|Fold #10 Loss = 0.461333
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:17,076 - 10_UsokinAE_350-300_50_tanh|Avg Validation Loss = 0.467443
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5919 - val_loss: 0.5265
Epoch 2/100
0s - loss: 0.5172 - val_loss: 0.4977
Epoch 3/100
0s - loss: 0.4928 - val_loss: 0.4832
Epoch 4/100
0s - loss: 0.4806 - val_loss: 0.4766
Epoch 5/100
0s - loss: 0.4733 - val_loss: 0.4728
Epoch 6/100
0s - loss: 0.4685 - val_loss: 0.4699
Epoch 7/100
0s - loss: 0.4648 - val_loss: 0.4673
Epoch 8/100
0s - loss: 0.4618 - val_loss: 0.4656
Epoch 9/100
0s - loss: 0.4593 - val_loss: 0.4660
Epoch 10/100
0s - loss: 0.4575 - val_loss: 0.4617
Epoch 11/100
0s - loss: 0.4539 - val_loss: 0.4599
Epoch 12/100
0s - loss: 0.4520 - val_loss: 0.4589
Epoch 13/100
0s - loss: 0.4493 - val_loss: 0.4576
Epoch 14/100
0s - loss: 0.4471 - val_loss: 0.4571
Epoch 15/100
0s - loss: 0.4452 - val_loss: 0.4560
Epoch 16/100
0s - loss: 0.4431 - val_loss: 0.4562
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:26,973 - 11_UsokinAE_350-250_200_elu|Fold #1 Loss = 0.456183
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5938 - val_loss: 0.5263
Epoch 2/100
0s - loss: 0.5174 - val_loss: 0.4970
Epoch 3/100
0s - loss: 0.4920 - val_loss: 0.4788
Epoch 4/100
0s - loss: 0.4786 - val_loss: 0.4733
Epoch 5/100
0s - loss: 0.4722 - val_loss: 0.4677
Epoch 6/100
0s - loss: 0.4667 - val_loss: 0.4644
Epoch 7/100
0s - loss: 0.4620 - val_loss: 0.4609
Epoch 8/100
0s - loss: 0.4586 - val_loss: 0.4588
Epoch 9/100
0s - loss: 0.4558 - val_loss: 0.4584
Epoch 10/100
0s - loss: 0.4532 - val_loss: 0.4556
Epoch 11/100
0s - loss: 0.4501 - val_loss: 0.4548
Epoch 12/100
0s - loss: 0.4475 - val_loss: 0.4538
Epoch 13/100
0s - loss: 0.4451 - val_loss: 0.4529
Epoch 14/100
0s - loss: 0.4424 - val_loss: 0.4511
Epoch 15/100
0s - loss: 0.4395 - val_loss: 0.4506
Epoch 16/100
0s - loss: 0.4367 - val_loss: 0.4504
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:36,908 - 11_UsokinAE_350-250_200_elu|Fold #2 Loss = 0.450426
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5896 - val_loss: 0.5360
Epoch 2/100
0s - loss: 0.5159 - val_loss: 0.5066
Epoch 3/100
0s - loss: 0.4903 - val_loss: 0.4915
Epoch 4/100
0s - loss: 0.4770 - val_loss: 0.4853
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4804
Epoch 6/100
0s - loss: 0.4653 - val_loss: 0.4774
Epoch 7/100
0s - loss: 0.4610 - val_loss: 0.4742
Epoch 8/100
0s - loss: 0.4572 - val_loss: 0.4714
Epoch 9/100
0s - loss: 0.4537 - val_loss: 0.4699
Epoch 10/100
0s - loss: 0.4509 - val_loss: 0.4692
Epoch 11/100
0s - loss: 0.4485 - val_loss: 0.4674
Epoch 12/100
0s - loss: 0.4457 - val_loss: 0.4661
Epoch 13/100
0s - loss: 0.4431 - val_loss: 0.4657
Epoch 14/100
0s - loss: 0.4406 - val_loss: 0.4650
Epoch 15/100
0s - loss: 0.4383 - val_loss: 0.4631
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:46,439 - 11_UsokinAE_350-250_200_elu|Fold #3 Loss = 0.463085
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5866 - val_loss: 0.5311
Epoch 2/100
0s - loss: 0.5179 - val_loss: 0.4966
Epoch 3/100
0s - loss: 0.4883 - val_loss: 0.4790
Epoch 4/100
0s - loss: 0.4764 - val_loss: 0.4741
Epoch 5/100
0s - loss: 0.4710 - val_loss: 0.4701
Epoch 6/100
0s - loss: 0.4660 - val_loss: 0.4664
Epoch 7/100
0s - loss: 0.4619 - val_loss: 0.4633
Epoch 8/100
0s - loss: 0.4584 - val_loss: 0.4611
Epoch 9/100
0s - loss: 0.4556 - val_loss: 0.4599
Epoch 10/100
0s - loss: 0.4527 - val_loss: 0.4576
Epoch 11/100
0s - loss: 0.4501 - val_loss: 0.4560
Epoch 12/100
0s - loss: 0.4474 - val_loss: 0.4553
Epoch 13/100
0s - loss: 0.4448 - val_loss: 0.4534
Epoch 14/100
0s - loss: 0.4421 - val_loss: 0.4524
Epoch 15/100
0s - loss: 0.4396 - val_loss: 0.4529
Epoch 16/100
0s - loss: 0.4375 - val_loss: 0.4507
Epoch 17/100
0s - loss: 0.4348 - val_loss: 0.4502
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:10:57,001 - 11_UsokinAE_350-250_200_elu|Fold #4 Loss = 0.450245
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5908 - val_loss: 0.5373
Epoch 2/100
0s - loss: 0.5196 - val_loss: 0.5028
Epoch 3/100
0s - loss: 0.4905 - val_loss: 0.4847
Epoch 4/100
0s - loss: 0.4781 - val_loss: 0.4783
Epoch 5/100
0s - loss: 0.4711 - val_loss: 0.4746
Epoch 6/100
0s - loss: 0.4662 - val_loss: 0.4714
Epoch 7/100
0s - loss: 0.4622 - val_loss: 0.4681
Epoch 8/100
0s - loss: 0.4589 - val_loss: 0.4657
Epoch 9/100
0s - loss: 0.4556 - val_loss: 0.4631
Epoch 10/100
0s - loss: 0.4523 - val_loss: 0.4619
Epoch 11/100
0s - loss: 0.4493 - val_loss: 0.4607
Epoch 12/100
0s - loss: 0.4469 - val_loss: 0.4595
Epoch 13/100
0s - loss: 0.4441 - val_loss: 0.4587
Epoch 14/100
0s - loss: 0.4412 - val_loss: 0.4582
Epoch 15/100
0s - loss: 0.4387 - val_loss: 0.4565
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:06,464 - 11_UsokinAE_350-250_200_elu|Fold #5 Loss = 0.456526
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5884 - val_loss: 0.5292
Epoch 2/100
0s - loss: 0.5195 - val_loss: 0.4943
Epoch 3/100
0s - loss: 0.4916 - val_loss: 0.4772
Epoch 4/100
0s - loss: 0.4803 - val_loss: 0.4679
Epoch 5/100
0s - loss: 0.4727 - val_loss: 0.4656
Epoch 6/100
0s - loss: 0.4675 - val_loss: 0.4618
Epoch 7/100
0s - loss: 0.4637 - val_loss: 0.4584
Epoch 8/100
0s - loss: 0.4602 - val_loss: 0.4565
Epoch 9/100
0s - loss: 0.4574 - val_loss: 0.4546
Epoch 10/100
0s - loss: 0.4547 - val_loss: 0.4535
Epoch 11/100
0s - loss: 0.4529 - val_loss: 0.4526
Epoch 12/100
0s - loss: 0.4501 - val_loss: 0.4510
Epoch 13/100
0s - loss: 0.4476 - val_loss: 0.4495
Epoch 14/100
0s - loss: 0.4452 - val_loss: 0.4491
Epoch 15/100
0s - loss: 0.4424 - val_loss: 0.4486
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:15,960 - 11_UsokinAE_350-250_200_elu|Fold #6 Loss = 0.448604
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5854 - val_loss: 0.5447
Epoch 2/100
0s - loss: 0.5165 - val_loss: 0.5125
Epoch 3/100
0s - loss: 0.4891 - val_loss: 0.4975
Epoch 4/100
0s - loss: 0.4763 - val_loss: 0.4912
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4866
Epoch 6/100
0s - loss: 0.4648 - val_loss: 0.4826
Epoch 7/100
0s - loss: 0.4604 - val_loss: 0.4804
Epoch 8/100
0s - loss: 0.4571 - val_loss: 0.4779
Epoch 9/100
0s - loss: 0.4539 - val_loss: 0.4764
Epoch 10/100
0s - loss: 0.4514 - val_loss: 0.4755
Epoch 11/100
0s - loss: 0.4491 - val_loss: 0.4737
Epoch 12/100
0s - loss: 0.4464 - val_loss: 0.4732
Epoch 13/100
0s - loss: 0.4440 - val_loss: 0.4713
Epoch 14/100
0s - loss: 0.4411 - val_loss: 0.4706
Epoch 15/100
0s - loss: 0.4385 - val_loss: 0.4710
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:25,425 - 11_UsokinAE_350-250_200_elu|Fold #7 Loss = 0.471042
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5874 - val_loss: 0.5287
Epoch 2/100
0s - loss: 0.5145 - val_loss: 0.4914
Epoch 3/100
0s - loss: 0.4869 - val_loss: 0.4758
Epoch 4/100
0s - loss: 0.4762 - val_loss: 0.4692
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4640
Epoch 6/100
0s - loss: 0.4652 - val_loss: 0.4601
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4584
Epoch 8/100
0s - loss: 0.4577 - val_loss: 0.4558
Epoch 9/100
0s - loss: 0.4544 - val_loss: 0.4542
Epoch 10/100
0s - loss: 0.4518 - val_loss: 0.4529
Epoch 11/100
0s - loss: 0.4491 - val_loss: 0.4524
Epoch 12/100
0s - loss: 0.4470 - val_loss: 0.4509
Epoch 13/100
0s - loss: 0.4442 - val_loss: 0.4493
Epoch 14/100
0s - loss: 0.4408 - val_loss: 0.4487
Epoch 15/100
0s - loss: 0.4380 - val_loss: 0.4485
Epoch 16/100
0s - loss: 0.4352 - val_loss: 0.4459
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:35,376 - 11_UsokinAE_350-250_200_elu|Fold #8 Loss = 0.445856
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5901 - val_loss: 0.5342
Epoch 2/100
0s - loss: 0.5171 - val_loss: 0.5030
Epoch 3/100
0s - loss: 0.4891 - val_loss: 0.4875
Epoch 4/100
0s - loss: 0.4761 - val_loss: 0.4811
Epoch 5/100
0s - loss: 0.4697 - val_loss: 0.4762
Epoch 6/100
0s - loss: 0.4651 - val_loss: 0.4723
Epoch 7/100
0s - loss: 0.4607 - val_loss: 0.4699
Epoch 8/100
0s - loss: 0.4570 - val_loss: 0.4678
Epoch 9/100
0s - loss: 0.4538 - val_loss: 0.4669
Epoch 10/100
0s - loss: 0.4508 - val_loss: 0.4653
Epoch 11/100
0s - loss: 0.4477 - val_loss: 0.4636
Epoch 12/100
0s - loss: 0.4453 - val_loss: 0.4640
Epoch 13/100
0s - loss: 0.4427 - val_loss: 0.4618
Epoch 14/100
0s - loss: 0.4399 - val_loss: 0.4610
Epoch 15/100
0s - loss: 0.4371 - val_loss: 0.4594
Epoch 16/100
0s - loss: 0.4341 - val_loss: 0.4585
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:45,387 - 11_UsokinAE_350-250_200_elu|Fold #9 Loss = 0.458472
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5865 - val_loss: 0.5331
Epoch 2/100
0s - loss: 0.5169 - val_loss: 0.5004
Epoch 3/100
0s - loss: 0.4910 - val_loss: 0.4800
Epoch 4/100
0s - loss: 0.4772 - val_loss: 0.4703
Epoch 5/100
0s - loss: 0.4703 - val_loss: 0.4654
Epoch 6/100
0s - loss: 0.4651 - val_loss: 0.4616
Epoch 7/100
0s - loss: 0.4611 - val_loss: 0.4597
Epoch 8/100
0s - loss: 0.4578 - val_loss: 0.4572
Epoch 9/100
0s - loss: 0.4546 - val_loss: 0.4551
Epoch 10/100
0s - loss: 0.4513 - val_loss: 0.4537
Epoch 11/100
0s - loss: 0.4485 - val_loss: 0.4516
Epoch 12/100
0s - loss: 0.4456 - val_loss: 0.4510
Epoch 13/100
0s - loss: 0.4429 - val_loss: 0.4504
Epoch 14/100
0s - loss: 0.4405 - val_loss: 0.4483
Epoch 15/100
0s - loss: 0.4371 - val_loss: 0.4476
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:54,949 - 11_UsokinAE_350-250_200_elu|Fold #10 Loss = 0.447592
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:11:54,950 - 11_UsokinAE_350-250_200_elu|Avg Validation Loss = 0.454803
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5901 - val_loss: 0.5326
Epoch 2/100
0s - loss: 0.5180 - val_loss: 0.4969
Epoch 3/100
0s - loss: 0.4902 - val_loss: 0.4798
Epoch 4/100
0s - loss: 0.4778 - val_loss: 0.4747
Epoch 5/100
0s - loss: 0.4716 - val_loss: 0.4701
Epoch 6/100
0s - loss: 0.4666 - val_loss: 0.4680
Epoch 7/100
0s - loss: 0.4625 - val_loss: 0.4651
Epoch 8/100
0s - loss: 0.4594 - val_loss: 0.4635
Epoch 9/100
0s - loss: 0.4568 - val_loss: 0.4621
Epoch 10/100
0s - loss: 0.4551 - val_loss: 0.4612
Epoch 11/100
0s - loss: 0.4524 - val_loss: 0.4602
Epoch 12/100
0s - loss: 0.4504 - val_loss: 0.4604
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:12:02,924 - 12_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.460386
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5838 - val_loss: 0.5310
Epoch 2/100
0s - loss: 0.5168 - val_loss: 0.4928
Epoch 3/100
0s - loss: 0.4870 - val_loss: 0.4769
Epoch 4/100
0s - loss: 0.4765 - val_loss: 0.4708
Epoch 5/100
0s - loss: 0.4698 - val_loss: 0.4659
Epoch 6/100
0s - loss: 0.4650 - val_loss: 0.4632
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4601
Epoch 8/100
0s - loss: 0.4571 - val_loss: 0.4577
Epoch 9/100
0s - loss: 0.4541 - val_loss: 0.4557
Epoch 10/100
0s - loss: 0.4511 - val_loss: 0.4546
Epoch 11/100
0s - loss: 0.4482 - val_loss: 0.4534
Epoch 12/100
0s - loss: 0.4453 - val_loss: 0.4519
Epoch 13/100
0s - loss: 0.4421 - val_loss: 0.4507
Epoch 14/100
0s - loss: 0.4389 - val_loss: 0.4495
Epoch 15/100
0s - loss: 0.4358 - val_loss: 0.4486
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:12:12,491 - 12_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.448558
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5872 - val_loss: 0.5346
Epoch 2/100
0s - loss: 0.5136 - val_loss: 0.5030
Epoch 3/100
0s - loss: 0.4859 - val_loss: 0.4893
Epoch 4/100
0s - loss: 0.4752 - val_loss: 0.4839
Epoch 5/100
0s - loss: 0.4689 - val_loss: 0.4789
Epoch 6/100
0s - loss: 0.4640 - val_loss: 0.4754
Epoch 7/100
0s - loss: 0.4595 - val_loss: 0.4734
Epoch 8/100
0s - loss: 0.4563 - val_loss: 0.4706
Epoch 9/100
0s - loss: 0.4530 - val_loss: 0.4694
Epoch 10/100
0s - loss: 0.4503 - val_loss: 0.4683
Epoch 11/100
0s - loss: 0.4475 - val_loss: 0.4658
Epoch 12/100
0s - loss: 0.4443 - val_loss: 0.4652
Epoch 13/100
0s - loss: 0.4416 - val_loss: 0.4640
Epoch 14/100
0s - loss: 0.4391 - val_loss: 0.4647
Epoch 15/100
0s - loss: 0.4368 - val_loss: 0.4628
Epoch 16/100
0s - loss: 0.4332 - val_loss: 0.4624
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:12:22,756 - 12_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.462412
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5843 - val_loss: 0.5301
Epoch 2/100
0s - loss: 0.5158 - val_loss: 0.4957
Epoch 3/100
0s - loss: 0.4878 - val_loss: 0.4786
Epoch 4/100
0s - loss: 0.4756 - val_loss: 0.4722
Epoch 5/100
0s - loss: 0.4684 - val_loss: 0.4671
Epoch 6/100
0s - loss: 0.4629 - val_loss: 0.4638
Epoch 7/100
0s - loss: 0.4591 - val_loss: 0.4609
Epoch 8/100
0s - loss: 0.4557 - val_loss: 0.4592
Epoch 9/100
0s - loss: 0.4527 - val_loss: 0.4571
Epoch 10/100
0s - loss: 0.4499 - val_loss: 0.4563
Epoch 11/100
0s - loss: 0.4475 - val_loss: 0.4557
Epoch 12/100
0s - loss: 0.4448 - val_loss: 0.4537
Epoch 13/100
0s - loss: 0.4417 - val_loss: 0.4525
Epoch 14/100
0s - loss: 0.4388 - val_loss: 0.4513
Epoch 15/100
0s - loss: 0.4355 - val_loss: 0.4504
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:12:32,713 - 12_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.450387
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5864 - val_loss: 0.5297
Epoch 2/100
0s - loss: 0.5102 - val_loss: 0.4972
Epoch 3/100
0s - loss: 0.4838 - val_loss: 0.4827
Epoch 4/100
0s - loss: 0.4745 - val_loss: 0.4771
Epoch 5/100
0s - loss: 0.4683 - val_loss: 0.4723
Epoch 6/100
0s - loss: 0.4631 - val_loss: 0.4697
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4663
Epoch 8/100
0s - loss: 0.4554 - val_loss: 0.4642
Epoch 9/100
0s - loss: 0.4522 - val_loss: 0.4628
Epoch 10/100
0s - loss: 0.4490 - val_loss: 0.4606
Epoch 11/100
0s - loss: 0.4458 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4428 - val_loss: 0.4580
Epoch 13/100
0s - loss: 0.4397 - val_loss: 0.4575
Epoch 14/100
0s - loss: 0.4366 - val_loss: 0.4564
Epoch 15/100
0s - loss: 0.4343 - val_loss: 0.4557
Epoch 16/100
0s - loss: 0.4313 - val_loss: 0.4543
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:12:43,290 - 12_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.454343
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5858 - val_loss: 0.5217
Epoch 2/100
0s - loss: 0.5095 - val_loss: 0.4854
Epoch 3/100
0s - loss: 0.4863 - val_loss: 0.4727
Epoch 4/100
0s - loss: 0.4767 - val_loss: 0.4676
Epoch 5/100
0s - loss: 0.4704 - val_loss: 0.4622
Epoch 6/100
0s - loss: 0.4655 - val_loss: 0.4588
Epoch 7/100
0s - loss: 0.4615 - val_loss: 0.4569
Epoch 8/100
0s - loss: 0.4583 - val_loss: 0.4542
Epoch 9/100
0s - loss: 0.4552 - val_loss: 0.4527
Epoch 10/100
0s - loss: 0.4522 - val_loss: 0.4511
Epoch 11/100
0s - loss: 0.4494 - val_loss: 0.4503
Epoch 12/100
0s - loss: 0.4465 - val_loss: 0.4489
Epoch 13/100
0s - loss: 0.4446 - val_loss: 0.4492
Epoch 14/100
0s - loss: 0.4424 - val_loss: 0.4476
Epoch 15/100
0s - loss: 0.4389 - val_loss: 0.4462
Epoch 16/100
0s - loss: 0.4363 - val_loss: 0.4452
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:12:53,751 - 12_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.445200
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5860 - val_loss: 0.5445
Epoch 2/100
0s - loss: 0.5130 - val_loss: 0.5109
Epoch 3/100
0s - loss: 0.4857 - val_loss: 0.4985
Epoch 4/100
0s - loss: 0.4751 - val_loss: 0.4909
Epoch 5/100
0s - loss: 0.4689 - val_loss: 0.4865
Epoch 6/100
0s - loss: 0.4640 - val_loss: 0.4836
Epoch 7/100
0s - loss: 0.4604 - val_loss: 0.4798
Epoch 8/100
0s - loss: 0.4567 - val_loss: 0.4781
Epoch 9/100
0s - loss: 0.4535 - val_loss: 0.4760
Epoch 10/100
0s - loss: 0.4509 - val_loss: 0.4748
Epoch 11/100
0s - loss: 0.4479 - val_loss: 0.4748
Epoch 12/100
0s - loss: 0.4457 - val_loss: 0.4727
Epoch 13/100
0s - loss: 0.4426 - val_loss: 0.4721
Epoch 14/100
0s - loss: 0.4396 - val_loss: 0.4711
Epoch 15/100
0s - loss: 0.4368 - val_loss: 0.4694
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:13:03,430 - 12_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.469353
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5853 - val_loss: 0.5280
Epoch 2/100
0s - loss: 0.5127 - val_loss: 0.4916
Epoch 3/100
0s - loss: 0.4859 - val_loss: 0.4758
Epoch 4/100
0s - loss: 0.4767 - val_loss: 0.4699
Epoch 5/100
0s - loss: 0.4711 - val_loss: 0.4646
Epoch 6/100
0s - loss: 0.4656 - val_loss: 0.4609
Epoch 7/100
0s - loss: 0.4617 - val_loss: 0.4594
Epoch 8/100
0s - loss: 0.4588 - val_loss: 0.4559
Epoch 9/100
0s - loss: 0.4550 - val_loss: 0.4543
Epoch 10/100
0s - loss: 0.4519 - val_loss: 0.4523
Epoch 11/100
0s - loss: 0.4493 - val_loss: 0.4519
Epoch 12/100
0s - loss: 0.4465 - val_loss: 0.4491
Epoch 13/100
0s - loss: 0.4436 - val_loss: 0.4491
Epoch 14/100
0s - loss: 0.4406 - val_loss: 0.4474
Epoch 15/100
0s - loss: 0.4379 - val_loss: 0.4466
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:13:13,125 - 12_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.446607
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5852 - val_loss: 0.5322
Epoch 2/100
0s - loss: 0.5116 - val_loss: 0.4956
Epoch 3/100
0s - loss: 0.4839 - val_loss: 0.4841
Epoch 4/100
0s - loss: 0.4741 - val_loss: 0.4782
Epoch 5/100
0s - loss: 0.4682 - val_loss: 0.4750
Epoch 6/100
0s - loss: 0.4637 - val_loss: 0.4715
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4686
Epoch 8/100
0s - loss: 0.4555 - val_loss: 0.4665
Epoch 9/100
0s - loss: 0.4522 - val_loss: 0.4650
Epoch 10/100
0s - loss: 0.4499 - val_loss: 0.4638
Epoch 11/100
0s - loss: 0.4469 - val_loss: 0.4625
Epoch 12/100
0s - loss: 0.4441 - val_loss: 0.4615
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:13:21,332 - 12_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.461481
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5847 - val_loss: 0.5303
Epoch 2/100
0s - loss: 0.5147 - val_loss: 0.4971
Epoch 3/100
0s - loss: 0.4883 - val_loss: 0.4767
Epoch 4/100
0s - loss: 0.4769 - val_loss: 0.4707
Epoch 5/100
0s - loss: 0.4694 - val_loss: 0.4645
Epoch 6/100
0s - loss: 0.4640 - val_loss: 0.4603
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4575
Epoch 8/100
0s - loss: 0.4566 - val_loss: 0.4557
Epoch 9/100
0s - loss: 0.4539 - val_loss: 0.4543
Epoch 10/100
0s - loss: 0.4511 - val_loss: 0.4522
Epoch 11/100
0s - loss: 0.4484 - val_loss: 0.4512
Epoch 12/100
0s - loss: 0.4456 - val_loss: 0.4499
Epoch 13/100
0s - loss: 0.4431 - val_loss: 0.4491
Epoch 14/100
0s - loss: 0.4404 - val_loss: 0.4476
Epoch 15/100
0s - loss: 0.4373 - val_loss: 0.4470
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:13:31,247 - 12_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.447031
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:13:31,248 - 12_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.454576
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6136 - val_loss: 0.6378
Epoch 2/100
0s - loss: 0.5028 - val_loss: 0.6264
Epoch 3/100
0s - loss: 0.4787 - val_loss: 0.6116
Epoch 4/100
0s - loss: 0.4688 - val_loss: 0.5977
Epoch 5/100
0s - loss: 0.4636 - val_loss: 0.5809
Epoch 6/100
0s - loss: 0.4595 - val_loss: 0.5709
Epoch 7/100
0s - loss: 0.4557 - val_loss: 0.5597
Epoch 8/100
0s - loss: 0.4539 - val_loss: 0.5431
Epoch 9/100
0s - loss: 0.4528 - val_loss: 0.5330
Epoch 10/100
0s - loss: 0.4506 - val_loss: 0.5309
Epoch 11/100
0s - loss: 0.4481 - val_loss: 0.5241
Epoch 12/100
0s - loss: 0.4463 - val_loss: 0.5126
Epoch 13/100
0s - loss: 0.4446 - val_loss: 0.5070
Epoch 14/100
0s - loss: 0.4441 - val_loss: 0.4978
Epoch 15/100
0s - loss: 0.4426 - val_loss: 0.4941
Epoch 16/100
0s - loss: 0.4416 - val_loss: 0.4897
Epoch 17/100
0s - loss: 0.4393 - val_loss: 0.4859
Epoch 18/100
0s - loss: 0.4365 - val_loss: 0.4843
Epoch 19/100
0s - loss: 0.4353 - val_loss: 0.4799
Epoch 20/100
0s - loss: 0.4345 - val_loss: 0.4808
Epoch 21/100
0s - loss: 0.4340 - val_loss: 0.4772
Epoch 22/100
0s - loss: 0.4305 - val_loss: 0.4764
Epoch 23/100
0s - loss: 0.4301 - val_loss: 0.4727
Epoch 24/100
0s - loss: 0.4281 - val_loss: 0.4712
Epoch 25/100
0s - loss: 0.4278 - val_loss: 0.4732
Epoch 26/100
0s - loss: 0.4270 - val_loss: 0.4753
Epoch 27/100
0s - loss: 0.4261 - val_loss: 0.4754
Epoch 28/100
0s - loss: 0.4244 - val_loss: 0.4763
Epoch 29/100
0s - loss: 0.4230 - val_loss: 0.4767
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:13:53,346 - 13_UsokinAE_450-300_200_relu_BN|Fold #1 Loss = 0.476694
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6148 - val_loss: 0.6401
Epoch 2/100
0s - loss: 0.5024 - val_loss: 0.6237
Epoch 3/100
0s - loss: 0.4769 - val_loss: 0.6110
Epoch 4/100
0s - loss: 0.4664 - val_loss: 0.5985
Epoch 5/100
0s - loss: 0.4583 - val_loss: 0.5846
Epoch 6/100
0s - loss: 0.4531 - val_loss: 0.5671
Epoch 7/100
0s - loss: 0.4481 - val_loss: 0.5540
Epoch 8/100
0s - loss: 0.4442 - val_loss: 0.5412
Epoch 9/100
0s - loss: 0.4414 - val_loss: 0.5323
Epoch 10/100
0s - loss: 0.4370 - val_loss: 0.5166
Epoch 11/100
0s - loss: 0.4332 - val_loss: 0.5067
Epoch 12/100
0s - loss: 0.4311 - val_loss: 0.4966
Epoch 13/100
0s - loss: 0.4276 - val_loss: 0.4890
Epoch 14/100
0s - loss: 0.4252 - val_loss: 0.4805
Epoch 15/100
0s - loss: 0.4220 - val_loss: 0.4769
Epoch 16/100
0s - loss: 0.4188 - val_loss: 0.4749
Epoch 17/100
0s - loss: 0.4159 - val_loss: 0.4713
Epoch 18/100
0s - loss: 0.4128 - val_loss: 0.4665
Epoch 19/100
0s - loss: 0.4107 - val_loss: 0.4652
Epoch 20/100
0s - loss: 0.4090 - val_loss: 0.4628
Epoch 21/100
0s - loss: 0.4063 - val_loss: 0.4659
Epoch 22/100
0s - loss: 0.4034 - val_loss: 0.4618
Epoch 23/100
0s - loss: 0.4014 - val_loss: 0.4624
Epoch 24/100
0s - loss: 0.3992 - val_loss: 0.4616
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:14:13,066 - 13_UsokinAE_450-300_200_relu_BN|Fold #2 Loss = 0.461580
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6164 - val_loss: 0.6427
Epoch 2/100
0s - loss: 0.5003 - val_loss: 0.6278
Epoch 3/100
0s - loss: 0.4757 - val_loss: 0.6178
Epoch 4/100
0s - loss: 0.4648 - val_loss: 0.6016
Epoch 5/100
0s - loss: 0.4572 - val_loss: 0.5919
Epoch 6/100
0s - loss: 0.4517 - val_loss: 0.5737
Epoch 7/100
0s - loss: 0.4471 - val_loss: 0.5590
Epoch 8/100
0s - loss: 0.4451 - val_loss: 0.5487
Epoch 9/100
0s - loss: 0.4401 - val_loss: 0.5328
Epoch 10/100
0s - loss: 0.4364 - val_loss: 0.5267
Epoch 11/100
0s - loss: 0.4327 - val_loss: 0.5129
Epoch 12/100
0s - loss: 0.4290 - val_loss: 0.5077
Epoch 13/100
0s - loss: 0.4264 - val_loss: 0.5018
Epoch 14/100
0s - loss: 0.4245 - val_loss: 0.4979
Epoch 15/100
0s - loss: 0.4219 - val_loss: 0.4895
Epoch 16/100
0s - loss: 0.4201 - val_loss: 0.4907
Epoch 17/100
0s - loss: 0.4162 - val_loss: 0.4862
Epoch 18/100
0s - loss: 0.4135 - val_loss: 0.4836
Epoch 19/100
0s - loss: 0.4114 - val_loss: 0.4784
Epoch 20/100
0s - loss: 0.4096 - val_loss: 0.4817
Epoch 21/100
0s - loss: 0.4072 - val_loss: 0.4800
Epoch 22/100
0s - loss: 0.4053 - val_loss: 0.4782
Epoch 23/100
0s - loss: 0.4013 - val_loss: 0.4762
Epoch 24/100
0s - loss: 0.3991 - val_loss: 0.4770
Epoch 25/100
0s - loss: 0.3973 - val_loss: 0.4757
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:14:33,294 - 13_UsokinAE_450-300_200_relu_BN|Fold #3 Loss = 0.475679
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6184 - val_loss: 0.6462
Epoch 2/100
0s - loss: 0.5036 - val_loss: 0.6345
Epoch 3/100
0s - loss: 0.4781 - val_loss: 0.6190
Epoch 4/100
0s - loss: 0.4663 - val_loss: 0.6037
Epoch 5/100
0s - loss: 0.4588 - val_loss: 0.5851
Epoch 6/100
0s - loss: 0.4530 - val_loss: 0.5722
Epoch 7/100
0s - loss: 0.4485 - val_loss: 0.5554
Epoch 8/100
0s - loss: 0.4447 - val_loss: 0.5392
Epoch 9/100
0s - loss: 0.4410 - val_loss: 0.5306
Epoch 10/100
0s - loss: 0.4376 - val_loss: 0.5209
Epoch 11/100
0s - loss: 0.4335 - val_loss: 0.5070
Epoch 12/100
0s - loss: 0.4308 - val_loss: 0.5000
Epoch 13/100
0s - loss: 0.4282 - val_loss: 0.4926
Epoch 14/100
0s - loss: 0.4252 - val_loss: 0.4879
Epoch 15/100
0s - loss: 0.4222 - val_loss: 0.4844
Epoch 16/100
0s - loss: 0.4183 - val_loss: 0.4764
Epoch 17/100
0s - loss: 0.4163 - val_loss: 0.4735
Epoch 18/100
0s - loss: 0.4142 - val_loss: 0.4718
Epoch 19/100
0s - loss: 0.4114 - val_loss: 0.4677
Epoch 20/100
0s - loss: 0.4088 - val_loss: 0.4669
Epoch 21/100
0s - loss: 0.4070 - val_loss: 0.4656
Epoch 22/100
0s - loss: 0.4045 - val_loss: 0.4651
Epoch 23/100
0s - loss: 0.4022 - val_loss: 0.4661
Epoch 24/100
0s - loss: 0.3997 - val_loss: 0.4644
Epoch 25/100
0s - loss: 0.3982 - val_loss: 0.4669
Epoch 26/100
0s - loss: 0.3967 - val_loss: 0.4668
Epoch 27/100
0s - loss: 0.3958 - val_loss: 0.4673
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:14:54,637 - 13_UsokinAE_450-300_200_relu_BN|Fold #4 Loss = 0.467346
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6145 - val_loss: 0.6423
Epoch 2/100
0s - loss: 0.5002 - val_loss: 0.6263
Epoch 3/100
0s - loss: 0.4767 - val_loss: 0.6113
Epoch 4/100
0s - loss: 0.4652 - val_loss: 0.5977
Epoch 5/100
0s - loss: 0.4573 - val_loss: 0.5865
Epoch 6/100
0s - loss: 0.4523 - val_loss: 0.5695
Epoch 7/100
0s - loss: 0.4473 - val_loss: 0.5602
Epoch 8/100
0s - loss: 0.4437 - val_loss: 0.5438
Epoch 9/100
0s - loss: 0.4387 - val_loss: 0.5344
Epoch 10/100
0s - loss: 0.4365 - val_loss: 0.5152
Epoch 11/100
0s - loss: 0.4318 - val_loss: 0.5124
Epoch 12/100
0s - loss: 0.4284 - val_loss: 0.5023
Epoch 13/100
0s - loss: 0.4250 - val_loss: 0.4955
Epoch 14/100
0s - loss: 0.4213 - val_loss: 0.4951
Epoch 15/100
0s - loss: 0.4188 - val_loss: 0.4828
Epoch 16/100
0s - loss: 0.4191 - val_loss: 0.4814
Epoch 17/100
0s - loss: 0.4146 - val_loss: 0.4777
Epoch 18/100
0s - loss: 0.4113 - val_loss: 0.4769
Epoch 19/100
0s - loss: 0.4106 - val_loss: 0.4769
Epoch 20/100
0s - loss: 0.4071 - val_loss: 0.4718
Epoch 21/100
0s - loss: 0.4041 - val_loss: 0.4724
Epoch 22/100
0s - loss: 0.4018 - val_loss: 0.4683
Epoch 23/100
0s - loss: 0.4003 - val_loss: 0.4678
Epoch 24/100
0s - loss: 0.3970 - val_loss: 0.4672
Epoch 25/100
0s - loss: 0.3962 - val_loss: 0.4696
Epoch 26/100
0s - loss: 0.3934 - val_loss: 0.4681
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:15:15,746 - 13_UsokinAE_450-300_200_relu_BN|Fold #5 Loss = 0.468101
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6140 - val_loss: 0.6477
Epoch 2/100
0s - loss: 0.5030 - val_loss: 0.6305
Epoch 3/100
0s - loss: 0.4788 - val_loss: 0.6195
Epoch 4/100
0s - loss: 0.4689 - val_loss: 0.6079
Epoch 5/100
0s - loss: 0.4620 - val_loss: 0.5908
Epoch 6/100
0s - loss: 0.4563 - val_loss: 0.5759
Epoch 7/100
0s - loss: 0.4515 - val_loss: 0.5631
Epoch 8/100
0s - loss: 0.4487 - val_loss: 0.5476
Epoch 9/100
0s - loss: 0.4452 - val_loss: 0.5375
Epoch 10/100
0s - loss: 0.4437 - val_loss: 0.5228
Epoch 11/100
0s - loss: 0.4414 - val_loss: 0.5082
Epoch 12/100
0s - loss: 0.4367 - val_loss: 0.5047
Epoch 13/100
0s - loss: 0.4345 - val_loss: 0.4868
Epoch 14/100
0s - loss: 0.4324 - val_loss: 0.4864
Epoch 15/100
0s - loss: 0.4307 - val_loss: 0.4760
Epoch 16/100
0s - loss: 0.4294 - val_loss: 0.4737
Epoch 17/100
0s - loss: 0.4267 - val_loss: 0.4709
Epoch 18/100
0s - loss: 0.4249 - val_loss: 0.4692
Epoch 19/100
0s - loss: 0.4219 - val_loss: 0.4686
Epoch 20/100
0s - loss: 0.4206 - val_loss: 0.4632
Epoch 21/100
0s - loss: 0.4183 - val_loss: 0.4618
Epoch 22/100
0s - loss: 0.4159 - val_loss: 0.4615
Epoch 23/100
0s - loss: 0.4150 - val_loss: 0.4603
Epoch 24/100
0s - loss: 0.4123 - val_loss: 0.4620
Epoch 25/100
0s - loss: 0.4106 - val_loss: 0.4621
Epoch 26/100
0s - loss: 0.4097 - val_loss: 0.4642
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:15:36,698 - 13_UsokinAE_450-300_200_relu_BN|Fold #6 Loss = 0.464164
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6133 - val_loss: 0.6503
Epoch 2/100
0s - loss: 0.4994 - val_loss: 0.6330
Epoch 3/100
0s - loss: 0.4762 - val_loss: 0.6165
Epoch 4/100
0s - loss: 0.4652 - val_loss: 0.6027
Epoch 5/100
0s - loss: 0.4579 - val_loss: 0.5863
Epoch 6/100
0s - loss: 0.4522 - val_loss: 0.5756
Epoch 7/100
0s - loss: 0.4470 - val_loss: 0.5580
Epoch 8/100
0s - loss: 0.4426 - val_loss: 0.5473
Epoch 9/100
0s - loss: 0.4387 - val_loss: 0.5347
Epoch 10/100
0s - loss: 0.4361 - val_loss: 0.5272
Epoch 11/100
0s - loss: 0.4329 - val_loss: 0.5204
Epoch 12/100
0s - loss: 0.4291 - val_loss: 0.5117
Epoch 13/100
0s - loss: 0.4264 - val_loss: 0.5064
Epoch 14/100
0s - loss: 0.4235 - val_loss: 0.5049
Epoch 15/100
0s - loss: 0.4205 - val_loss: 0.4961
Epoch 16/100
0s - loss: 0.4162 - val_loss: 0.4930
Epoch 17/100
0s - loss: 0.4139 - val_loss: 0.4874
Epoch 18/100
0s - loss: 0.4119 - val_loss: 0.4888
Epoch 19/100
0s - loss: 0.4104 - val_loss: 0.4873
Epoch 20/100
0s - loss: 0.4070 - val_loss: 0.4837
Epoch 21/100
0s - loss: 0.4052 - val_loss: 0.4837
Epoch 22/100
0s - loss: 0.4028 - val_loss: 0.4838
Epoch 23/100
0s - loss: 0.4008 - val_loss: 0.4838
Epoch 24/100
0s - loss: 0.3993 - val_loss: 0.4804
Epoch 25/100
0s - loss: 0.3955 - val_loss: 0.4818
Epoch 26/100
0s - loss: 0.3932 - val_loss: 0.4842
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:15:57,385 - 13_UsokinAE_450-300_200_relu_BN|Fold #7 Loss = 0.484185
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6234 - val_loss: 0.6413
Epoch 2/100
0s - loss: 0.5050 - val_loss: 0.6234
Epoch 3/100
0s - loss: 0.4779 - val_loss: 0.6093
Epoch 4/100
0s - loss: 0.4658 - val_loss: 0.5958
Epoch 5/100
0s - loss: 0.4595 - val_loss: 0.5827
Epoch 6/100
0s - loss: 0.4534 - val_loss: 0.5704
Epoch 7/100
0s - loss: 0.4487 - val_loss: 0.5588
Epoch 8/100
0s - loss: 0.4449 - val_loss: 0.5420
Epoch 9/100
0s - loss: 0.4408 - val_loss: 0.5286
Epoch 10/100
0s - loss: 0.4373 - val_loss: 0.5188
Epoch 11/100
0s - loss: 0.4336 - val_loss: 0.5098
Epoch 12/100
0s - loss: 0.4308 - val_loss: 0.4975
Epoch 13/100
0s - loss: 0.4276 - val_loss: 0.4899
Epoch 14/100
0s - loss: 0.4252 - val_loss: 0.4834
Epoch 15/100
0s - loss: 0.4219 - val_loss: 0.4751
Epoch 16/100
0s - loss: 0.4197 - val_loss: 0.4728
Epoch 17/100
0s - loss: 0.4174 - val_loss: 0.4708
Epoch 18/100
0s - loss: 0.4147 - val_loss: 0.4654
Epoch 19/100
0s - loss: 0.4116 - val_loss: 0.4621
Epoch 20/100
0s - loss: 0.4086 - val_loss: 0.4627
Epoch 21/100
0s - loss: 0.4059 - val_loss: 0.4602
Epoch 22/100
0s - loss: 0.4030 - val_loss: 0.4603
Epoch 23/100
0s - loss: 0.4024 - val_loss: 0.4613
Epoch 24/100
0s - loss: 0.4000 - val_loss: 0.4581
Epoch 25/100
0s - loss: 0.3980 - val_loss: 0.4590
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:16:17,180 - 13_UsokinAE_450-300_200_relu_BN|Fold #8 Loss = 0.458980
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6139 - val_loss: 0.6399
Epoch 2/100
0s - loss: 0.4988 - val_loss: 0.6269
Epoch 3/100
0s - loss: 0.4773 - val_loss: 0.6131
Epoch 4/100
0s - loss: 0.4658 - val_loss: 0.5923
Epoch 5/100
0s - loss: 0.4592 - val_loss: 0.5917
Epoch 6/100
0s - loss: 0.4523 - val_loss: 0.5699
Epoch 7/100
0s - loss: 0.4491 - val_loss: 0.5621
Epoch 8/100
0s - loss: 0.4443 - val_loss: 0.5411
Epoch 9/100
0s - loss: 0.4401 - val_loss: 0.5316
Epoch 10/100
0s - loss: 0.4373 - val_loss: 0.5184
Epoch 11/100
0s - loss: 0.4332 - val_loss: 0.5093
Epoch 12/100
0s - loss: 0.4302 - val_loss: 0.5010
Epoch 13/100
0s - loss: 0.4273 - val_loss: 0.4920
Epoch 14/100
0s - loss: 0.4246 - val_loss: 0.4877
Epoch 15/100
0s - loss: 0.4217 - val_loss: 0.4832
Epoch 16/100
0s - loss: 0.4196 - val_loss: 0.4810
Epoch 17/100
0s - loss: 0.4163 - val_loss: 0.4786
Epoch 18/100
0s - loss: 0.4137 - val_loss: 0.4753
Epoch 19/100
0s - loss: 0.4117 - val_loss: 0.4738
Epoch 20/100
0s - loss: 0.4090 - val_loss: 0.4736
Epoch 21/100
0s - loss: 0.4073 - val_loss: 0.4742
Epoch 22/100
0s - loss: 0.4051 - val_loss: 0.4751
Epoch 23/100
0s - loss: 0.4026 - val_loss: 0.4709
Epoch 24/100
0s - loss: 0.4000 - val_loss: 0.4718
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:16:36,621 - 13_UsokinAE_450-300_200_relu_BN|Fold #9 Loss = 0.471828
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6079 - val_loss: 0.6482
Epoch 2/100
0s - loss: 0.5015 - val_loss: 0.6406
Epoch 3/100
0s - loss: 0.4767 - val_loss: 0.6249
Epoch 4/100
0s - loss: 0.4653 - val_loss: 0.6060
Epoch 5/100
0s - loss: 0.4581 - val_loss: 0.5919
Epoch 6/100
0s - loss: 0.4520 - val_loss: 0.5753
Epoch 7/100
0s - loss: 0.4477 - val_loss: 0.5609
Epoch 8/100
0s - loss: 0.4435 - val_loss: 0.5423
Epoch 9/100
0s - loss: 0.4394 - val_loss: 0.5284
Epoch 10/100
0s - loss: 0.4348 - val_loss: 0.5186
Epoch 11/100
0s - loss: 0.4312 - val_loss: 0.5102
Epoch 12/100
0s - loss: 0.4278 - val_loss: 0.4992
Epoch 13/100
0s - loss: 0.4252 - val_loss: 0.4928
Epoch 14/100
0s - loss: 0.4219 - val_loss: 0.4842
Epoch 15/100
0s - loss: 0.4188 - val_loss: 0.4808
Epoch 16/100
0s - loss: 0.4165 - val_loss: 0.4780
Epoch 17/100
0s - loss: 0.4149 - val_loss: 0.4717
Epoch 18/100
0s - loss: 0.4113 - val_loss: 0.4701
Epoch 19/100
0s - loss: 0.4086 - val_loss: 0.4688
Epoch 20/100
0s - loss: 0.4062 - val_loss: 0.4641
Epoch 21/100
0s - loss: 0.4029 - val_loss: 0.4633
Epoch 22/100
0s - loss: 0.4008 - val_loss: 0.4625
Epoch 23/100
0s - loss: 0.3983 - val_loss: 0.4625
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:16:55,693 - 13_UsokinAE_450-300_200_relu_BN|Fold #10 Loss = 0.462475
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:16:55,694 - 13_UsokinAE_450-300_200_relu_BN|Avg Validation Loss = 0.469103
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6246 - val_loss: 0.6451
Epoch 2/100
0s - loss: 0.5079 - val_loss: 0.6305
Epoch 3/100
0s - loss: 0.4827 - val_loss: 0.6207
Epoch 4/100
0s - loss: 0.4726 - val_loss: 0.6090
Epoch 5/100
0s - loss: 0.4666 - val_loss: 0.5925
Epoch 6/100
0s - loss: 0.4619 - val_loss: 0.5854
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.5687
Epoch 8/100
0s - loss: 0.4556 - val_loss: 0.5580
Epoch 9/100
0s - loss: 0.4533 - val_loss: 0.5504
Epoch 10/100
0s - loss: 0.4513 - val_loss: 0.5397
Epoch 11/100
0s - loss: 0.4484 - val_loss: 0.5321
Epoch 12/100
0s - loss: 0.4472 - val_loss: 0.5207
Epoch 13/100
0s - loss: 0.4452 - val_loss: 0.5098
Epoch 14/100
0s - loss: 0.4437 - val_loss: 0.5022
Epoch 15/100
0s - loss: 0.4417 - val_loss: 0.4964
Epoch 16/100
0s - loss: 0.4412 - val_loss: 0.4883
Epoch 17/100
0s - loss: 0.4401 - val_loss: 0.4842
Epoch 18/100
0s - loss: 0.4390 - val_loss: 0.4805
Epoch 19/100
0s - loss: 0.4378 - val_loss: 0.4765
Epoch 20/100
0s - loss: 0.4369 - val_loss: 0.4780
Epoch 21/100
0s - loss: 0.4358 - val_loss: 0.4744
Epoch 22/100
0s - loss: 0.4357 - val_loss: 0.4726
Epoch 23/100
0s - loss: 0.4330 - val_loss: 0.4734
Epoch 24/100
0s - loss: 0.4327 - val_loss: 0.4772
Epoch 25/100
0s - loss: 0.4312 - val_loss: 0.4807
Epoch 26/100
0s - loss: 0.4309 - val_loss: 0.4825
Epoch 27/100
0s - loss: 0.4314 - val_loss: 0.4896
Epoch 28/100
0s - loss: 0.4301 - val_loss: 0.4899
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:17:16,842 - 14_UsokinAE_400-300_150_relu_BN|Fold #1 Loss = 0.489891
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6220 - val_loss: 0.6475
Epoch 2/100
0s - loss: 0.5060 - val_loss: 0.6268
Epoch 3/100
0s - loss: 0.4794 - val_loss: 0.6139
Epoch 4/100
0s - loss: 0.4684 - val_loss: 0.6060
Epoch 5/100
0s - loss: 0.4611 - val_loss: 0.5896
Epoch 6/100
0s - loss: 0.4568 - val_loss: 0.5783
Epoch 7/100
0s - loss: 0.4529 - val_loss: 0.5571
Epoch 8/100
0s - loss: 0.4489 - val_loss: 0.5501
Epoch 9/100
0s - loss: 0.4463 - val_loss: 0.5314
Epoch 10/100
0s - loss: 0.4418 - val_loss: 0.5192
Epoch 11/100
0s - loss: 0.4381 - val_loss: 0.5158
Epoch 12/100
0s - loss: 0.4354 - val_loss: 0.5049
Epoch 13/100
0s - loss: 0.4331 - val_loss: 0.4958
Epoch 14/100
0s - loss: 0.4299 - val_loss: 0.4928
Epoch 15/100
0s - loss: 0.4268 - val_loss: 0.4837
Epoch 16/100
0s - loss: 0.4235 - val_loss: 0.4796
Epoch 17/100
0s - loss: 0.4217 - val_loss: 0.4777
Epoch 18/100
0s - loss: 0.4186 - val_loss: 0.4724
Epoch 19/100
0s - loss: 0.4170 - val_loss: 0.4678
Epoch 20/100
0s - loss: 0.4151 - val_loss: 0.4688
Epoch 21/100
0s - loss: 0.4122 - val_loss: 0.4641
Epoch 22/100
0s - loss: 0.4098 - val_loss: 0.4660
Epoch 23/100
0s - loss: 0.4077 - val_loss: 0.4634
Epoch 24/100
0s - loss: 0.4065 - val_loss: 0.4630
Epoch 25/100
0s - loss: 0.4039 - val_loss: 0.4638
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:17:36,565 - 14_UsokinAE_400-300_150_relu_BN|Fold #2 Loss = 0.463818
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6244 - val_loss: 0.6453
Epoch 2/100
0s - loss: 0.5062 - val_loss: 0.6319
Epoch 3/100
0s - loss: 0.4782 - val_loss: 0.6197
Epoch 4/100
0s - loss: 0.4675 - val_loss: 0.6065
Epoch 5/100
0s - loss: 0.4606 - val_loss: 0.5913
Epoch 6/100
0s - loss: 0.4549 - val_loss: 0.5833
Epoch 7/100
0s - loss: 0.4503 - val_loss: 0.5635
Epoch 8/100
0s - loss: 0.4465 - val_loss: 0.5585
Epoch 9/100
0s - loss: 0.4431 - val_loss: 0.5389
Epoch 10/100
0s - loss: 0.4404 - val_loss: 0.5324
Epoch 11/100
0s - loss: 0.4371 - val_loss: 0.5194
Epoch 12/100
0s - loss: 0.4344 - val_loss: 0.5156
Epoch 13/100
0s - loss: 0.4314 - val_loss: 0.5033
Epoch 14/100
0s - loss: 0.4282 - val_loss: 0.4939
Epoch 15/100
0s - loss: 0.4264 - val_loss: 0.4906
Epoch 16/100
0s - loss: 0.4249 - val_loss: 0.4933
Epoch 17/100
0s - loss: 0.4228 - val_loss: 0.4886
Epoch 18/100
0s - loss: 0.4198 - val_loss: 0.4831
Epoch 19/100
0s - loss: 0.4169 - val_loss: 0.4825
Epoch 20/100
0s - loss: 0.4143 - val_loss: 0.4790
Epoch 21/100
0s - loss: 0.4114 - val_loss: 0.4758
Epoch 22/100
0s - loss: 0.4095 - val_loss: 0.4739
Epoch 23/100
0s - loss: 0.4078 - val_loss: 0.4746
Epoch 24/100
0s - loss: 0.4063 - val_loss: 0.4751
Epoch 25/100
0s - loss: 0.4034 - val_loss: 0.4741
Epoch 26/100
0s - loss: 0.4021 - val_loss: 0.4745
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:17:56,679 - 14_UsokinAE_400-300_150_relu_BN|Fold #3 Loss = 0.474514
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6251 - val_loss: 0.6516
Epoch 2/100
0s - loss: 0.5089 - val_loss: 0.6346
Epoch 3/100
0s - loss: 0.4795 - val_loss: 0.6260
Epoch 4/100
0s - loss: 0.4690 - val_loss: 0.6102
Epoch 5/100
0s - loss: 0.4617 - val_loss: 0.5964
Epoch 6/100
0s - loss: 0.4556 - val_loss: 0.5841
Epoch 7/100
0s - loss: 0.4513 - val_loss: 0.5639
Epoch 8/100
0s - loss: 0.4478 - val_loss: 0.5584
Epoch 9/100
0s - loss: 0.4447 - val_loss: 0.5397
Epoch 10/100
0s - loss: 0.4416 - val_loss: 0.5383
Epoch 11/100
0s - loss: 0.4393 - val_loss: 0.5165
Epoch 12/100
0s - loss: 0.4361 - val_loss: 0.5104
Epoch 13/100
0s - loss: 0.4323 - val_loss: 0.5017
Epoch 14/100
0s - loss: 0.4291 - val_loss: 0.4935
Epoch 15/100
0s - loss: 0.4265 - val_loss: 0.4874
Epoch 16/100
0s - loss: 0.4241 - val_loss: 0.4822
Epoch 17/100
0s - loss: 0.4216 - val_loss: 0.4810
Epoch 18/100
0s - loss: 0.4196 - val_loss: 0.4754
Epoch 19/100
0s - loss: 0.4161 - val_loss: 0.4731
Epoch 20/100
0s - loss: 0.4143 - val_loss: 0.4735
Epoch 21/100
0s - loss: 0.4117 - val_loss: 0.4691
Epoch 22/100
0s - loss: 0.4106 - val_loss: 0.4678
Epoch 23/100
0s - loss: 0.4085 - val_loss: 0.4662
Epoch 24/100
0s - loss: 0.4062 - val_loss: 0.4688
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:18:15,861 - 14_UsokinAE_400-300_150_relu_BN|Fold #4 Loss = 0.468785
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6256 - val_loss: 0.6405
Epoch 2/100
0s - loss: 0.5077 - val_loss: 0.6236
Epoch 3/100
0s - loss: 0.4797 - val_loss: 0.6126
Epoch 4/100
0s - loss: 0.4686 - val_loss: 0.6001
Epoch 5/100
0s - loss: 0.4604 - val_loss: 0.5955
Epoch 6/100
0s - loss: 0.4550 - val_loss: 0.5748
Epoch 7/100
0s - loss: 0.4507 - val_loss: 0.5653
Epoch 8/100
0s - loss: 0.4466 - val_loss: 0.5507
Epoch 9/100
0s - loss: 0.4426 - val_loss: 0.5365
Epoch 10/100
0s - loss: 0.4396 - val_loss: 0.5253
Epoch 11/100
0s - loss: 0.4370 - val_loss: 0.5108
Epoch 12/100
0s - loss: 0.4334 - val_loss: 0.5110
Epoch 13/100
0s - loss: 0.4313 - val_loss: 0.4975
Epoch 14/100
0s - loss: 0.4279 - val_loss: 0.4929
Epoch 15/100
0s - loss: 0.4251 - val_loss: 0.4826
Epoch 16/100
0s - loss: 0.4226 - val_loss: 0.4843
Epoch 17/100
0s - loss: 0.4206 - val_loss: 0.4795
Epoch 18/100
0s - loss: 0.4178 - val_loss: 0.4767
Epoch 19/100
0s - loss: 0.4165 - val_loss: 0.4762
Epoch 20/100
0s - loss: 0.4142 - val_loss: 0.4712
Epoch 21/100
0s - loss: 0.4115 - val_loss: 0.4724
Epoch 22/100
0s - loss: 0.4105 - val_loss: 0.4705
Epoch 23/100
0s - loss: 0.4082 - val_loss: 0.4704
Epoch 24/100
0s - loss: 0.4046 - val_loss: 0.4683
Epoch 25/100
0s - loss: 0.4030 - val_loss: 0.4707
Epoch 26/100
0s - loss: 0.4004 - val_loss: 0.4676
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:18:36,266 - 14_UsokinAE_400-300_150_relu_BN|Fold #5 Loss = 0.467615
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6218 - val_loss: 0.6480
Epoch 2/100
0s - loss: 0.5070 - val_loss: 0.6307
Epoch 3/100
0s - loss: 0.4814 - val_loss: 0.6190
Epoch 4/100
0s - loss: 0.4706 - val_loss: 0.6016
Epoch 5/100
0s - loss: 0.4638 - val_loss: 0.5884
Epoch 6/100
0s - loss: 0.4583 - val_loss: 0.5758
Epoch 7/100
0s - loss: 0.4543 - val_loss: 0.5580
Epoch 8/100
0s - loss: 0.4513 - val_loss: 0.5447
Epoch 9/100
0s - loss: 0.4495 - val_loss: 0.5341
Epoch 10/100
0s - loss: 0.4460 - val_loss: 0.5267
Epoch 11/100
0s - loss: 0.4425 - val_loss: 0.5088
Epoch 12/100
0s - loss: 0.4407 - val_loss: 0.5038
Epoch 13/100
0s - loss: 0.4384 - val_loss: 0.4954
Epoch 14/100
0s - loss: 0.4362 - val_loss: 0.4863
Epoch 15/100
0s - loss: 0.4349 - val_loss: 0.4817
Epoch 16/100
0s - loss: 0.4319 - val_loss: 0.4773
Epoch 17/100
0s - loss: 0.4299 - val_loss: 0.4749
Epoch 18/100
0s - loss: 0.4274 - val_loss: 0.4715
Epoch 19/100
0s - loss: 0.4246 - val_loss: 0.4702
Epoch 20/100
0s - loss: 0.4232 - val_loss: 0.4638
Epoch 21/100
0s - loss: 0.4209 - val_loss: 0.4620
Epoch 22/100
0s - loss: 0.4192 - val_loss: 0.4610
Epoch 23/100
0s - loss: 0.4181 - val_loss: 0.4604
Epoch 24/100
0s - loss: 0.4159 - val_loss: 0.4598
Epoch 25/100
0s - loss: 0.4146 - val_loss: 0.4607
Epoch 26/100
0s - loss: 0.4123 - val_loss: 0.4597
Epoch 27/100
0s - loss: 0.4105 - val_loss: 0.4644
Epoch 28/100
0s - loss: 0.4090 - val_loss: 0.4656
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:18:57,702 - 14_UsokinAE_400-300_150_relu_BN|Fold #6 Loss = 0.465592
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6171 - val_loss: 0.6563
Epoch 2/100
0s - loss: 0.5027 - val_loss: 0.6396
Epoch 3/100
0s - loss: 0.4771 - val_loss: 0.6232
Epoch 4/100
0s - loss: 0.4671 - val_loss: 0.6086
Epoch 5/100
0s - loss: 0.4601 - val_loss: 0.5940
Epoch 6/100
0s - loss: 0.4552 - val_loss: 0.5820
Epoch 7/100
0s - loss: 0.4506 - val_loss: 0.5664
Epoch 8/100
0s - loss: 0.4464 - val_loss: 0.5532
Epoch 9/100
0s - loss: 0.4429 - val_loss: 0.5423
Epoch 10/100
0s - loss: 0.4392 - val_loss: 0.5291
Epoch 11/100
0s - loss: 0.4360 - val_loss: 0.5270
Epoch 12/100
0s - loss: 0.4329 - val_loss: 0.5178
Epoch 13/100
0s - loss: 0.4308 - val_loss: 0.5093
Epoch 14/100
0s - loss: 0.4284 - val_loss: 0.5041
Epoch 15/100
0s - loss: 0.4260 - val_loss: 0.4987
Epoch 16/100
0s - loss: 0.4239 - val_loss: 0.4888
Epoch 17/100
0s - loss: 0.4214 - val_loss: 0.4937
Epoch 18/100
0s - loss: 0.4184 - val_loss: 0.4873
Epoch 19/100
0s - loss: 0.4161 - val_loss: 0.4837
Epoch 20/100
0s - loss: 0.4140 - val_loss: 0.4835
Epoch 21/100
0s - loss: 0.4119 - val_loss: 0.4839
Epoch 22/100
0s - loss: 0.4103 - val_loss: 0.4832
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:19:15,790 - 14_UsokinAE_400-300_150_relu_BN|Fold #7 Loss = 0.483192
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6185 - val_loss: 0.6461
Epoch 2/100
0s - loss: 0.5074 - val_loss: 0.6345
Epoch 3/100
0s - loss: 0.4812 - val_loss: 0.6172
Epoch 4/100
0s - loss: 0.4705 - val_loss: 0.6068
Epoch 5/100
0s - loss: 0.4635 - val_loss: 0.5968
Epoch 6/100
0s - loss: 0.4578 - val_loss: 0.5700
Epoch 7/100
0s - loss: 0.4534 - val_loss: 0.5699
Epoch 8/100
0s - loss: 0.4491 - val_loss: 0.5437
Epoch 9/100
0s - loss: 0.4454 - val_loss: 0.5310
Epoch 10/100
0s - loss: 0.4423 - val_loss: 0.5224
Epoch 11/100
0s - loss: 0.4392 - val_loss: 0.5046
Epoch 12/100
0s - loss: 0.4364 - val_loss: 0.4992
Epoch 13/100
0s - loss: 0.4322 - val_loss: 0.4907
Epoch 14/100
0s - loss: 0.4301 - val_loss: 0.4829
Epoch 15/100
0s - loss: 0.4281 - val_loss: 0.4826
Epoch 16/100
0s - loss: 0.4247 - val_loss: 0.4701
Epoch 17/100
0s - loss: 0.4229 - val_loss: 0.4692
Epoch 18/100
0s - loss: 0.4205 - val_loss: 0.4627
Epoch 19/100
0s - loss: 0.4176 - val_loss: 0.4640
Epoch 20/100
0s - loss: 0.4147 - val_loss: 0.4601
Epoch 21/100
0s - loss: 0.4147 - val_loss: 0.4627
Epoch 22/100
0s - loss: 0.4114 - val_loss: 0.4583
Epoch 23/100
0s - loss: 0.4102 - val_loss: 0.4600
Epoch 24/100
0s - loss: 0.4083 - val_loss: 0.4592
Epoch 25/100
0s - loss: 0.4060 - val_loss: 0.4574
Epoch 26/100
0s - loss: 0.4042 - val_loss: 0.4576
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:19:36,188 - 14_UsokinAE_400-300_150_relu_BN|Fold #8 Loss = 0.457628
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6232 - val_loss: 0.6447
Epoch 2/100
0s - loss: 0.5025 - val_loss: 0.6255
Epoch 3/100
0s - loss: 0.4783 - val_loss: 0.6148
Epoch 4/100
0s - loss: 0.4682 - val_loss: 0.6050
Epoch 5/100
0s - loss: 0.4613 - val_loss: 0.5921
Epoch 6/100
0s - loss: 0.4562 - val_loss: 0.5828
Epoch 7/100
0s - loss: 0.4507 - val_loss: 0.5667
Epoch 8/100
0s - loss: 0.4473 - val_loss: 0.5511
Epoch 9/100
0s - loss: 0.4440 - val_loss: 0.5357
Epoch 10/100
0s - loss: 0.4416 - val_loss: 0.5254
Epoch 11/100
0s - loss: 0.4377 - val_loss: 0.5114
Epoch 12/100
0s - loss: 0.4358 - val_loss: 0.5105
Epoch 13/100
0s - loss: 0.4322 - val_loss: 0.4965
Epoch 14/100
0s - loss: 0.4300 - val_loss: 0.4978
Epoch 15/100
0s - loss: 0.4266 - val_loss: 0.4852
Epoch 16/100
0s - loss: 0.4254 - val_loss: 0.4835
Epoch 17/100
0s - loss: 0.4220 - val_loss: 0.4818
Epoch 18/100
0s - loss: 0.4194 - val_loss: 0.4775
Epoch 19/100
0s - loss: 0.4172 - val_loss: 0.4758
Epoch 20/100
0s - loss: 0.4153 - val_loss: 0.4753
Epoch 21/100
0s - loss: 0.4136 - val_loss: 0.4748
Epoch 22/100
0s - loss: 0.4109 - val_loss: 0.4726
Epoch 23/100
0s - loss: 0.4094 - val_loss: 0.4724
Epoch 24/100
0s - loss: 0.4077 - val_loss: 0.4736
Epoch 25/100
0s - loss: 0.4049 - val_loss: 0.4741
Epoch 26/100
0s - loss: 0.4029 - val_loss: 0.4763
Epoch 27/100
0s - loss: 0.4007 - val_loss: 0.4755
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:19:57,325 - 14_UsokinAE_400-300_150_relu_BN|Fold #9 Loss = 0.475548
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6206 - val_loss: 0.6528
Epoch 2/100
0s - loss: 0.5073 - val_loss: 0.6392
Epoch 3/100
0s - loss: 0.4796 - val_loss: 0.6236
Epoch 4/100
0s - loss: 0.4681 - val_loss: 0.6090
Epoch 5/100
0s - loss: 0.4610 - val_loss: 0.5964
Epoch 6/100
0s - loss: 0.4551 - val_loss: 0.5785
Epoch 7/100
0s - loss: 0.4509 - val_loss: 0.5646
Epoch 8/100
0s - loss: 0.4470 - val_loss: 0.5489
Epoch 9/100
0s - loss: 0.4425 - val_loss: 0.5350
Epoch 10/100
0s - loss: 0.4396 - val_loss: 0.5239
Epoch 11/100
0s - loss: 0.4361 - val_loss: 0.5170
Epoch 12/100
0s - loss: 0.4326 - val_loss: 0.5034
Epoch 13/100
0s - loss: 0.4299 - val_loss: 0.4939
Epoch 14/100
0s - loss: 0.4267 - val_loss: 0.4881
Epoch 15/100
0s - loss: 0.4244 - val_loss: 0.4830
Epoch 16/100
0s - loss: 0.4206 - val_loss: 0.4747
Epoch 17/100
0s - loss: 0.4186 - val_loss: 0.4742
Epoch 18/100
0s - loss: 0.4159 - val_loss: 0.4671
Epoch 19/100
0s - loss: 0.4141 - val_loss: 0.4669
Epoch 20/100
0s - loss: 0.4116 - val_loss: 0.4625
Epoch 21/100
0s - loss: 0.4093 - val_loss: 0.4638
Epoch 22/100
0s - loss: 0.4076 - val_loss: 0.4630
Epoch 23/100
0s - loss: 0.4055 - val_loss: 0.4627
Epoch 24/100
0s - loss: 0.4031 - val_loss: 0.4607
Epoch 25/100
0s - loss: 0.4009 - val_loss: 0.4618
Epoch 26/100
0s - loss: 0.3983 - val_loss: 0.4628
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:20:17,235 - 14_UsokinAE_400-300_150_relu_BN|Fold #10 Loss = 0.462755
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:20:17,236 - 14_UsokinAE_400-300_150_relu_BN|Avg Validation Loss = 0.470934
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5930 - val_loss: 0.5401
Epoch 2/100
0s - loss: 0.5391 - val_loss: 0.5278
Epoch 3/100
0s - loss: 0.5229 - val_loss: 0.5080
Epoch 4/100
0s - loss: 0.5048 - val_loss: 0.4948
Epoch 5/100
0s - loss: 0.4937 - val_loss: 0.4878
Epoch 6/100
0s - loss: 0.4852 - val_loss: 0.4817
Epoch 7/100
0s - loss: 0.4806 - val_loss: 0.4785
Epoch 8/100
0s - loss: 0.4774 - val_loss: 0.4754
Epoch 9/100
0s - loss: 0.4739 - val_loss: 0.4738
Epoch 10/100
0s - loss: 0.4715 - val_loss: 0.4724
Epoch 11/100
0s - loss: 0.4698 - val_loss: 0.4705
Epoch 12/100
0s - loss: 0.4673 - val_loss: 0.4700
Epoch 13/100
0s - loss: 0.4664 - val_loss: 0.4696
Epoch 14/100
0s - loss: 0.4653 - val_loss: 0.4694
Epoch 15/100
0s - loss: 0.4644 - val_loss: 0.4694
Epoch 16/100
0s - loss: 0.4638 - val_loss: 0.4676
Epoch 17/100
0s - loss: 0.4620 - val_loss: 0.4656
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:20:27,809 - 15_UsokinAE_400-300_50_tanh|Fold #1 Loss = 0.465611
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5980 - val_loss: 0.5365
Epoch 2/100
0s - loss: 0.5354 - val_loss: 0.5200
Epoch 3/100
0s - loss: 0.5139 - val_loss: 0.4981
Epoch 4/100
0s - loss: 0.4950 - val_loss: 0.4835
Epoch 5/100
0s - loss: 0.4839 - val_loss: 0.4774
Epoch 6/100
0s - loss: 0.4800 - val_loss: 0.4758
Epoch 7/100
0s - loss: 0.4770 - val_loss: 0.4724
Epoch 8/100
0s - loss: 0.4744 - val_loss: 0.4707
Epoch 9/100
0s - loss: 0.4722 - val_loss: 0.4687
Epoch 10/100
0s - loss: 0.4699 - val_loss: 0.4674
Epoch 11/100
0s - loss: 0.4678 - val_loss: 0.4664
Epoch 12/100
0s - loss: 0.4664 - val_loss: 0.4646
Epoch 13/100
0s - loss: 0.4645 - val_loss: 0.4638
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:20:36,133 - 15_UsokinAE_400-300_50_tanh|Fold #2 Loss = 0.463845
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5932 - val_loss: 0.5456
Epoch 2/100
0s - loss: 0.5353 - val_loss: 0.5292
Epoch 3/100
0s - loss: 0.5161 - val_loss: 0.5126
Epoch 4/100
0s - loss: 0.4985 - val_loss: 0.4981
Epoch 5/100
0s - loss: 0.4849 - val_loss: 0.4898
Epoch 6/100
0s - loss: 0.4772 - val_loss: 0.4856
Epoch 7/100
0s - loss: 0.4737 - val_loss: 0.4841
Epoch 8/100
0s - loss: 0.4717 - val_loss: 0.4823
Epoch 9/100
0s - loss: 0.4699 - val_loss: 0.4810
Epoch 10/100
0s - loss: 0.4687 - val_loss: 0.4807
Epoch 11/100
0s - loss: 0.4677 - val_loss: 0.4799
Epoch 12/100
0s - loss: 0.4658 - val_loss: 0.4787
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:20:43,739 - 15_UsokinAE_400-300_50_tanh|Fold #3 Loss = 0.478718
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6005 - val_loss: 0.5365
Epoch 2/100
0s - loss: 0.5323 - val_loss: 0.5171
Epoch 3/100
0s - loss: 0.5129 - val_loss: 0.5014
Epoch 4/100
0s - loss: 0.4958 - val_loss: 0.4873
Epoch 5/100
0s - loss: 0.4837 - val_loss: 0.4796
Epoch 6/100
0s - loss: 0.4775 - val_loss: 0.4767
Epoch 7/100
0s - loss: 0.4745 - val_loss: 0.4745
Epoch 8/100
0s - loss: 0.4721 - val_loss: 0.4737
Epoch 9/100
0s - loss: 0.4702 - val_loss: 0.4718
Epoch 10/100
0s - loss: 0.4685 - val_loss: 0.4706
Epoch 11/100
0s - loss: 0.4666 - val_loss: 0.4686
Epoch 12/100
0s - loss: 0.4645 - val_loss: 0.4668
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:20:51,526 - 15_UsokinAE_400-300_50_tanh|Fold #4 Loss = 0.466848
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5989 - val_loss: 0.5439
Epoch 2/100
0s - loss: 0.5384 - val_loss: 0.5337
Epoch 3/100
0s - loss: 0.5228 - val_loss: 0.5141
Epoch 4/100
0s - loss: 0.5033 - val_loss: 0.4991
Epoch 5/100
0s - loss: 0.4918 - val_loss: 0.4903
Epoch 6/100
0s - loss: 0.4833 - val_loss: 0.4846
Epoch 7/100
0s - loss: 0.4778 - val_loss: 0.4798
Epoch 8/100
0s - loss: 0.4741 - val_loss: 0.4775
Epoch 9/100
0s - loss: 0.4713 - val_loss: 0.4759
Epoch 10/100
0s - loss: 0.4693 - val_loss: 0.4744
Epoch 11/100
0s - loss: 0.4678 - val_loss: 0.4731
Epoch 12/100
0s - loss: 0.4659 - val_loss: 0.4719
Epoch 13/100
0s - loss: 0.4645 - val_loss: 0.4712
Epoch 14/100
0s - loss: 0.4638 - val_loss: 0.4713
Epoch 15/100
0s - loss: 0.4625 - val_loss: 0.4693
Epoch 16/100
0s - loss: 0.4610 - val_loss: 0.4684
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:01,377 - 15_UsokinAE_400-300_50_tanh|Fold #5 Loss = 0.468404
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.6000 - val_loss: 0.5366
Epoch 2/100
0s - loss: 0.5398 - val_loss: 0.5281
Epoch 3/100
0s - loss: 0.5257 - val_loss: 0.5071
Epoch 4/100
0s - loss: 0.5050 - val_loss: 0.4900
Epoch 5/100
0s - loss: 0.4947 - val_loss: 0.4856
Epoch 6/100
0s - loss: 0.4880 - val_loss: 0.4764
Epoch 7/100
0s - loss: 0.4819 - val_loss: 0.4723
Epoch 8/100
0s - loss: 0.4779 - val_loss: 0.4698
Epoch 9/100
0s - loss: 0.4755 - val_loss: 0.4689
Epoch 10/100
0s - loss: 0.4734 - val_loss: 0.4662
Epoch 11/100
0s - loss: 0.4708 - val_loss: 0.4651
Epoch 12/100
0s - loss: 0.4692 - val_loss: 0.4630
Epoch 13/100
0s - loss: 0.4670 - val_loss: 0.4614
Epoch 14/100
0s - loss: 0.4655 - val_loss: 0.4600
Epoch 15/100
0s - loss: 0.4639 - val_loss: 0.4586
Epoch 16/100
0s - loss: 0.4622 - val_loss: 0.4581
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:11,285 - 15_UsokinAE_400-300_50_tanh|Fold #6 Loss = 0.458136
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5958 - val_loss: 0.5525
Epoch 2/100
0s - loss: 0.5313 - val_loss: 0.5318
Epoch 3/100
0s - loss: 0.5120 - val_loss: 0.5161
Epoch 4/100
0s - loss: 0.4931 - val_loss: 0.5019
Epoch 5/100
0s - loss: 0.4808 - val_loss: 0.4959
Epoch 6/100
0s - loss: 0.4763 - val_loss: 0.4934
Epoch 7/100
0s - loss: 0.4727 - val_loss: 0.4902
Epoch 8/100
0s - loss: 0.4707 - val_loss: 0.4888
Epoch 9/100
0s - loss: 0.4682 - val_loss: 0.4871
Epoch 10/100
0s - loss: 0.4659 - val_loss: 0.4845
Epoch 11/100
0s - loss: 0.4640 - val_loss: 0.4821
Epoch 12/100
0s - loss: 0.4614 - val_loss: 0.4812
Epoch 13/100
0s - loss: 0.4592 - val_loss: 0.4794
Epoch 14/100
0s - loss: 0.4570 - val_loss: 0.4786
Epoch 15/100
0s - loss: 0.4555 - val_loss: 0.4780
Epoch 16/100
0s - loss: 0.4543 - val_loss: 0.4772
Epoch 17/100
0s - loss: 0.4531 - val_loss: 0.4764
Epoch 18/100
0s - loss: 0.4522 - val_loss: 0.4771
Epoch 19/100
0s - loss: 0.4515 - val_loss: 0.4764
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:22,754 - 15_UsokinAE_400-300_50_tanh|Fold #7 Loss = 0.476389
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5974 - val_loss: 0.5353
Epoch 2/100
0s - loss: 0.5344 - val_loss: 0.5192
Epoch 3/100
0s - loss: 0.5137 - val_loss: 0.5008
Epoch 4/100
0s - loss: 0.4970 - val_loss: 0.4847
Epoch 5/100
0s - loss: 0.4842 - val_loss: 0.4759
Epoch 6/100
0s - loss: 0.4783 - val_loss: 0.4707
Epoch 7/100
0s - loss: 0.4747 - val_loss: 0.4682
Epoch 8/100
0s - loss: 0.4728 - val_loss: 0.4667
Epoch 9/100
0s - loss: 0.4709 - val_loss: 0.4645
Epoch 10/100
0s - loss: 0.4685 - val_loss: 0.4627
Epoch 11/100
0s - loss: 0.4661 - val_loss: 0.4609
Epoch 12/100
0s - loss: 0.4639 - val_loss: 0.4586
Epoch 13/100
0s - loss: 0.4619 - val_loss: 0.4573
Epoch 14/100
0s - loss: 0.4605 - val_loss: 0.4567
Epoch 15/100
0s - loss: 0.4594 - val_loss: 0.4560
Epoch 16/100
0s - loss: 0.4580 - val_loss: 0.4550
Epoch 17/100
0s - loss: 0.4569 - val_loss: 0.4550
Epoch 18/100
0s - loss: 0.4563 - val_loss: 0.4545
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:33,792 - 15_UsokinAE_400-300_50_tanh|Fold #8 Loss = 0.454467
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6003 - val_loss: 0.5415
Epoch 2/100
0s - loss: 0.5350 - val_loss: 0.5260
Epoch 3/100
0s - loss: 0.5156 - val_loss: 0.5077
Epoch 4/100
0s - loss: 0.4964 - val_loss: 0.4930
Epoch 5/100
0s - loss: 0.4843 - val_loss: 0.4860
Epoch 6/100
0s - loss: 0.4785 - val_loss: 0.4856
Epoch 7/100
0s - loss: 0.4765 - val_loss: 0.4815
Epoch 8/100
0s - loss: 0.4740 - val_loss: 0.4800
Epoch 9/100
0s - loss: 0.4720 - val_loss: 0.4782
Epoch 10/100
0s - loss: 0.4697 - val_loss: 0.4771
Epoch 11/100
0s - loss: 0.4680 - val_loss: 0.4759
Epoch 12/100
0s - loss: 0.4662 - val_loss: 0.4740
Epoch 13/100
0s - loss: 0.4641 - val_loss: 0.4722
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:42,001 - 15_UsokinAE_400-300_50_tanh|Fold #9 Loss = 0.472182
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5964 - val_loss: 0.5397
Epoch 2/100
0s - loss: 0.5301 - val_loss: 0.5168
Epoch 3/100
0s - loss: 0.5075 - val_loss: 0.4975
Epoch 4/100
0s - loss: 0.4937 - val_loss: 0.4865
Epoch 5/100
0s - loss: 0.4844 - val_loss: 0.4768
Epoch 6/100
0s - loss: 0.4779 - val_loss: 0.4729
Epoch 7/100
0s - loss: 0.4744 - val_loss: 0.4698
Epoch 8/100
0s - loss: 0.4721 - val_loss: 0.4678
Epoch 9/100
0s - loss: 0.4698 - val_loss: 0.4660
Epoch 10/100
0s - loss: 0.4679 - val_loss: 0.4644
Epoch 11/100
0s - loss: 0.4660 - val_loss: 0.4638
Epoch 12/100
0s - loss: 0.4646 - val_loss: 0.4626
Epoch 13/100
0s - loss: 0.4631 - val_loss: 0.4617
Epoch 14/100
0s - loss: 0.4614 - val_loss: 0.4597
Epoch 15/100
0s - loss: 0.4597 - val_loss: 0.4582
Epoch 16/100
0s - loss: 0.4582 - val_loss: 0.4582
Epoch 17/100
0s - loss: 0.4571 - val_loss: 0.4565
Epoch 18/100
0s - loss: 0.4559 - val_loss: 0.4563
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:52,894 - 15_UsokinAE_400-300_50_tanh|Fold #10 Loss = 0.456252
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:21:52,895 - 15_UsokinAE_400-300_50_tanh|Avg Validation Loss = 0.466085
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5944 - val_loss: 0.5375
Epoch 2/100
0s - loss: 0.5341 - val_loss: 0.5186
Epoch 3/100
0s - loss: 0.5111 - val_loss: 0.4942
Epoch 4/100
0s - loss: 0.4902 - val_loss: 0.4832
Epoch 5/100
0s - loss: 0.4815 - val_loss: 0.4776
Epoch 6/100
0s - loss: 0.4767 - val_loss: 0.4768
Epoch 7/100
0s - loss: 0.4743 - val_loss: 0.4786
Epoch 8/100
0s - loss: 0.4719 - val_loss: 0.4721
Epoch 9/100
0s - loss: 0.4685 - val_loss: 0.4705
Epoch 10/100
0s - loss: 0.4671 - val_loss: 0.4692
Epoch 11/100
0s - loss: 0.4652 - val_loss: 0.4681
Epoch 12/100
0s - loss: 0.4632 - val_loss: 0.4653
Epoch 13/100
0s - loss: 0.4607 - val_loss: 0.4650
Epoch 14/100
0s - loss: 0.4592 - val_loss: 0.4634
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:01,720 - 16_UsokinAE_450-250_100_tanh|Fold #1 Loss = 0.463400
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5915 - val_loss: 0.5353
Epoch 2/100
0s - loss: 0.5327 - val_loss: 0.5131
Epoch 3/100
0s - loss: 0.5065 - val_loss: 0.4875
Epoch 4/100
0s - loss: 0.4869 - val_loss: 0.4776
Epoch 5/100
0s - loss: 0.4796 - val_loss: 0.4764
Epoch 6/100
0s - loss: 0.4763 - val_loss: 0.4716
Epoch 7/100
0s - loss: 0.4730 - val_loss: 0.4690
Epoch 8/100
0s - loss: 0.4694 - val_loss: 0.4660
Epoch 9/100
0s - loss: 0.4665 - val_loss: 0.4636
Epoch 10/100
0s - loss: 0.4641 - val_loss: 0.4618
Epoch 11/100
0s - loss: 0.4612 - val_loss: 0.4602
Epoch 12/100
0s - loss: 0.4589 - val_loss: 0.4590
Epoch 13/100
0s - loss: 0.4571 - val_loss: 0.4584
Epoch 14/100
0s - loss: 0.4556 - val_loss: 0.4576
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:10,681 - 16_UsokinAE_450-250_100_tanh|Fold #2 Loss = 0.457645
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5877 - val_loss: 0.5468
Epoch 2/100
0s - loss: 0.5367 - val_loss: 0.5318
Epoch 3/100
0s - loss: 0.5153 - val_loss: 0.5079
Epoch 4/100
0s - loss: 0.4925 - val_loss: 0.4928
Epoch 5/100
0s - loss: 0.4806 - val_loss: 0.4882
Epoch 6/100
0s - loss: 0.4757 - val_loss: 0.4864
Epoch 7/100
0s - loss: 0.4734 - val_loss: 0.4835
Epoch 8/100
0s - loss: 0.4708 - val_loss: 0.4813
Epoch 9/100
0s - loss: 0.4679 - val_loss: 0.4793
Epoch 10/100
0s - loss: 0.4651 - val_loss: 0.4778
Epoch 11/100
0s - loss: 0.4627 - val_loss: 0.4759
Epoch 12/100
0s - loss: 0.4609 - val_loss: 0.4746
Epoch 13/100
0s - loss: 0.4586 - val_loss: 0.4731
Epoch 14/100
0s - loss: 0.4569 - val_loss: 0.4724
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:19,621 - 16_UsokinAE_450-250_100_tanh|Fold #3 Loss = 0.472384
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5946 - val_loss: 0.5374
Epoch 2/100
0s - loss: 0.5315 - val_loss: 0.5150
Epoch 3/100
0s - loss: 0.5085 - val_loss: 0.4950
Epoch 4/100
0s - loss: 0.4891 - val_loss: 0.4818
Epoch 5/100
0s - loss: 0.4795 - val_loss: 0.4782
Epoch 6/100
0s - loss: 0.4752 - val_loss: 0.4743
Epoch 7/100
0s - loss: 0.4719 - val_loss: 0.4723
Epoch 8/100
0s - loss: 0.4685 - val_loss: 0.4691
Epoch 9/100
0s - loss: 0.4658 - val_loss: 0.4675
Epoch 10/100
0s - loss: 0.4635 - val_loss: 0.4652
Epoch 11/100
0s - loss: 0.4614 - val_loss: 0.4642
Epoch 12/100
0s - loss: 0.4594 - val_loss: 0.4628
Epoch 13/100
0s - loss: 0.4578 - val_loss: 0.4612
Epoch 14/100
0s - loss: 0.4562 - val_loss: 0.4615
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:28,545 - 16_UsokinAE_450-250_100_tanh|Fold #4 Loss = 0.461488
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5952 - val_loss: 0.5414
Epoch 2/100
0s - loss: 0.5333 - val_loss: 0.5240
Epoch 3/100
0s - loss: 0.5105 - val_loss: 0.5020
Epoch 4/100
0s - loss: 0.4943 - val_loss: 0.4923
Epoch 5/100
0s - loss: 0.4837 - val_loss: 0.4841
Epoch 6/100
0s - loss: 0.4767 - val_loss: 0.4783
Epoch 7/100
0s - loss: 0.4725 - val_loss: 0.4756
Epoch 8/100
0s - loss: 0.4694 - val_loss: 0.4731
Epoch 9/100
0s - loss: 0.4665 - val_loss: 0.4727
Epoch 10/100
0s - loss: 0.4646 - val_loss: 0.4707
Epoch 11/100
0s - loss: 0.4627 - val_loss: 0.4691
Epoch 12/100
0s - loss: 0.4606 - val_loss: 0.4676
Epoch 13/100
0s - loss: 0.4586 - val_loss: 0.4667
Epoch 14/100
0s - loss: 0.4573 - val_loss: 0.4644
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:37,623 - 16_UsokinAE_450-250_100_tanh|Fold #5 Loss = 0.464391
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5927 - val_loss: 0.5363
Epoch 2/100
0s - loss: 0.5376 - val_loss: 0.5215
Epoch 3/100
0s - loss: 0.5159 - val_loss: 0.4948
Epoch 4/100
0s - loss: 0.4954 - val_loss: 0.4791
Epoch 5/100
0s - loss: 0.4839 - val_loss: 0.4738
Epoch 6/100
0s - loss: 0.4799 - val_loss: 0.4712
Epoch 7/100
0s - loss: 0.4765 - val_loss: 0.4687
Epoch 8/100
0s - loss: 0.4737 - val_loss: 0.4662
Epoch 9/100
0s - loss: 0.4702 - val_loss: 0.4635
Epoch 10/100
0s - loss: 0.4674 - val_loss: 0.4614
Epoch 11/100
0s - loss: 0.4649 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4628 - val_loss: 0.4579
Epoch 13/100
0s - loss: 0.4605 - val_loss: 0.4564
Epoch 14/100
0s - loss: 0.4587 - val_loss: 0.4550
Epoch 15/100
0s - loss: 0.4567 - val_loss: 0.4551
Epoch 16/100
0s - loss: 0.4555 - val_loss: 0.4540
Epoch 17/100
0s - loss: 0.4540 - val_loss: 0.4532
Epoch 18/100
0s - loss: 0.4521 - val_loss: 0.4527
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:48,718 - 16_UsokinAE_450-250_100_tanh|Fold #6 Loss = 0.452650
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5923 - val_loss: 0.5539
Epoch 2/100
0s - loss: 0.5299 - val_loss: 0.5307
Epoch 3/100
0s - loss: 0.5090 - val_loss: 0.5116
Epoch 4/100
0s - loss: 0.4912 - val_loss: 0.4991
Epoch 5/100
0s - loss: 0.4796 - val_loss: 0.4946
Epoch 6/100
0s - loss: 0.4740 - val_loss: 0.4912
Epoch 7/100
0s - loss: 0.4705 - val_loss: 0.4878
Epoch 8/100
0s - loss: 0.4672 - val_loss: 0.4867
Epoch 9/100
0s - loss: 0.4656 - val_loss: 0.4849
Epoch 10/100
0s - loss: 0.4632 - val_loss: 0.4831
Epoch 11/100
0s - loss: 0.4610 - val_loss: 0.4813
Epoch 12/100
0s - loss: 0.4585 - val_loss: 0.4795
Epoch 13/100
0s - loss: 0.4565 - val_loss: 0.4782
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:22:57,125 - 16_UsokinAE_450-250_100_tanh|Fold #7 Loss = 0.478240
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5916 - val_loss: 0.5341
Epoch 2/100
0s - loss: 0.5364 - val_loss: 0.5225
Epoch 3/100
0s - loss: 0.5150 - val_loss: 0.4994
Epoch 4/100
0s - loss: 0.4957 - val_loss: 0.4843
Epoch 5/100
0s - loss: 0.4837 - val_loss: 0.4759
Epoch 6/100
0s - loss: 0.4784 - val_loss: 0.4729
Epoch 7/100
0s - loss: 0.4752 - val_loss: 0.4680
Epoch 8/100
0s - loss: 0.4722 - val_loss: 0.4658
Epoch 9/100
0s - loss: 0.4698 - val_loss: 0.4629
Epoch 10/100
0s - loss: 0.4672 - val_loss: 0.4610
Epoch 11/100
0s - loss: 0.4653 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4628 - val_loss: 0.4577
Epoch 13/100
0s - loss: 0.4604 - val_loss: 0.4568
Epoch 14/100
0s - loss: 0.4586 - val_loss: 0.4554
Epoch 15/100
0s - loss: 0.4570 - val_loss: 0.4541
Epoch 16/100
0s - loss: 0.4554 - val_loss: 0.4531
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:06,980 - 16_UsokinAE_450-250_100_tanh|Fold #8 Loss = 0.453114
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5918 - val_loss: 0.5412
Epoch 2/100
0s - loss: 0.5323 - val_loss: 0.5192
Epoch 3/100
0s - loss: 0.5059 - val_loss: 0.4974
Epoch 4/100
0s - loss: 0.4878 - val_loss: 0.4874
Epoch 5/100
0s - loss: 0.4796 - val_loss: 0.4834
Epoch 6/100
0s - loss: 0.4755 - val_loss: 0.4826
Epoch 7/100
0s - loss: 0.4731 - val_loss: 0.4800
Epoch 8/100
0s - loss: 0.4706 - val_loss: 0.4791
Epoch 9/100
0s - loss: 0.4680 - val_loss: 0.4747
Epoch 10/100
0s - loss: 0.4647 - val_loss: 0.4728
Epoch 11/100
0s - loss: 0.4621 - val_loss: 0.4702
Epoch 12/100
0s - loss: 0.4593 - val_loss: 0.4685
Epoch 13/100
0s - loss: 0.4571 - val_loss: 0.4681
Epoch 14/100
0s - loss: 0.4559 - val_loss: 0.4667
Epoch 15/100
0s - loss: 0.4540 - val_loss: 0.4660
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:16,488 - 16_UsokinAE_450-250_100_tanh|Fold #9 Loss = 0.465974
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5871 - val_loss: 0.5403
Epoch 2/100
0s - loss: 0.5310 - val_loss: 0.5178
Epoch 3/100
0s - loss: 0.5125 - val_loss: 0.5025
Epoch 4/100
0s - loss: 0.4959 - val_loss: 0.4847
Epoch 5/100
0s - loss: 0.4827 - val_loss: 0.4749
Epoch 6/100
0s - loss: 0.4766 - val_loss: 0.4703
Epoch 7/100
0s - loss: 0.4730 - val_loss: 0.4684
Epoch 8/100
0s - loss: 0.4702 - val_loss: 0.4663
Epoch 9/100
0s - loss: 0.4679 - val_loss: 0.4644
Epoch 10/100
0s - loss: 0.4656 - val_loss: 0.4627
Epoch 11/100
0s - loss: 0.4639 - val_loss: 0.4617
Epoch 12/100
0s - loss: 0.4621 - val_loss: 0.4602
Epoch 13/100
0s - loss: 0.4597 - val_loss: 0.4579
Epoch 14/100
0s - loss: 0.4577 - val_loss: 0.4571
Epoch 15/100
0s - loss: 0.4558 - val_loss: 0.4560
Epoch 16/100
0s - loss: 0.4541 - val_loss: 0.4555
Epoch 17/100
0s - loss: 0.4532 - val_loss: 0.4555
Epoch 18/100
0s - loss: 0.4521 - val_loss: 0.4536
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:27,618 - 16_UsokinAE_450-250_100_tanh|Fold #10 Loss = 0.453605
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:27,618 - 16_UsokinAE_450-250_100_tanh|Avg Validation Loss = 0.462289
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.6200 - val_loss: 0.5496
Epoch 2/100
0s - loss: 0.5450 - val_loss: 0.5371
Epoch 3/100
0s - loss: 0.5323 - val_loss: 0.5229
Epoch 4/100
0s - loss: 0.5161 - val_loss: 0.5035
Epoch 5/100
0s - loss: 0.4972 - val_loss: 0.4871
Epoch 6/100
0s - loss: 0.4837 - val_loss: 0.4808
Epoch 7/100
0s - loss: 0.4783 - val_loss: 0.4770
Epoch 8/100
0s - loss: 0.4756 - val_loss: 0.4759
Epoch 9/100
0s - loss: 0.4744 - val_loss: 0.4743
Epoch 10/100
0s - loss: 0.4723 - val_loss: 0.4742
Epoch 11/100
0s - loss: 0.4706 - val_loss: 0.4732
Epoch 12/100
0s - loss: 0.4688 - val_loss: 0.4707
Epoch 13/100
0s - loss: 0.4667 - val_loss: 0.4705
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:35,923 - 17_UsokinAE_400-300_50_relu|Fold #1 Loss = 0.470518
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6063 - val_loss: 0.5439
Epoch 2/100
0s - loss: 0.5394 - val_loss: 0.5248
Epoch 3/100
0s - loss: 0.5231 - val_loss: 0.5067
Epoch 4/100
0s - loss: 0.5005 - val_loss: 0.4855
Epoch 5/100
0s - loss: 0.4834 - val_loss: 0.4779
Epoch 6/100
0s - loss: 0.4777 - val_loss: 0.4762
Epoch 7/100
0s - loss: 0.4754 - val_loss: 0.4738
Epoch 8/100
0s - loss: 0.4733 - val_loss: 0.4727
Epoch 9/100
0s - loss: 0.4718 - val_loss: 0.4706
Epoch 10/100
0s - loss: 0.4688 - val_loss: 0.4683
Epoch 11/100
0s - loss: 0.4657 - val_loss: 0.4665
Epoch 12/100
0s - loss: 0.4633 - val_loss: 0.4644
Epoch 13/100
0s - loss: 0.4608 - val_loss: 0.4635
Epoch 14/100
0s - loss: 0.4589 - val_loss: 0.4636
Epoch 15/100
0s - loss: 0.4570 - val_loss: 0.4624
Epoch 16/100
0s - loss: 0.4553 - val_loss: 0.4611
Epoch 17/100
0s - loss: 0.4539 - val_loss: 0.4605
Epoch 18/100
0s - loss: 0.4525 - val_loss: 0.4598
Epoch 19/100
0s - loss: 0.4513 - val_loss: 0.4600
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:47,331 - 17_UsokinAE_400-300_50_relu|Fold #2 Loss = 0.460048
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6073 - val_loss: 0.5488
Epoch 2/100
0s - loss: 0.5399 - val_loss: 0.5364
Epoch 3/100
0s - loss: 0.5255 - val_loss: 0.5251
Epoch 4/100
0s - loss: 0.5090 - val_loss: 0.5058
Epoch 5/100
0s - loss: 0.4893 - val_loss: 0.4927
Epoch 6/100
0s - loss: 0.4787 - val_loss: 0.4879
Epoch 7/100
0s - loss: 0.4745 - val_loss: 0.4865
Epoch 8/100
0s - loss: 0.4720 - val_loss: 0.4832
Epoch 9/100
0s - loss: 0.4690 - val_loss: 0.4826
Epoch 10/100
0s - loss: 0.4668 - val_loss: 0.4799
Epoch 11/100
0s - loss: 0.4640 - val_loss: 0.4784
Epoch 12/100
0s - loss: 0.4615 - val_loss: 0.4764
Epoch 13/100
0s - loss: 0.4594 - val_loss: 0.4753
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4743
Epoch 15/100
0s - loss: 0.4559 - val_loss: 0.4738
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:23:56,649 - 17_UsokinAE_400-300_50_relu|Fold #3 Loss = 0.473816
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6183 - val_loss: 0.5501
Epoch 2/100
0s - loss: 0.5443 - val_loss: 0.5329
Epoch 3/100
0s - loss: 0.5306 - val_loss: 0.5210
Epoch 4/100
0s - loss: 0.5173 - val_loss: 0.5060
Epoch 5/100
0s - loss: 0.5008 - val_loss: 0.4919
Epoch 6/100
0s - loss: 0.4858 - val_loss: 0.4810
Epoch 7/100
0s - loss: 0.4776 - val_loss: 0.4777
Epoch 8/100
0s - loss: 0.4743 - val_loss: 0.4756
Epoch 9/100
0s - loss: 0.4720 - val_loss: 0.4742
Epoch 10/100
0s - loss: 0.4696 - val_loss: 0.4729
Epoch 11/100
0s - loss: 0.4675 - val_loss: 0.4714
Epoch 12/100
0s - loss: 0.4658 - val_loss: 0.4708
Epoch 13/100
0s - loss: 0.4639 - val_loss: 0.4681
Epoch 14/100
0s - loss: 0.4617 - val_loss: 0.4665
Epoch 15/100
0s - loss: 0.4595 - val_loss: 0.4656
Epoch 16/100
0s - loss: 0.4581 - val_loss: 0.4651
Epoch 17/100
0s - loss: 0.4577 - val_loss: 0.4647
Epoch 18/100
0s - loss: 0.4562 - val_loss: 0.4625
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:24:07,631 - 17_UsokinAE_400-300_50_relu|Fold #4 Loss = 0.462541
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.6159 - val_loss: 0.5499
Epoch 2/100
0s - loss: 0.5412 - val_loss: 0.5347
Epoch 3/100
0s - loss: 0.5268 - val_loss: 0.5207
Epoch 4/100
0s - loss: 0.5098 - val_loss: 0.5022
Epoch 5/100
0s - loss: 0.4905 - val_loss: 0.4875
Epoch 6/100
0s - loss: 0.4809 - val_loss: 0.4828
Epoch 7/100
0s - loss: 0.4761 - val_loss: 0.4799
Epoch 8/100
0s - loss: 0.4732 - val_loss: 0.4771
Epoch 9/100
0s - loss: 0.4703 - val_loss: 0.4748
Epoch 10/100
0s - loss: 0.4670 - val_loss: 0.4727
Epoch 11/100
0s - loss: 0.4644 - val_loss: 0.4705
Epoch 12/100
0s - loss: 0.4621 - val_loss: 0.4698
Epoch 13/100
0s - loss: 0.4605 - val_loss: 0.4683
Epoch 14/100
0s - loss: 0.4585 - val_loss: 0.4671
Epoch 15/100
0s - loss: 0.4565 - val_loss: 0.4660
Epoch 16/100
0s - loss: 0.4553 - val_loss: 0.4653
Epoch 17/100
0s - loss: 0.4537 - val_loss: 0.4645
Epoch 18/100
0s - loss: 0.4525 - val_loss: 0.4647
Epoch 19/100
0s - loss: 0.4516 - val_loss: 0.4639
Epoch 20/100
0s - loss: 0.4503 - val_loss: 0.4639
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:24:19,618 - 17_UsokinAE_400-300_50_relu|Fold #5 Loss = 0.463869
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.6201 - val_loss: 0.5453
Epoch 2/100
0s - loss: 0.5433 - val_loss: 0.5301
Epoch 3/100
0s - loss: 0.5272 - val_loss: 0.5123
Epoch 4/100
0s - loss: 0.5073 - val_loss: 0.4879
Epoch 5/100
0s - loss: 0.4890 - val_loss: 0.4781
Epoch 6/100
0s - loss: 0.4809 - val_loss: 0.4719
Epoch 7/100
0s - loss: 0.4776 - val_loss: 0.4701
Epoch 8/100
0s - loss: 0.4752 - val_loss: 0.4705
Epoch 9/100
0s - loss: 0.4733 - val_loss: 0.4667
Epoch 10/100
0s - loss: 0.4702 - val_loss: 0.4647
Epoch 11/100
0s - loss: 0.4673 - val_loss: 0.4643
Epoch 12/100
0s - loss: 0.4653 - val_loss: 0.4614
Epoch 13/100
0s - loss: 0.4631 - val_loss: 0.4597
Epoch 14/100
0s - loss: 0.4610 - val_loss: 0.4589
Epoch 15/100
0s - loss: 0.4595 - val_loss: 0.4586
Epoch 16/100
0s - loss: 0.4584 - val_loss: 0.4583
Epoch 17/100
0s - loss: 0.4569 - val_loss: 0.4573
Epoch 18/100
0s - loss: 0.4554 - val_loss: 0.4573
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:24:30,573 - 17_UsokinAE_400-300_50_relu|Fold #6 Loss = 0.457284
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6107 - val_loss: 0.5566
Epoch 2/100
0s - loss: 0.5388 - val_loss: 0.5400
Epoch 3/100
0s - loss: 0.5204 - val_loss: 0.5230
Epoch 4/100
0s - loss: 0.4993 - val_loss: 0.5067
Epoch 5/100
0s - loss: 0.4835 - val_loss: 0.4977
Epoch 6/100
0s - loss: 0.4762 - val_loss: 0.4934
Epoch 7/100
0s - loss: 0.4730 - val_loss: 0.4916
Epoch 8/100
0s - loss: 0.4707 - val_loss: 0.4900
Epoch 9/100
0s - loss: 0.4682 - val_loss: 0.4876
Epoch 10/100
0s - loss: 0.4658 - val_loss: 0.4855
Epoch 11/100
0s - loss: 0.4632 - val_loss: 0.4832
Epoch 12/100
0s - loss: 0.4611 - val_loss: 0.4821
Epoch 13/100
0s - loss: 0.4593 - val_loss: 0.4809
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4795
Epoch 15/100
0s - loss: 0.4554 - val_loss: 0.4794
Epoch 16/100
0s - loss: 0.4540 - val_loss: 0.4780
Epoch 17/100
0s - loss: 0.4525 - val_loss: 0.4773
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:24:41,089 - 17_UsokinAE_400-300_50_relu|Fold #7 Loss = 0.477282
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.6191 - val_loss: 0.5487
Epoch 2/100
0s - loss: 0.5413 - val_loss: 0.5282
Epoch 3/100
0s - loss: 0.5221 - val_loss: 0.5087
Epoch 4/100
0s - loss: 0.5038 - val_loss: 0.4919
Epoch 5/100
0s - loss: 0.4887 - val_loss: 0.4791
Epoch 6/100
0s - loss: 0.4798 - val_loss: 0.4756
Epoch 7/100
0s - loss: 0.4764 - val_loss: 0.4729
Epoch 8/100
0s - loss: 0.4741 - val_loss: 0.4710
Epoch 9/100
0s - loss: 0.4714 - val_loss: 0.4680
Epoch 10/100
0s - loss: 0.4692 - val_loss: 0.4662
Epoch 11/100
0s - loss: 0.4666 - val_loss: 0.4632
Epoch 12/100
0s - loss: 0.4642 - val_loss: 0.4614
Epoch 13/100
0s - loss: 0.4621 - val_loss: 0.4601
Epoch 14/100
0s - loss: 0.4604 - val_loss: 0.4592
Epoch 15/100
0s - loss: 0.4585 - val_loss: 0.4584
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:24:50,460 - 17_UsokinAE_400-300_50_relu|Fold #8 Loss = 0.458366
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.6119 - val_loss: 0.5471
Epoch 2/100
0s - loss: 0.5428 - val_loss: 0.5344
Epoch 3/100
0s - loss: 0.5274 - val_loss: 0.5215
Epoch 4/100
0s - loss: 0.5088 - val_loss: 0.5033
Epoch 5/100
0s - loss: 0.4907 - val_loss: 0.4922
Epoch 6/100
0s - loss: 0.4809 - val_loss: 0.4857
Epoch 7/100
0s - loss: 0.4757 - val_loss: 0.4822
Epoch 8/100
0s - loss: 0.4726 - val_loss: 0.4812
Epoch 9/100
0s - loss: 0.4701 - val_loss: 0.4790
Epoch 10/100
0s - loss: 0.4678 - val_loss: 0.4771
Epoch 11/100
0s - loss: 0.4656 - val_loss: 0.4757
Epoch 12/100
0s - loss: 0.4631 - val_loss: 0.4744
Epoch 13/100
0s - loss: 0.4612 - val_loss: 0.4728
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:24:58,664 - 17_UsokinAE_400-300_50_relu|Fold #9 Loss = 0.472752
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.6121 - val_loss: 0.5508
Epoch 2/100
0s - loss: 0.5423 - val_loss: 0.5328
Epoch 3/100
0s - loss: 0.5248 - val_loss: 0.5132
Epoch 4/100
0s - loss: 0.5036 - val_loss: 0.4919
Epoch 5/100
0s - loss: 0.4871 - val_loss: 0.4786
Epoch 6/100
0s - loss: 0.4793 - val_loss: 0.4746
Epoch 7/100
0s - loss: 0.4753 - val_loss: 0.4711
Epoch 8/100
0s - loss: 0.4728 - val_loss: 0.4695
Epoch 9/100
0s - loss: 0.4695 - val_loss: 0.4666
Epoch 10/100
0s - loss: 0.4667 - val_loss: 0.4655
Epoch 11/100
0s - loss: 0.4647 - val_loss: 0.4637
Epoch 12/100
0s - loss: 0.4628 - val_loss: 0.4631
Epoch 13/100
0s - loss: 0.4614 - val_loss: 0.4615
Epoch 14/100
0s - loss: 0.4594 - val_loss: 0.4601
Epoch 15/100
0s - loss: 0.4576 - val_loss: 0.4598
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:25:08,110 - 17_UsokinAE_400-300_50_relu|Fold #10 Loss = 0.459774
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:25:08,111 - 17_UsokinAE_400-300_50_relu|Avg Validation Loss = 0.465625
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6582 - val_loss: 0.6609
Epoch 2/100
0s - loss: 0.5086 - val_loss: 0.5888
Epoch 3/100
0s - loss: 0.4797 - val_loss: 0.5857
Epoch 4/100
0s - loss: 0.4682 - val_loss: 0.5593
Epoch 5/100
0s - loss: 0.4642 - val_loss: 0.5508
Epoch 6/100
0s - loss: 0.4598 - val_loss: 0.5374
Epoch 7/100
0s - loss: 0.4587 - val_loss: 0.5330
Epoch 8/100
0s - loss: 0.4573 - val_loss: 0.5083
Epoch 9/100
0s - loss: 0.4547 - val_loss: 0.5037
Epoch 10/100
0s - loss: 0.4519 - val_loss: 0.5050
Epoch 11/100
0s - loss: 0.4523 - val_loss: 0.4927
Epoch 12/100
0s - loss: 0.4499 - val_loss: 0.4935
Epoch 13/100
0s - loss: 0.4478 - val_loss: 0.4869
Epoch 14/100
0s - loss: 0.4478 - val_loss: 0.4823
Epoch 15/100
0s - loss: 0.4445 - val_loss: 0.4752
Epoch 16/100
0s - loss: 0.4437 - val_loss: 0.4764
Epoch 17/100
0s - loss: 0.4410 - val_loss: 0.4699
Epoch 18/100
0s - loss: 0.4419 - val_loss: 0.4678
Epoch 19/100
0s - loss: 0.4399 - val_loss: 0.4650
Epoch 20/100
0s - loss: 0.4394 - val_loss: 0.4660
Epoch 21/100
0s - loss: 0.4366 - val_loss: 0.4634
Epoch 22/100
0s - loss: 0.4353 - val_loss: 0.4627
Epoch 23/100
0s - loss: 0.4346 - val_loss: 0.4678
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:25:26,240 - 18_UsokinAE_350-250_100_elu_BN|Fold #1 Loss = 0.467784
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6549 - val_loss: 0.6679
Epoch 2/100
0s - loss: 0.5050 - val_loss: 0.5895
Epoch 3/100
0s - loss: 0.4768 - val_loss: 0.5895
Epoch 4/100
0s - loss: 0.4665 - val_loss: 0.5718
Epoch 5/100
0s - loss: 0.4604 - val_loss: 0.5546
Epoch 6/100
0s - loss: 0.4556 - val_loss: 0.5280
Epoch 7/100
0s - loss: 0.4510 - val_loss: 0.5260
Epoch 8/100
0s - loss: 0.4477 - val_loss: 0.5062
Epoch 9/100
0s - loss: 0.4432 - val_loss: 0.4984
Epoch 10/100
0s - loss: 0.4407 - val_loss: 0.4893
Epoch 11/100
0s - loss: 0.4368 - val_loss: 0.4836
Epoch 12/100
0s - loss: 0.4342 - val_loss: 0.4741
Epoch 13/100
0s - loss: 0.4314 - val_loss: 0.4711
Epoch 14/100
0s - loss: 0.4283 - val_loss: 0.4637
Epoch 15/100
0s - loss: 0.4271 - val_loss: 0.4634
Epoch 16/100
0s - loss: 0.4242 - val_loss: 0.4606
Epoch 17/100
0s - loss: 0.4223 - val_loss: 0.4599
Epoch 18/100
0s - loss: 0.4191 - val_loss: 0.4561
Epoch 19/100
0s - loss: 0.4163 - val_loss: 0.4521
Epoch 20/100
0s - loss: 0.4139 - val_loss: 0.4534
Epoch 21/100
0s - loss: 0.4119 - val_loss: 0.4519
Epoch 22/100
0s - loss: 0.4102 - val_loss: 0.4506
Epoch 23/100
0s - loss: 0.4081 - val_loss: 0.4507
Epoch 24/100
0s - loss: 0.4082 - val_loss: 0.4522
Epoch 25/100
0s - loss: 0.4055 - val_loss: 0.4497
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:25:45,376 - 18_UsokinAE_350-250_100_elu_BN|Fold #2 Loss = 0.449744
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6543 - val_loss: 0.6656
Epoch 2/100
0s - loss: 0.5038 - val_loss: 0.5850
Epoch 3/100
0s - loss: 0.4756 - val_loss: 0.5844
Epoch 4/100
0s - loss: 0.4640 - val_loss: 0.5530
Epoch 5/100
0s - loss: 0.4579 - val_loss: 0.5352
Epoch 6/100
0s - loss: 0.4533 - val_loss: 0.5313
Epoch 7/100
0s - loss: 0.4488 - val_loss: 0.5236
Epoch 8/100
0s - loss: 0.4452 - val_loss: 0.5079
Epoch 9/100
0s - loss: 0.4438 - val_loss: 0.5018
Epoch 10/100
0s - loss: 0.4405 - val_loss: 0.4983
Epoch 11/100
0s - loss: 0.4366 - val_loss: 0.4836
Epoch 12/100
0s - loss: 0.4336 - val_loss: 0.4850
Epoch 13/100
0s - loss: 0.4304 - val_loss: 0.4810
Epoch 14/100
0s - loss: 0.4273 - val_loss: 0.4791
Epoch 15/100
0s - loss: 0.4258 - val_loss: 0.4744
Epoch 16/100
0s - loss: 0.4222 - val_loss: 0.4720
Epoch 17/100
0s - loss: 0.4193 - val_loss: 0.4705
Epoch 18/100
0s - loss: 0.4175 - val_loss: 0.4708
Epoch 19/100
0s - loss: 0.4159 - val_loss: 0.4693
Epoch 20/100
0s - loss: 0.4135 - val_loss: 0.4696
Epoch 21/100
0s - loss: 0.4117 - val_loss: 0.4678
Epoch 22/100
0s - loss: 0.4090 - val_loss: 0.4660
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:26:02,785 - 18_UsokinAE_350-250_100_elu_BN|Fold #3 Loss = 0.465996
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6586 - val_loss: 0.6717
Epoch 2/100
0s - loss: 0.5070 - val_loss: 0.5661
Epoch 3/100
0s - loss: 0.4763 - val_loss: 0.5920
Epoch 4/100
0s - loss: 0.4680 - val_loss: 0.5375
Epoch 5/100
0s - loss: 0.4619 - val_loss: 0.5425
Epoch 6/100
0s - loss: 0.4556 - val_loss: 0.5260
Epoch 7/100
0s - loss: 0.4530 - val_loss: 0.5119
Epoch 8/100
0s - loss: 0.4493 - val_loss: 0.5087
Epoch 9/100
0s - loss: 0.4442 - val_loss: 0.4958
Epoch 10/100
0s - loss: 0.4402 - val_loss: 0.4908
Epoch 11/100
0s - loss: 0.4380 - val_loss: 0.4821
Epoch 12/100
0s - loss: 0.4350 - val_loss: 0.4758
Epoch 13/100
0s - loss: 0.4312 - val_loss: 0.4761
Epoch 14/100
0s - loss: 0.4287 - val_loss: 0.4727
Epoch 15/100
0s - loss: 0.4259 - val_loss: 0.4672
Epoch 16/100
0s - loss: 0.4233 - val_loss: 0.4682
Epoch 17/100
0s - loss: 0.4213 - val_loss: 0.4613
Epoch 18/100
0s - loss: 0.4188 - val_loss: 0.4653
Epoch 19/100
0s - loss: 0.4160 - val_loss: 0.4605
Epoch 20/100
0s - loss: 0.4146 - val_loss: 0.4607
Epoch 21/100
0s - loss: 0.4127 - val_loss: 0.4586
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:26:19,844 - 18_UsokinAE_350-250_100_elu_BN|Fold #4 Loss = 0.458636
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6477 - val_loss: 0.6601
Epoch 2/100
0s - loss: 0.5007 - val_loss: 0.5936
Epoch 3/100
0s - loss: 0.4759 - val_loss: 0.5822
Epoch 4/100
0s - loss: 0.4645 - val_loss: 0.5618
Epoch 5/100
0s - loss: 0.4590 - val_loss: 0.5475
Epoch 6/100
0s - loss: 0.4543 - val_loss: 0.5319
Epoch 7/100
0s - loss: 0.4500 - val_loss: 0.5202
Epoch 8/100
0s - loss: 0.4470 - val_loss: 0.5087
Epoch 9/100
0s - loss: 0.4435 - val_loss: 0.4948
Epoch 10/100
0s - loss: 0.4412 - val_loss: 0.4890
Epoch 11/100
0s - loss: 0.4364 - val_loss: 0.4828
Epoch 12/100
0s - loss: 0.4349 - val_loss: 0.4790
Epoch 13/100
0s - loss: 0.4314 - val_loss: 0.4762
Epoch 14/100
0s - loss: 0.4288 - val_loss: 0.4736
Epoch 15/100
0s - loss: 0.4256 - val_loss: 0.4690
Epoch 16/100
0s - loss: 0.4234 - val_loss: 0.4696
Epoch 17/100
0s - loss: 0.4202 - val_loss: 0.4629
Epoch 18/100
0s - loss: 0.4185 - val_loss: 0.4605
Epoch 19/100
0s - loss: 0.4157 - val_loss: 0.4604
Epoch 20/100
0s - loss: 0.4132 - val_loss: 0.4607
Epoch 21/100
0s - loss: 0.4122 - val_loss: 0.4592
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:26:36,747 - 18_UsokinAE_350-250_100_elu_BN|Fold #5 Loss = 0.459169
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6606 - val_loss: 0.6639
Epoch 2/100
0s - loss: 0.5098 - val_loss: 0.5905
Epoch 3/100
0s - loss: 0.4787 - val_loss: 0.5773
Epoch 4/100
0s - loss: 0.4695 - val_loss: 0.5556
Epoch 5/100
0s - loss: 0.4655 - val_loss: 0.5477
Epoch 6/100
0s - loss: 0.4611 - val_loss: 0.5299
Epoch 7/100
0s - loss: 0.4556 - val_loss: 0.5141
Epoch 8/100
0s - loss: 0.4519 - val_loss: 0.5089
Epoch 9/100
0s - loss: 0.4479 - val_loss: 0.4901
Epoch 10/100
0s - loss: 0.4455 - val_loss: 0.4725
Epoch 11/100
0s - loss: 0.4422 - val_loss: 0.4793
Epoch 12/100
0s - loss: 0.4403 - val_loss: 0.4763
Epoch 13/100
0s - loss: 0.4377 - val_loss: 0.4737
Epoch 14/100
0s - loss: 0.4357 - val_loss: 0.4679
Epoch 15/100
0s - loss: 0.4319 - val_loss: 0.4637
Epoch 16/100
0s - loss: 0.4298 - val_loss: 0.4624
Epoch 17/100
0s - loss: 0.4277 - val_loss: 0.4573
Epoch 18/100
0s - loss: 0.4251 - val_loss: 0.4563
Epoch 19/100
0s - loss: 0.4234 - val_loss: 0.4536
Epoch 20/100
0s - loss: 0.4228 - val_loss: 0.4585
Epoch 21/100
0s - loss: 0.4215 - val_loss: 0.4547
Epoch 22/100
0s - loss: 0.4189 - val_loss: 0.4514
Epoch 23/100
0s - loss: 0.4152 - val_loss: 0.4526
Epoch 24/100
0s - loss: 0.4146 - val_loss: 0.4511
Epoch 25/100
0s - loss: 0.4142 - val_loss: 0.4512
Epoch 26/100
0s - loss: 0.4118 - val_loss: 0.4481
Epoch 27/100
0s - loss: 0.4122 - val_loss: 0.4625
Epoch 28/100
0s - loss: 0.4107 - val_loss: 0.4537
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:26:57,419 - 18_UsokinAE_350-250_100_elu_BN|Fold #6 Loss = 0.453740
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6545 - val_loss: 0.6526
Epoch 2/100
0s - loss: 0.5040 - val_loss: 0.5955
Epoch 3/100
0s - loss: 0.4769 - val_loss: 0.5782
Epoch 4/100
0s - loss: 0.4663 - val_loss: 0.5651
Epoch 5/100
0s - loss: 0.4592 - val_loss: 0.5447
Epoch 6/100
0s - loss: 0.4555 - val_loss: 0.5278
Epoch 7/100
0s - loss: 0.4507 - val_loss: 0.5230
Epoch 8/100
0s - loss: 0.4470 - val_loss: 0.5112
Epoch 9/100
0s - loss: 0.4429 - val_loss: 0.5095
Epoch 10/100
0s - loss: 0.4394 - val_loss: 0.4990
Epoch 11/100
0s - loss: 0.4356 - val_loss: 0.4972
Epoch 12/100
0s - loss: 0.4349 - val_loss: 0.4904
Epoch 13/100
0s - loss: 0.4309 - val_loss: 0.4861
Epoch 14/100
0s - loss: 0.4283 - val_loss: 0.4799
Epoch 15/100
0s - loss: 0.4255 - val_loss: 0.4810
Epoch 16/100
0s - loss: 0.4226 - val_loss: 0.4783
Epoch 17/100
0s - loss: 0.4203 - val_loss: 0.4730
Epoch 18/100
0s - loss: 0.4181 - val_loss: 0.4764
Epoch 19/100
0s - loss: 0.4161 - val_loss: 0.4741
Epoch 20/100
0s - loss: 0.4129 - val_loss: 0.4718
Epoch 21/100
0s - loss: 0.4109 - val_loss: 0.4692
Epoch 22/100
0s - loss: 0.4090 - val_loss: 0.4707
Epoch 23/100
0s - loss: 0.4072 - val_loss: 0.4715
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:27:15,600 - 18_UsokinAE_350-250_100_elu_BN|Fold #7 Loss = 0.471548
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6575 - val_loss: 0.6722
Epoch 2/100
0s - loss: 0.5069 - val_loss: 0.5917
Epoch 3/100
0s - loss: 0.4778 - val_loss: 0.5832
Epoch 4/100
0s - loss: 0.4684 - val_loss: 0.5500
Epoch 5/100
0s - loss: 0.4613 - val_loss: 0.5401
Epoch 6/100
0s - loss: 0.4560 - val_loss: 0.5189
Epoch 7/100
0s - loss: 0.4531 - val_loss: 0.5080
Epoch 8/100
0s - loss: 0.4478 - val_loss: 0.4997
Epoch 9/100
0s - loss: 0.4446 - val_loss: 0.4874
Epoch 10/100
0s - loss: 0.4408 - val_loss: 0.4811
Epoch 11/100
0s - loss: 0.4396 - val_loss: 0.4770
Epoch 12/100
0s - loss: 0.4355 - val_loss: 0.4731
Epoch 13/100
0s - loss: 0.4318 - val_loss: 0.4717
Epoch 14/100
0s - loss: 0.4287 - val_loss: 0.4659
Epoch 15/100
0s - loss: 0.4263 - val_loss: 0.4616
Epoch 16/100
0s - loss: 0.4239 - val_loss: 0.4614
Epoch 17/100
0s - loss: 0.4211 - val_loss: 0.4583
Epoch 18/100
0s - loss: 0.4197 - val_loss: 0.4543
Epoch 19/100
0s - loss: 0.4168 - val_loss: 0.4532
Epoch 20/100
0s - loss: 0.4148 - val_loss: 0.4495
Epoch 21/100
0s - loss: 0.4136 - val_loss: 0.4487
Epoch 22/100
0s - loss: 0.4110 - val_loss: 0.4519
Epoch 23/100
0s - loss: 0.4090 - val_loss: 0.4478
Epoch 24/100
0s - loss: 0.4080 - val_loss: 0.4494
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:27:34,222 - 18_UsokinAE_350-250_100_elu_BN|Fold #8 Loss = 0.449366
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6573 - val_loss: 0.6764
Epoch 2/100
0s - loss: 0.5050 - val_loss: 0.6084
Epoch 3/100
0s - loss: 0.4752 - val_loss: 0.6115
Epoch 4/100
0s - loss: 0.4648 - val_loss: 0.5818
Epoch 5/100
0s - loss: 0.4588 - val_loss: 0.5501
Epoch 6/100
0s - loss: 0.4544 - val_loss: 0.5344
Epoch 7/100
0s - loss: 0.4503 - val_loss: 0.5212
Epoch 8/100
0s - loss: 0.4464 - val_loss: 0.5078
Epoch 9/100
0s - loss: 0.4424 - val_loss: 0.4983
Epoch 10/100
0s - loss: 0.4389 - val_loss: 0.4885
Epoch 11/100
0s - loss: 0.4364 - val_loss: 0.4817
Epoch 12/100
0s - loss: 0.4341 - val_loss: 0.4778
Epoch 13/100
0s - loss: 0.4310 - val_loss: 0.4778
Epoch 14/100
0s - loss: 0.4293 - val_loss: 0.4713
Epoch 15/100
0s - loss: 0.4256 - val_loss: 0.4710
Epoch 16/100
0s - loss: 0.4236 - val_loss: 0.4647
Epoch 17/100
0s - loss: 0.4208 - val_loss: 0.4653
Epoch 18/100
0s - loss: 0.4192 - val_loss: 0.4635
Epoch 19/100
0s - loss: 0.4172 - val_loss: 0.4647
Epoch 20/100
0s - loss: 0.4147 - val_loss: 0.4615
Epoch 21/100
0s - loss: 0.4127 - val_loss: 0.4629
Epoch 22/100
0s - loss: 0.4101 - val_loss: 0.4590
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:27:51,694 - 18_UsokinAE_350-250_100_elu_BN|Fold #9 Loss = 0.458969
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6569 - val_loss: 0.6644
Epoch 2/100
0s - loss: 0.5069 - val_loss: 0.5615
Epoch 3/100
0s - loss: 0.4762 - val_loss: 0.5525
Epoch 4/100
0s - loss: 0.4672 - val_loss: 0.5419
Epoch 5/100
0s - loss: 0.4610 - val_loss: 0.5235
Epoch 6/100
0s - loss: 0.4549 - val_loss: 0.5158
Epoch 7/100
0s - loss: 0.4492 - val_loss: 0.5094
Epoch 8/100
0s - loss: 0.4458 - val_loss: 0.4943
Epoch 9/100
0s - loss: 0.4423 - val_loss: 0.4911
Epoch 10/100
0s - loss: 0.4394 - val_loss: 0.4856
Epoch 11/100
0s - loss: 0.4369 - val_loss: 0.4747
Epoch 12/100
0s - loss: 0.4340 - val_loss: 0.4740
Epoch 13/100
0s - loss: 0.4297 - val_loss: 0.4704
Epoch 14/100
0s - loss: 0.4271 - val_loss: 0.4654
Epoch 15/100
0s - loss: 0.4241 - val_loss: 0.4602
Epoch 16/100
0s - loss: 0.4217 - val_loss: 0.4586
Epoch 17/100
0s - loss: 0.4186 - val_loss: 0.4589
Epoch 18/100
0s - loss: 0.4168 - val_loss: 0.4564
Epoch 19/100
0s - loss: 0.4150 - val_loss: 0.4540
Epoch 20/100
0s - loss: 0.4128 - val_loss: 0.4522
Epoch 21/100
0s - loss: 0.4103 - val_loss: 0.4524
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:28:08,726 - 18_UsokinAE_350-250_100_elu_BN|Fold #10 Loss = 0.452385
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:28:08,726 - 18_UsokinAE_350-250_100_elu_BN|Avg Validation Loss = 0.458734
Train on 553 samples, validate on 69 samples
Epoch 1/100
2s - loss: 0.6836 - val_loss: 0.7251
Epoch 2/100
0s - loss: 0.6199 - val_loss: 0.7380
Epoch 3/100
0s - loss: 0.5462 - val_loss: 0.7494
Epoch 4/100
0s - loss: 0.4965 - val_loss: 0.7496
Epoch 5/100
0s - loss: 0.4844 - val_loss: 0.6162
Epoch 6/100
0s - loss: 0.4789 - val_loss: 0.5982
Epoch 7/100
0s - loss: 0.4784 - val_loss: 0.5469
Epoch 8/100
0s - loss: 0.4781 - val_loss: 0.5182
Epoch 9/100
0s - loss: 0.4743 - val_loss: 0.5169
Epoch 10/100
0s - loss: 0.4711 - val_loss: 0.5063
Epoch 11/100
0s - loss: 0.4702 - val_loss: 0.4938
Epoch 12/100
0s - loss: 0.4734 - val_loss: 0.4967
Epoch 13/100
0s - loss: 0.4715 - val_loss: 0.4877
Epoch 14/100
0s - loss: 0.4681 - val_loss: 0.4872
Epoch 15/100
0s - loss: 0.4669 - val_loss: 0.4824
Epoch 16/100
0s - loss: 0.4682 - val_loss: 0.4834
Epoch 17/100
0s - loss: 0.4669 - val_loss: 0.4760
Epoch 18/100
0s - loss: 0.4674 - val_loss: 0.4753
Epoch 19/100
0s - loss: 0.4662 - val_loss: 0.4746
Epoch 20/100
0s - loss: 0.4632 - val_loss: 0.4706
Epoch 21/100
0s - loss: 0.4618 - val_loss: 0.4699
Epoch 22/100
0s - loss: 0.4608 - val_loss: 0.4683
Epoch 23/100
0s - loss: 0.4599 - val_loss: 0.4678
Epoch 24/100
0s - loss: 0.4581 - val_loss: 0.4668
Epoch 25/100
0s - loss: 0.4576 - val_loss: 0.4670
Epoch 26/100
0s - loss: 0.4568 - val_loss: 0.4672
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:28:28,031 - 19_UsokinAE_350-250_50_tanh_BN|Fold #1 Loss = 0.467243
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6819 - val_loss: 0.7146
Epoch 2/100
0s - loss: 0.6158 - val_loss: 0.7107
Epoch 3/100
0s - loss: 0.5384 - val_loss: 0.7013
Epoch 4/100
0s - loss: 0.4913 - val_loss: 0.6355
Epoch 5/100
0s - loss: 0.4823 - val_loss: 0.5744
Epoch 6/100
0s - loss: 0.4735 - val_loss: 0.6189
Epoch 7/100
0s - loss: 0.4699 - val_loss: 0.5352
Epoch 8/100
0s - loss: 0.4692 - val_loss: 0.5129
Epoch 9/100
0s - loss: 0.4664 - val_loss: 0.4974
Epoch 10/100
0s - loss: 0.4667 - val_loss: 0.4919
Epoch 11/100
0s - loss: 0.4629 - val_loss: 0.4835
Epoch 12/100
0s - loss: 0.4613 - val_loss: 0.4808
Epoch 13/100
0s - loss: 0.4597 - val_loss: 0.4715
Epoch 14/100
0s - loss: 0.4574 - val_loss: 0.4693
Epoch 15/100
0s - loss: 0.4560 - val_loss: 0.4733
Epoch 16/100
0s - loss: 0.4545 - val_loss: 0.4668
Epoch 17/100
0s - loss: 0.4532 - val_loss: 0.4638
Epoch 18/100
0s - loss: 0.4516 - val_loss: 0.4619
Epoch 19/100
0s - loss: 0.4503 - val_loss: 0.4613
Epoch 20/100
0s - loss: 0.4501 - val_loss: 0.4605
Epoch 21/100
0s - loss: 0.4492 - val_loss: 0.4591
Epoch 22/100
0s - loss: 0.4482 - val_loss: 0.4585
Epoch 23/100
0s - loss: 0.4484 - val_loss: 0.4590
Epoch 24/100
0s - loss: 0.4460 - val_loss: 0.4590
Epoch 25/100
0s - loss: 0.4450 - val_loss: 0.4584
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:28:47,141 - 19_UsokinAE_350-250_50_tanh_BN|Fold #2 Loss = 0.458437
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6823 - val_loss: 0.7180
Epoch 2/100
0s - loss: 0.6124 - val_loss: 0.6881
Epoch 3/100
0s - loss: 0.5308 - val_loss: 0.7312
Epoch 4/100
0s - loss: 0.4930 - val_loss: 0.6400
Epoch 5/100
0s - loss: 0.4801 - val_loss: 0.5601
Epoch 6/100
0s - loss: 0.4811 - val_loss: 0.5250
Epoch 7/100
0s - loss: 0.4730 - val_loss: 0.5535
Epoch 8/100
0s - loss: 0.4694 - val_loss: 0.5133
Epoch 9/100
0s - loss: 0.4653 - val_loss: 0.5181
Epoch 10/100
0s - loss: 0.4646 - val_loss: 0.4964
Epoch 11/100
0s - loss: 0.4618 - val_loss: 0.4920
Epoch 12/100
0s - loss: 0.4603 - val_loss: 0.4865
Epoch 13/100
0s - loss: 0.4588 - val_loss: 0.4839
Epoch 14/100
0s - loss: 0.4572 - val_loss: 0.4823
Epoch 15/100
0s - loss: 0.4564 - val_loss: 0.4781
Epoch 16/100
0s - loss: 0.4560 - val_loss: 0.4786
Epoch 17/100
0s - loss: 0.4543 - val_loss: 0.4791
Epoch 18/100
0s - loss: 0.4547 - val_loss: 0.4770
Epoch 19/100
0s - loss: 0.4524 - val_loss: 0.4754
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:29:02,995 - 19_UsokinAE_350-250_50_tanh_BN|Fold #3 Loss = 0.475352
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6829 - val_loss: 0.7254
Epoch 2/100
0s - loss: 0.6135 - val_loss: 0.6966
Epoch 3/100
0s - loss: 0.5383 - val_loss: 0.6966
Epoch 4/100
0s - loss: 0.4955 - val_loss: 0.6614
Epoch 5/100
0s - loss: 0.4814 - val_loss: 0.5818
Epoch 6/100
0s - loss: 0.4847 - val_loss: 0.6016
Epoch 7/100
0s - loss: 0.4828 - val_loss: 0.5633
Epoch 8/100
0s - loss: 0.4738 - val_loss: 0.5592
Epoch 9/100
0s - loss: 0.4700 - val_loss: 0.5131
Epoch 10/100
0s - loss: 0.4693 - val_loss: 0.5043
Epoch 11/100
0s - loss: 0.4660 - val_loss: 0.4959
Epoch 12/100
0s - loss: 0.4651 - val_loss: 0.4838
Epoch 13/100
0s - loss: 0.4659 - val_loss: 0.4891
Epoch 14/100
0s - loss: 0.4623 - val_loss: 0.4844
Epoch 15/100
0s - loss: 0.4605 - val_loss: 0.4785
Epoch 16/100
0s - loss: 0.4593 - val_loss: 0.4737
Epoch 17/100
0s - loss: 0.4587 - val_loss: 0.4714
Epoch 18/100
0s - loss: 0.4572 - val_loss: 0.4704
Epoch 19/100
0s - loss: 0.4555 - val_loss: 0.4687
Epoch 20/100
0s - loss: 0.4544 - val_loss: 0.4669
Epoch 21/100
0s - loss: 0.4529 - val_loss: 0.4654
Epoch 22/100
0s - loss: 0.4515 - val_loss: 0.4636
Epoch 23/100
0s - loss: 0.4504 - val_loss: 0.4635
Epoch 24/100
0s - loss: 0.4493 - val_loss: 0.4630
Epoch 25/100
0s - loss: 0.4481 - val_loss: 0.4621
Epoch 26/100
0s - loss: 0.4475 - val_loss: 0.4619
Epoch 27/100
0s - loss: 0.4464 - val_loss: 0.4613
Epoch 28/100
0s - loss: 0.4453 - val_loss: 0.4614
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:29:23,492 - 19_UsokinAE_350-250_50_tanh_BN|Fold #4 Loss = 0.461359
Train on 562 samples, validate on 60 samples
Epoch 1/100
2s - loss: 0.6839 - val_loss: 0.7023
Epoch 2/100
0s - loss: 0.6148 - val_loss: 0.7037
Epoch 3/100
0s - loss: 0.5310 - val_loss: 0.7107
Epoch 4/100
0s - loss: 0.4915 - val_loss: 0.5969
Epoch 5/100
0s - loss: 0.4828 - val_loss: 0.5519
Epoch 6/100
0s - loss: 0.4767 - val_loss: 0.5320
Epoch 7/100
0s - loss: 0.4716 - val_loss: 0.5114
Epoch 8/100
0s - loss: 0.4686 - val_loss: 0.5084
Epoch 9/100
0s - loss: 0.4652 - val_loss: 0.4988
Epoch 10/100
0s - loss: 0.4626 - val_loss: 0.4914
Epoch 11/100
0s - loss: 0.4605 - val_loss: 0.4863
Epoch 12/100
0s - loss: 0.4586 - val_loss: 0.4809
Epoch 13/100
0s - loss: 0.4578 - val_loss: 0.4765
Epoch 14/100
0s - loss: 0.4566 - val_loss: 0.4759
Epoch 15/100
0s - loss: 0.4560 - val_loss: 0.4734
Epoch 16/100
0s - loss: 0.4554 - val_loss: 0.4719
Epoch 17/100
0s - loss: 0.4571 - val_loss: 0.4761
Epoch 18/100
0s - loss: 0.4553 - val_loss: 0.4729
Epoch 19/100
0s - loss: 0.4522 - val_loss: 0.4704
Epoch 20/100
0s - loss: 0.4507 - val_loss: 0.4686
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:29:39,517 - 19_UsokinAE_350-250_50_tanh_BN|Fold #5 Loss = 0.468576
Train on 556 samples, validate on 66 samples
Epoch 1/100
2s - loss: 0.6824 - val_loss: 0.7185
Epoch 2/100
0s - loss: 0.6139 - val_loss: 0.7223
Epoch 3/100
0s - loss: 0.5411 - val_loss: 0.7160
Epoch 4/100
0s - loss: 0.4996 - val_loss: 0.6710
Epoch 5/100
0s - loss: 0.4856 - val_loss: 0.5560
Epoch 6/100
0s - loss: 0.4817 - val_loss: 0.5261
Epoch 7/100
0s - loss: 0.4775 - val_loss: 0.5033
Epoch 8/100
0s - loss: 0.4739 - val_loss: 0.4989
Epoch 9/100
0s - loss: 0.4772 - val_loss: 0.5017
Epoch 10/100
0s - loss: 0.4783 - val_loss: 0.4903
Epoch 11/100
0s - loss: 0.4743 - val_loss: 0.4851
Epoch 12/100
0s - loss: 0.4738 - val_loss: 0.4844
Epoch 13/100
0s - loss: 0.4688 - val_loss: 0.4779
Epoch 14/100
0s - loss: 0.4673 - val_loss: 0.4787
Epoch 15/100
0s - loss: 0.4653 - val_loss: 0.4737
Epoch 16/100
0s - loss: 0.4633 - val_loss: 0.4680
Epoch 17/100
0s - loss: 0.4609 - val_loss: 0.4663
Epoch 18/100
0s - loss: 0.4609 - val_loss: 0.4664
Epoch 19/100
0s - loss: 0.4615 - val_loss: 0.4642
Epoch 20/100
0s - loss: 0.4587 - val_loss: 0.4612
Epoch 21/100
0s - loss: 0.4563 - val_loss: 0.4606
Epoch 22/100
0s - loss: 0.4556 - val_loss: 0.4598
Epoch 23/100
0s - loss: 0.4562 - val_loss: 0.4606
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:29:57,533 - 19_UsokinAE_350-250_50_tanh_BN|Fold #6 Loss = 0.460551
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6810 - val_loss: 0.7085
Epoch 2/100
0s - loss: 0.6141 - val_loss: 0.7248
Epoch 3/100
0s - loss: 0.5392 - val_loss: 0.7413
Epoch 4/100
0s - loss: 0.4934 - val_loss: 0.6223
Epoch 5/100
0s - loss: 0.4786 - val_loss: 0.6656
Epoch 6/100
0s - loss: 0.4743 - val_loss: 0.5564
Epoch 7/100
0s - loss: 0.4723 - val_loss: 0.5482
Epoch 8/100
0s - loss: 0.4719 - val_loss: 0.5393
Epoch 9/100
0s - loss: 0.4676 - val_loss: 0.5263
Epoch 10/100
0s - loss: 0.4633 - val_loss: 0.5219
Epoch 11/100
0s - loss: 0.4608 - val_loss: 0.5074
Epoch 12/100
0s - loss: 0.4604 - val_loss: 0.4978
Epoch 13/100
0s - loss: 0.4641 - val_loss: 0.4934
Epoch 14/100
0s - loss: 0.4618 - val_loss: 0.4902
Epoch 15/100
0s - loss: 0.4566 - val_loss: 0.4890
Epoch 16/100
0s - loss: 0.4561 - val_loss: 0.4847
Epoch 17/100
0s - loss: 0.4557 - val_loss: 0.4855
Epoch 18/100
0s - loss: 0.4542 - val_loss: 0.4847
Epoch 19/100
0s - loss: 0.4532 - val_loss: 0.4837
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:30:13,458 - 19_UsokinAE_350-250_50_tanh_BN|Fold #7 Loss = 0.483657
Train on 561 samples, validate on 61 samples
Epoch 1/100
2s - loss: 0.6814 - val_loss: 0.7192
Epoch 2/100
0s - loss: 0.6130 - val_loss: 0.7196
Epoch 3/100
0s - loss: 0.5388 - val_loss: 0.7110
Epoch 4/100
0s - loss: 0.4932 - val_loss: 0.6910
Epoch 5/100
0s - loss: 0.4846 - val_loss: 0.5739
Epoch 6/100
0s - loss: 0.4857 - val_loss: 0.5174
Epoch 7/100
0s - loss: 0.4793 - val_loss: 0.5216
Epoch 8/100
0s - loss: 0.4735 - val_loss: 0.5068
Epoch 9/100
0s - loss: 0.4691 - val_loss: 0.4968
Epoch 10/100
0s - loss: 0.4675 - val_loss: 0.4891
Epoch 11/100
0s - loss: 0.4667 - val_loss: 0.4885
Epoch 12/100
0s - loss: 0.4653 - val_loss: 0.4834
Epoch 13/100
0s - loss: 0.4622 - val_loss: 0.4782
Epoch 14/100
0s - loss: 0.4604 - val_loss: 0.4732
Epoch 15/100
0s - loss: 0.4602 - val_loss: 0.4700
Epoch 16/100
0s - loss: 0.4600 - val_loss: 0.4684
Epoch 17/100
0s - loss: 0.4582 - val_loss: 0.4686
Epoch 18/100
0s - loss: 0.4569 - val_loss: 0.4646
Epoch 19/100
0s - loss: 0.4570 - val_loss: 0.4653
Epoch 20/100
0s - loss: 0.4567 - val_loss: 0.4621
Epoch 21/100
0s - loss: 0.4550 - val_loss: 0.4624
Epoch 22/100
0s - loss: 0.4527 - val_loss: 0.4627
Epoch 23/100
0s - loss: 0.4522 - val_loss: 0.4603
Epoch 24/100
0s - loss: 0.4512 - val_loss: 0.4583
Epoch 25/100
0s - loss: 0.4502 - val_loss: 0.4581
Epoch 26/100
0s - loss: 0.4499 - val_loss: 0.4574
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:30:33,164 - 19_UsokinAE_350-250_50_tanh_BN|Fold #8 Loss = 0.457446
Train on 560 samples, validate on 62 samples
Epoch 1/100
2s - loss: 0.6852 - val_loss: 0.7172
Epoch 2/100
0s - loss: 0.6212 - val_loss: 0.7188
Epoch 3/100
0s - loss: 0.5441 - val_loss: 0.6955
Epoch 4/100
0s - loss: 0.4955 - val_loss: 0.6807
Epoch 5/100
0s - loss: 0.4820 - val_loss: 0.5913
Epoch 6/100
0s - loss: 0.4739 - val_loss: 0.5967
Epoch 7/100
0s - loss: 0.4720 - val_loss: 0.5271
Epoch 8/100
0s - loss: 0.4693 - val_loss: 0.5490
Epoch 9/100
0s - loss: 0.4663 - val_loss: 0.5300
Epoch 10/100
0s - loss: 0.4651 - val_loss: 0.5101
Epoch 11/100
0s - loss: 0.4616 - val_loss: 0.4961
Epoch 12/100
0s - loss: 0.4595 - val_loss: 0.4980
Epoch 13/100
0s - loss: 0.4577 - val_loss: 0.4890
Epoch 14/100
0s - loss: 0.4562 - val_loss: 0.4874
Epoch 15/100
0s - loss: 0.4560 - val_loss: 0.4793
Epoch 16/100
0s - loss: 0.4543 - val_loss: 0.4781
Epoch 17/100
0s - loss: 0.4526 - val_loss: 0.4769
Epoch 18/100
0s - loss: 0.4517 - val_loss: 0.4739
Epoch 19/100
0s - loss: 0.4507 - val_loss: 0.4734
Epoch 20/100
0s - loss: 0.4513 - val_loss: 0.4780
Epoch 21/100
0s - loss: 0.4538 - val_loss: 0.4747
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:30:49,940 - 19_UsokinAE_350-250_50_tanh_BN|Fold #9 Loss = 0.474717
Train on 564 samples, validate on 58 samples
Epoch 1/100
2s - loss: 0.6781 - val_loss: 0.7251
Epoch 2/100
0s - loss: 0.6108 - val_loss: 0.7224
Epoch 3/100
0s - loss: 0.5318 - val_loss: 0.7056
Epoch 4/100
0s - loss: 0.4970 - val_loss: 0.6484
Epoch 5/100
0s - loss: 0.4865 - val_loss: 0.5294
Epoch 6/100
0s - loss: 0.4796 - val_loss: 0.5482
Epoch 7/100
0s - loss: 0.4758 - val_loss: 0.5214
Epoch 8/100
0s - loss: 0.4721 - val_loss: 0.4982
Epoch 9/100
0s - loss: 0.4706 - val_loss: 0.4911
Epoch 10/100
0s - loss: 0.4660 - val_loss: 0.4904
Epoch 11/100
0s - loss: 0.4633 - val_loss: 0.4791
Epoch 12/100
0s - loss: 0.4614 - val_loss: 0.4736
Epoch 13/100
0s - loss: 0.4594 - val_loss: 0.4703
Epoch 14/100
0s - loss: 0.4576 - val_loss: 0.4667
Epoch 15/100
0s - loss: 0.4572 - val_loss: 0.4655
Epoch 16/100
0s - loss: 0.4579 - val_loss: 0.4643
Epoch 17/100
0s - loss: 0.4576 - val_loss: 0.4652
Epoch 18/100
0s - loss: 0.4558 - val_loss: 0.4619
Epoch 19/100
0s - loss: 0.4531 - val_loss: 0.4608
Epoch 20/100
0s - loss: 0.4518 - val_loss: 0.4594
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:06,097 - 19_UsokinAE_350-250_50_tanh_BN|Fold #10 Loss = 0.459361
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:06,097 - 19_UsokinAE_350-250_50_tanh_BN|Avg Validation Loss = 0.466670
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5838 - val_loss: 0.5274
Epoch 2/100
0s - loss: 0.5147 - val_loss: 0.4941
Epoch 3/100
0s - loss: 0.4906 - val_loss: 0.4812
Epoch 4/100
0s - loss: 0.4793 - val_loss: 0.4757
Epoch 5/100
0s - loss: 0.4723 - val_loss: 0.4714
Epoch 6/100
0s - loss: 0.4672 - val_loss: 0.4679
Epoch 7/100
0s - loss: 0.4621 - val_loss: 0.4656
Epoch 8/100
0s - loss: 0.4583 - val_loss: 0.4626
Epoch 9/100
0s - loss: 0.4558 - val_loss: 0.4615
Epoch 10/100
0s - loss: 0.4540 - val_loss: 0.4600
Epoch 11/100
0s - loss: 0.4511 - val_loss: 0.4583
Epoch 12/100
0s - loss: 0.4481 - val_loss: 0.4586
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:14,232 - 20_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.458644
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5866 - val_loss: 0.5228
Epoch 2/100
0s - loss: 0.5094 - val_loss: 0.4888
Epoch 3/100
0s - loss: 0.4855 - val_loss: 0.4742
Epoch 4/100
0s - loss: 0.4742 - val_loss: 0.4687
Epoch 5/100
0s - loss: 0.4683 - val_loss: 0.4645
Epoch 6/100
0s - loss: 0.4629 - val_loss: 0.4607
Epoch 7/100
0s - loss: 0.4588 - val_loss: 0.4597
Epoch 8/100
0s - loss: 0.4562 - val_loss: 0.4572
Epoch 9/100
0s - loss: 0.4533 - val_loss: 0.4557
Epoch 10/100
0s - loss: 0.4504 - val_loss: 0.4541
Epoch 11/100
0s - loss: 0.4474 - val_loss: 0.4525
Epoch 12/100
0s - loss: 0.4446 - val_loss: 0.4518
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:22,370 - 20_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.451757
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5861 - val_loss: 0.5349
Epoch 2/100
0s - loss: 0.5128 - val_loss: 0.5036
Epoch 3/100
0s - loss: 0.4850 - val_loss: 0.4887
Epoch 4/100
0s - loss: 0.4739 - val_loss: 0.4816
Epoch 5/100
0s - loss: 0.4674 - val_loss: 0.4794
Epoch 6/100
0s - loss: 0.4628 - val_loss: 0.4767
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4734
Epoch 8/100
0s - loss: 0.4556 - val_loss: 0.4714
Epoch 9/100
0s - loss: 0.4525 - val_loss: 0.4692
Epoch 10/100
0s - loss: 0.4492 - val_loss: 0.4674
Epoch 11/100
0s - loss: 0.4462 - val_loss: 0.4666
Epoch 12/100
0s - loss: 0.4436 - val_loss: 0.4655
Epoch 13/100
0s - loss: 0.4408 - val_loss: 0.4639
Epoch 14/100
0s - loss: 0.4375 - val_loss: 0.4631
Epoch 15/100
0s - loss: 0.4344 - val_loss: 0.4620
Epoch 16/100
0s - loss: 0.4320 - val_loss: 0.4627
Epoch 17/100
0s - loss: 0.4299 - val_loss: 0.4611
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:33,397 - 20_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.461088
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5885 - val_loss: 0.5280
Epoch 2/100
0s - loss: 0.5148 - val_loss: 0.4934
Epoch 3/100
0s - loss: 0.4863 - val_loss: 0.4817
Epoch 4/100
0s - loss: 0.4760 - val_loss: 0.4729
Epoch 5/100
0s - loss: 0.4695 - val_loss: 0.4694
Epoch 6/100
0s - loss: 0.4649 - val_loss: 0.4648
Epoch 7/100
0s - loss: 0.4603 - val_loss: 0.4624
Epoch 8/100
0s - loss: 0.4568 - val_loss: 0.4600
Epoch 9/100
0s - loss: 0.4541 - val_loss: 0.4584
Epoch 10/100
0s - loss: 0.4513 - val_loss: 0.4574
Epoch 11/100
0s - loss: 0.4486 - val_loss: 0.4558
Epoch 12/100
0s - loss: 0.4459 - val_loss: 0.4537
Epoch 13/100
0s - loss: 0.4427 - val_loss: 0.4527
Epoch 14/100
0s - loss: 0.4401 - val_loss: 0.4508
Epoch 15/100
0s - loss: 0.4372 - val_loss: 0.4509
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:43,133 - 20_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.450904
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5885 - val_loss: 0.5343
Epoch 2/100
0s - loss: 0.5161 - val_loss: 0.5008
Epoch 3/100
0s - loss: 0.4883 - val_loss: 0.4830
Epoch 4/100
0s - loss: 0.4761 - val_loss: 0.4766
Epoch 5/100
0s - loss: 0.4694 - val_loss: 0.4729
Epoch 6/100
0s - loss: 0.4643 - val_loss: 0.4697
Epoch 7/100
0s - loss: 0.4596 - val_loss: 0.4664
Epoch 8/100
0s - loss: 0.4557 - val_loss: 0.4640
Epoch 9/100
0s - loss: 0.4524 - val_loss: 0.4618
Epoch 10/100
0s - loss: 0.4489 - val_loss: 0.4607
Epoch 11/100
0s - loss: 0.4459 - val_loss: 0.4591
Epoch 12/100
0s - loss: 0.4428 - val_loss: 0.4583
Epoch 13/100
0s - loss: 0.4399 - val_loss: 0.4568
Epoch 14/100
0s - loss: 0.4367 - val_loss: 0.4556
Epoch 15/100
0s - loss: 0.4337 - val_loss: 0.4553
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:31:53,000 - 20_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.455278
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5851 - val_loss: 0.5263
Epoch 2/100
0s - loss: 0.5158 - val_loss: 0.4881
Epoch 3/100
0s - loss: 0.4877 - val_loss: 0.4749
Epoch 4/100
0s - loss: 0.4771 - val_loss: 0.4661
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4609
Epoch 6/100
0s - loss: 0.4652 - val_loss: 0.4580
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4559
Epoch 8/100
0s - loss: 0.4579 - val_loss: 0.4543
Epoch 9/100
0s - loss: 0.4554 - val_loss: 0.4522
Epoch 10/100
0s - loss: 0.4531 - val_loss: 0.4515
Epoch 11/100
0s - loss: 0.4501 - val_loss: 0.4513
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:00,738 - 20_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.451307
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5826 - val_loss: 0.5398
Epoch 2/100
0s - loss: 0.5101 - val_loss: 0.5105
Epoch 3/100
0s - loss: 0.4867 - val_loss: 0.4959
Epoch 4/100
0s - loss: 0.4742 - val_loss: 0.4899
Epoch 5/100
0s - loss: 0.4676 - val_loss: 0.4844
Epoch 6/100
0s - loss: 0.4625 - val_loss: 0.4808
Epoch 7/100
0s - loss: 0.4581 - val_loss: 0.4776
Epoch 8/100
0s - loss: 0.4543 - val_loss: 0.4764
Epoch 9/100
0s - loss: 0.4514 - val_loss: 0.4748
Epoch 10/100
0s - loss: 0.4486 - val_loss: 0.4737
Epoch 11/100
0s - loss: 0.4458 - val_loss: 0.4723
Epoch 12/100
0s - loss: 0.4433 - val_loss: 0.4716
Epoch 13/100
0s - loss: 0.4401 - val_loss: 0.4694
Epoch 14/100
0s - loss: 0.4370 - val_loss: 0.4687
Epoch 15/100
0s - loss: 0.4346 - val_loss: 0.4683
Epoch 16/100
0s - loss: 0.4312 - val_loss: 0.4673
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:11,113 - 20_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.467325
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5876 - val_loss: 0.5261
Epoch 2/100
0s - loss: 0.5116 - val_loss: 0.4896
Epoch 3/100
0s - loss: 0.4853 - val_loss: 0.4746
Epoch 4/100
0s - loss: 0.4752 - val_loss: 0.4670
Epoch 5/100
0s - loss: 0.4686 - val_loss: 0.4625
Epoch 6/100
0s - loss: 0.4640 - val_loss: 0.4602
Epoch 7/100
0s - loss: 0.4603 - val_loss: 0.4575
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4563
Epoch 9/100
0s - loss: 0.4540 - val_loss: 0.4547
Epoch 10/100
0s - loss: 0.4510 - val_loss: 0.4518
Epoch 11/100
0s - loss: 0.4477 - val_loss: 0.4506
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4491
Epoch 13/100
0s - loss: 0.4415 - val_loss: 0.4483
Epoch 14/100
0s - loss: 0.4383 - val_loss: 0.4468
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4457
Epoch 16/100
0s - loss: 0.4330 - val_loss: 0.4459
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:21,470 - 20_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.445899
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5886 - val_loss: 0.5355
Epoch 2/100
0s - loss: 0.5173 - val_loss: 0.5028
Epoch 3/100
0s - loss: 0.4891 - val_loss: 0.4864
Epoch 4/100
0s - loss: 0.4768 - val_loss: 0.4792
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4762
Epoch 6/100
0s - loss: 0.4657 - val_loss: 0.4732
Epoch 7/100
0s - loss: 0.4619 - val_loss: 0.4703
Epoch 8/100
0s - loss: 0.4582 - val_loss: 0.4687
Epoch 9/100
0s - loss: 0.4552 - val_loss: 0.4676
Epoch 10/100
0s - loss: 0.4526 - val_loss: 0.4651
Epoch 11/100
0s - loss: 0.4491 - val_loss: 0.4631
Epoch 12/100
0s - loss: 0.4465 - val_loss: 0.4626
Epoch 13/100
0s - loss: 0.4437 - val_loss: 0.4614
Epoch 14/100
0s - loss: 0.4409 - val_loss: 0.4598
Epoch 15/100
0s - loss: 0.4381 - val_loss: 0.4592
Epoch 16/100
0s - loss: 0.4356 - val_loss: 0.4578
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:31,833 - 20_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.457823
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5876 - val_loss: 0.5289
Epoch 2/100
0s - loss: 0.5104 - val_loss: 0.4908
Epoch 3/100
0s - loss: 0.4849 - val_loss: 0.4758
Epoch 4/100
0s - loss: 0.4756 - val_loss: 0.4695
Epoch 5/100
0s - loss: 0.4692 - val_loss: 0.4654
Epoch 6/100
0s - loss: 0.4640 - val_loss: 0.4610
Epoch 7/100
0s - loss: 0.4596 - val_loss: 0.4578
Epoch 8/100
0s - loss: 0.4561 - val_loss: 0.4562
Epoch 9/100
0s - loss: 0.4532 - val_loss: 0.4545
Epoch 10/100
0s - loss: 0.4503 - val_loss: 0.4539
Epoch 11/100
0s - loss: 0.4476 - val_loss: 0.4518
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4501
Epoch 13/100
0s - loss: 0.4411 - val_loss: 0.4491
Epoch 14/100
0s - loss: 0.4384 - val_loss: 0.4480
Epoch 15/100
0s - loss: 0.4354 - val_loss: 0.4473
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:41,714 - 20_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.447339
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:41,714 - 20_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.454736
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5835 - val_loss: 0.5269
Epoch 2/100
0s - loss: 0.5139 - val_loss: 0.4947
Epoch 3/100
0s - loss: 0.4905 - val_loss: 0.4814
Epoch 4/100
0s - loss: 0.4781 - val_loss: 0.4755
Epoch 5/100
0s - loss: 0.4708 - val_loss: 0.4692
Epoch 6/100
0s - loss: 0.4658 - val_loss: 0.4670
Epoch 7/100
0s - loss: 0.4626 - val_loss: 0.4653
Epoch 8/100
0s - loss: 0.4595 - val_loss: 0.4652
Epoch 9/100
0s - loss: 0.4571 - val_loss: 0.4617
Epoch 10/100
0s - loss: 0.4541 - val_loss: 0.4594
Epoch 11/100
0s - loss: 0.4511 - val_loss: 0.4581
Epoch 12/100
0s - loss: 0.4489 - val_loss: 0.4573
Epoch 13/100
0s - loss: 0.4466 - val_loss: 0.4558
Epoch 14/100
0s - loss: 0.4437 - val_loss: 0.4542
Epoch 15/100
0s - loss: 0.4413 - val_loss: 0.4545
Epoch 16/100
0s - loss: 0.4397 - val_loss: 0.4535
Epoch 17/100
0s - loss: 0.4363 - val_loss: 0.4522
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:32:52,280 - 21_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.452184
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5885 - val_loss: 0.5264
Epoch 2/100
0s - loss: 0.5146 - val_loss: 0.4919
Epoch 3/100
0s - loss: 0.4865 - val_loss: 0.4763
Epoch 4/100
0s - loss: 0.4755 - val_loss: 0.4697
Epoch 5/100
0s - loss: 0.4685 - val_loss: 0.4648
Epoch 6/100
0s - loss: 0.4643 - val_loss: 0.4625
Epoch 7/100
0s - loss: 0.4600 - val_loss: 0.4592
Epoch 8/100
0s - loss: 0.4567 - val_loss: 0.4574
Epoch 9/100
0s - loss: 0.4535 - val_loss: 0.4555
Epoch 10/100
0s - loss: 0.4508 - val_loss: 0.4538
Epoch 11/100
0s - loss: 0.4478 - val_loss: 0.4525
Epoch 12/100
0s - loss: 0.4452 - val_loss: 0.4513
Epoch 13/100
0s - loss: 0.4424 - val_loss: 0.4502
Epoch 14/100
0s - loss: 0.4393 - val_loss: 0.4506
Epoch 15/100
0s - loss: 0.4366 - val_loss: 0.4488
Epoch 16/100
0s - loss: 0.4336 - val_loss: 0.4480
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:33:02,310 - 21_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.447997
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5865 - val_loss: 0.5312
Epoch 2/100
0s - loss: 0.5100 - val_loss: 0.4995
Epoch 3/100
0s - loss: 0.4830 - val_loss: 0.4876
Epoch 4/100
0s - loss: 0.4735 - val_loss: 0.4822
Epoch 5/100
0s - loss: 0.4671 - val_loss: 0.4778
Epoch 6/100
0s - loss: 0.4620 - val_loss: 0.4748
Epoch 7/100
0s - loss: 0.4579 - val_loss: 0.4724
Epoch 8/100
0s - loss: 0.4543 - val_loss: 0.4703
Epoch 9/100
0s - loss: 0.4514 - val_loss: 0.4688
Epoch 10/100
0s - loss: 0.4485 - val_loss: 0.4668
Epoch 11/100
0s - loss: 0.4451 - val_loss: 0.4666
Epoch 12/100
0s - loss: 0.4422 - val_loss: 0.4645
Epoch 13/100
0s - loss: 0.4390 - val_loss: 0.4642
Epoch 14/100
0s - loss: 0.4364 - val_loss: 0.4641
Epoch 15/100
0s - loss: 0.4331 - val_loss: 0.4623
Epoch 16/100
0s - loss: 0.4302 - val_loss: 0.4608
Epoch 17/100
0s - loss: 0.4267 - val_loss: 0.4609
Epoch 18/100
0s - loss: 0.4240 - val_loss: 0.4609
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:33:13,517 - 21_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.460934
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5872 - val_loss: 0.5285
Epoch 2/100
0s - loss: 0.5139 - val_loss: 0.4940
Epoch 3/100
0s - loss: 0.4854 - val_loss: 0.4778
Epoch 4/100
0s - loss: 0.4745 - val_loss: 0.4718
Epoch 5/100
0s - loss: 0.4678 - val_loss: 0.4677
Epoch 6/100
0s - loss: 0.4632 - val_loss: 0.4646
Epoch 7/100
0s - loss: 0.4593 - val_loss: 0.4618
Epoch 8/100
0s - loss: 0.4563 - val_loss: 0.4601
Epoch 9/100
0s - loss: 0.4534 - val_loss: 0.4587
Epoch 10/100
0s - loss: 0.4511 - val_loss: 0.4575
Epoch 11/100
0s - loss: 0.4486 - val_loss: 0.4554
Epoch 12/100
0s - loss: 0.4456 - val_loss: 0.4539
Epoch 13/100
0s - loss: 0.4430 - val_loss: 0.4529
Epoch 14/100
0s - loss: 0.4400 - val_loss: 0.4516
Epoch 15/100
0s - loss: 0.4372 - val_loss: 0.4508
Epoch 16/100
0s - loss: 0.4339 - val_loss: 0.4497
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:33:23,654 - 21_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.449713
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5834 - val_loss: 0.5312
Epoch 2/100
0s - loss: 0.5127 - val_loss: 0.4987
Epoch 3/100
0s - loss: 0.4869 - val_loss: 0.4829
Epoch 4/100
0s - loss: 0.4754 - val_loss: 0.4772
Epoch 5/100
0s - loss: 0.4691 - val_loss: 0.4722
Epoch 6/100
0s - loss: 0.4641 - val_loss: 0.4691
Epoch 7/100
0s - loss: 0.4596 - val_loss: 0.4655
Epoch 8/100
0s - loss: 0.4561 - val_loss: 0.4636
Epoch 9/100
0s - loss: 0.4529 - val_loss: 0.4635
Epoch 10/100
0s - loss: 0.4506 - val_loss: 0.4606
Epoch 11/100
0s - loss: 0.4477 - val_loss: 0.4599
Epoch 12/100
0s - loss: 0.4445 - val_loss: 0.4579
Epoch 13/100
0s - loss: 0.4416 - val_loss: 0.4574
Epoch 14/100
0s - loss: 0.4384 - val_loss: 0.4568
Epoch 15/100
0s - loss: 0.4354 - val_loss: 0.4553
Epoch 16/100
0s - loss: 0.4324 - val_loss: 0.4540
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:33:33,808 - 21_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.453952
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5242
Epoch 2/100
0s - loss: 0.5146 - val_loss: 0.4892
Epoch 3/100
0s - loss: 0.4885 - val_loss: 0.4728
Epoch 4/100
0s - loss: 0.4776 - val_loss: 0.4689
Epoch 5/100
0s - loss: 0.4718 - val_loss: 0.4632
Epoch 6/100
0s - loss: 0.4665 - val_loss: 0.4599
Epoch 7/100
0s - loss: 0.4623 - val_loss: 0.4569
Epoch 8/100
0s - loss: 0.4587 - val_loss: 0.4546
Epoch 9/100
0s - loss: 0.4554 - val_loss: 0.4531
Epoch 10/100
0s - loss: 0.4528 - val_loss: 0.4514
Epoch 11/100
0s - loss: 0.4500 - val_loss: 0.4506
Epoch 12/100
0s - loss: 0.4474 - val_loss: 0.4512
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:33:41,724 - 21_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.451172
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5832 - val_loss: 0.5415
Epoch 2/100
0s - loss: 0.5118 - val_loss: 0.5101
Epoch 3/100
0s - loss: 0.4843 - val_loss: 0.4952
Epoch 4/100
0s - loss: 0.4733 - val_loss: 0.4888
Epoch 5/100
0s - loss: 0.4673 - val_loss: 0.4845
Epoch 6/100
0s - loss: 0.4622 - val_loss: 0.4808
Epoch 7/100
0s - loss: 0.4579 - val_loss: 0.4783
Epoch 8/100
0s - loss: 0.4544 - val_loss: 0.4767
Epoch 9/100
0s - loss: 0.4510 - val_loss: 0.4744
Epoch 10/100
0s - loss: 0.4481 - val_loss: 0.4733
Epoch 11/100
0s - loss: 0.4452 - val_loss: 0.4720
Epoch 12/100
0s - loss: 0.4420 - val_loss: 0.4710
Epoch 13/100
0s - loss: 0.4392 - val_loss: 0.4709
Epoch 14/100
0s - loss: 0.4365 - val_loss: 0.4690
Epoch 15/100
0s - loss: 0.4333 - val_loss: 0.4688
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:33:51,380 - 21_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.468785
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5881 - val_loss: 0.5317
Epoch 2/100
0s - loss: 0.5173 - val_loss: 0.4956
Epoch 3/100
0s - loss: 0.4896 - val_loss: 0.4772
Epoch 4/100
0s - loss: 0.4773 - val_loss: 0.4690
Epoch 5/100
0s - loss: 0.4706 - val_loss: 0.4644
Epoch 6/100
0s - loss: 0.4657 - val_loss: 0.4601
Epoch 7/100
0s - loss: 0.4615 - val_loss: 0.4572
Epoch 8/100
0s - loss: 0.4580 - val_loss: 0.4557
Epoch 9/100
0s - loss: 0.4551 - val_loss: 0.4538
Epoch 10/100
0s - loss: 0.4521 - val_loss: 0.4529
Epoch 11/100
0s - loss: 0.4496 - val_loss: 0.4515
Epoch 12/100
0s - loss: 0.4465 - val_loss: 0.4503
Epoch 13/100
0s - loss: 0.4435 - val_loss: 0.4489
Epoch 14/100
0s - loss: 0.4409 - val_loss: 0.4478
Epoch 15/100
0s - loss: 0.4380 - val_loss: 0.4460
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:01,073 - 21_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.446025
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5847 - val_loss: 0.5330
Epoch 2/100
0s - loss: 0.5132 - val_loss: 0.4976
Epoch 3/100
0s - loss: 0.4865 - val_loss: 0.4856
Epoch 4/100
0s - loss: 0.4757 - val_loss: 0.4792
Epoch 5/100
0s - loss: 0.4690 - val_loss: 0.4740
Epoch 6/100
0s - loss: 0.4639 - val_loss: 0.4714
Epoch 7/100
0s - loss: 0.4607 - val_loss: 0.4688
Epoch 8/100
0s - loss: 0.4565 - val_loss: 0.4673
Epoch 9/100
0s - loss: 0.4537 - val_loss: 0.4651
Epoch 10/100
0s - loss: 0.4505 - val_loss: 0.4636
Epoch 11/100
0s - loss: 0.4474 - val_loss: 0.4630
Epoch 12/100
0s - loss: 0.4445 - val_loss: 0.4610
Epoch 13/100
0s - loss: 0.4418 - val_loss: 0.4615
Epoch 14/100
0s - loss: 0.4391 - val_loss: 0.4594
Epoch 15/100
0s - loss: 0.4359 - val_loss: 0.4587
Epoch 16/100
0s - loss: 0.4327 - val_loss: 0.4572
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:11,114 - 21_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.457231
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5824 - val_loss: 0.5293
Epoch 2/100
0s - loss: 0.5125 - val_loss: 0.4930
Epoch 3/100
0s - loss: 0.4866 - val_loss: 0.4760
Epoch 4/100
0s - loss: 0.4762 - val_loss: 0.4694
Epoch 5/100
0s - loss: 0.4699 - val_loss: 0.4649
Epoch 6/100
0s - loss: 0.4649 - val_loss: 0.4613
Epoch 7/100
0s - loss: 0.4606 - val_loss: 0.4576
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4562
Epoch 9/100
0s - loss: 0.4537 - val_loss: 0.4542
Epoch 10/100
0s - loss: 0.4510 - val_loss: 0.4531
Epoch 11/100
0s - loss: 0.4477 - val_loss: 0.4513
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4502
Epoch 13/100
0s - loss: 0.4414 - val_loss: 0.4490
Epoch 14/100
0s - loss: 0.4384 - val_loss: 0.4492
Epoch 15/100
0s - loss: 0.4362 - val_loss: 0.4471
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:20,573 - 21_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.447073
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:20,574 - 21_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453507
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5856 - val_loss: 0.5290
Epoch 2/100
0s - loss: 0.5141 - val_loss: 0.4926
Epoch 3/100
0s - loss: 0.4883 - val_loss: 0.4798
Epoch 4/100
0s - loss: 0.4773 - val_loss: 0.4746
Epoch 5/100
0s - loss: 0.4718 - val_loss: 0.4706
Epoch 6/100
0s - loss: 0.4662 - val_loss: 0.4662
Epoch 7/100
0s - loss: 0.4619 - val_loss: 0.4654
Epoch 8/100
0s - loss: 0.4592 - val_loss: 0.4636
Epoch 9/100
0s - loss: 0.4565 - val_loss: 0.4622
Epoch 10/100
0s - loss: 0.4542 - val_loss: 0.4602
Epoch 11/100
0s - loss: 0.4523 - val_loss: 0.4593
Epoch 12/100
0s - loss: 0.4505 - val_loss: 0.4579
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:28,394 - 22_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.457921
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5234
Epoch 2/100
0s - loss: 0.5110 - val_loss: 0.4887
Epoch 3/100
0s - loss: 0.4850 - val_loss: 0.4760
Epoch 4/100
0s - loss: 0.4748 - val_loss: 0.4693
Epoch 5/100
0s - loss: 0.4680 - val_loss: 0.4651
Epoch 6/100
0s - loss: 0.4629 - val_loss: 0.4611
Epoch 7/100
0s - loss: 0.4585 - val_loss: 0.4589
Epoch 8/100
0s - loss: 0.4554 - val_loss: 0.4572
Epoch 9/100
0s - loss: 0.4524 - val_loss: 0.4552
Epoch 10/100
0s - loss: 0.4492 - val_loss: 0.4538
Epoch 11/100
0s - loss: 0.4463 - val_loss: 0.4531
Epoch 12/100
0s - loss: 0.4435 - val_loss: 0.4521
Epoch 13/100
0s - loss: 0.4404 - val_loss: 0.4506
Epoch 14/100
0s - loss: 0.4375 - val_loss: 0.4511
Epoch 15/100
0s - loss: 0.4350 - val_loss: 0.4490
Epoch 16/100
0s - loss: 0.4317 - val_loss: 0.4494
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:38,313 - 22_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.449393
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5392
Epoch 2/100
0s - loss: 0.5165 - val_loss: 0.5068
Epoch 3/100
0s - loss: 0.4876 - val_loss: 0.4896
Epoch 4/100
0s - loss: 0.4757 - val_loss: 0.4847
Epoch 5/100
0s - loss: 0.4700 - val_loss: 0.4805
Epoch 6/100
0s - loss: 0.4647 - val_loss: 0.4766
Epoch 7/100
0s - loss: 0.4595 - val_loss: 0.4741
Epoch 8/100
0s - loss: 0.4557 - val_loss: 0.4714
Epoch 9/100
0s - loss: 0.4524 - val_loss: 0.4698
Epoch 10/100
0s - loss: 0.4497 - val_loss: 0.4685
Epoch 11/100
0s - loss: 0.4468 - val_loss: 0.4664
Epoch 12/100
0s - loss: 0.4439 - val_loss: 0.4661
Epoch 13/100
0s - loss: 0.4411 - val_loss: 0.4649
Epoch 14/100
0s - loss: 0.4381 - val_loss: 0.4642
Epoch 15/100
0s - loss: 0.4351 - val_loss: 0.4635
Epoch 16/100
0s - loss: 0.4324 - val_loss: 0.4620
Epoch 17/100
0s - loss: 0.4291 - val_loss: 0.4615
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:48,984 - 22_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.461481
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5921 - val_loss: 0.5305
Epoch 2/100
0s - loss: 0.5150 - val_loss: 0.4934
Epoch 3/100
0s - loss: 0.4860 - val_loss: 0.4784
Epoch 4/100
0s - loss: 0.4759 - val_loss: 0.4735
Epoch 5/100
0s - loss: 0.4700 - val_loss: 0.4691
Epoch 6/100
0s - loss: 0.4650 - val_loss: 0.4661
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4626
Epoch 8/100
0s - loss: 0.4572 - val_loss: 0.4590
Epoch 9/100
0s - loss: 0.4540 - val_loss: 0.4574
Epoch 10/100
0s - loss: 0.4509 - val_loss: 0.4560
Epoch 11/100
0s - loss: 0.4478 - val_loss: 0.4546
Epoch 12/100
0s - loss: 0.4453 - val_loss: 0.4534
Epoch 13/100
0s - loss: 0.4424 - val_loss: 0.4520
Epoch 14/100
0s - loss: 0.4395 - val_loss: 0.4512
Epoch 15/100
0s - loss: 0.4365 - val_loss: 0.4500
Epoch 16/100
0s - loss: 0.4332 - val_loss: 0.4497
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:34:59,236 - 22_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.449720
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5851 - val_loss: 0.5316
Epoch 2/100
0s - loss: 0.5139 - val_loss: 0.4985
Epoch 3/100
0s - loss: 0.4873 - val_loss: 0.4824
Epoch 4/100
0s - loss: 0.4762 - val_loss: 0.4768
Epoch 5/100
0s - loss: 0.4696 - val_loss: 0.4729
Epoch 6/100
0s - loss: 0.4643 - val_loss: 0.4687
Epoch 7/100
0s - loss: 0.4600 - val_loss: 0.4663
Epoch 8/100
0s - loss: 0.4565 - val_loss: 0.4639
Epoch 9/100
0s - loss: 0.4532 - val_loss: 0.4614
Epoch 10/100
0s - loss: 0.4504 - val_loss: 0.4604
Epoch 11/100
0s - loss: 0.4476 - val_loss: 0.4586
Epoch 12/100
0s - loss: 0.4447 - val_loss: 0.4584
Epoch 13/100
0s - loss: 0.4422 - val_loss: 0.4573
Epoch 14/100
0s - loss: 0.4394 - val_loss: 0.4566
Epoch 15/100
0s - loss: 0.4368 - val_loss: 0.4547
Epoch 16/100
0s - loss: 0.4335 - val_loss: 0.4540
Epoch 17/100
0s - loss: 0.4310 - val_loss: 0.4539
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:35:10,015 - 22_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.453932
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5873 - val_loss: 0.5285
Epoch 2/100
0s - loss: 0.5192 - val_loss: 0.4945
Epoch 3/100
0s - loss: 0.4888 - val_loss: 0.4734
Epoch 4/100
0s - loss: 0.4776 - val_loss: 0.4678
Epoch 5/100
0s - loss: 0.4714 - val_loss: 0.4627
Epoch 6/100
0s - loss: 0.4664 - val_loss: 0.4592
Epoch 7/100
0s - loss: 0.4629 - val_loss: 0.4562
Epoch 8/100
0s - loss: 0.4592 - val_loss: 0.4548
Epoch 9/100
0s - loss: 0.4565 - val_loss: 0.4531
Epoch 10/100
0s - loss: 0.4537 - val_loss: 0.4517
Epoch 11/100
0s - loss: 0.4516 - val_loss: 0.4516
Epoch 12/100
0s - loss: 0.4496 - val_loss: 0.4517
Epoch 13/100
0s - loss: 0.4472 - val_loss: 0.4488
Epoch 14/100
0s - loss: 0.4442 - val_loss: 0.4479
Epoch 15/100
0s - loss: 0.4419 - val_loss: 0.4467
Epoch 16/100
0s - loss: 0.4392 - val_loss: 0.4474
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:35:20,091 - 22_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.447372
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5848 - val_loss: 0.5437
Epoch 2/100
0s - loss: 0.5116 - val_loss: 0.5089
Epoch 3/100
0s - loss: 0.4848 - val_loss: 0.4965
Epoch 4/100
0s - loss: 0.4740 - val_loss: 0.4889
Epoch 5/100
0s - loss: 0.4673 - val_loss: 0.4855
Epoch 6/100
0s - loss: 0.4631 - val_loss: 0.4813
Epoch 7/100
0s - loss: 0.4589 - val_loss: 0.4786
Epoch 8/100
0s - loss: 0.4551 - val_loss: 0.4774
Epoch 9/100
0s - loss: 0.4521 - val_loss: 0.4761
Epoch 10/100
0s - loss: 0.4491 - val_loss: 0.4742
Epoch 11/100
0s - loss: 0.4464 - val_loss: 0.4729
Epoch 12/100
0s - loss: 0.4435 - val_loss: 0.4720
Epoch 13/100
0s - loss: 0.4409 - val_loss: 0.4712
Epoch 14/100
0s - loss: 0.4379 - val_loss: 0.4702
Epoch 15/100
0s - loss: 0.4348 - val_loss: 0.4693
Epoch 16/100
0s - loss: 0.4320 - val_loss: 0.4685
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:35:30,180 - 22_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.468481
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5825 - val_loss: 0.5256
Epoch 2/100
0s - loss: 0.5111 - val_loss: 0.4905
Epoch 3/100
0s - loss: 0.4853 - val_loss: 0.4743
Epoch 4/100
0s - loss: 0.4758 - val_loss: 0.4689
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4637
Epoch 6/100
0s - loss: 0.4646 - val_loss: 0.4599
Epoch 7/100
0s - loss: 0.4600 - val_loss: 0.4571
Epoch 8/100
0s - loss: 0.4565 - val_loss: 0.4541
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4528
Epoch 10/100
0s - loss: 0.4511 - val_loss: 0.4509
Epoch 11/100
0s - loss: 0.4479 - val_loss: 0.4491
Epoch 12/100
0s - loss: 0.4448 - val_loss: 0.4480
Epoch 13/100
0s - loss: 0.4420 - val_loss: 0.4475
Epoch 14/100
0s - loss: 0.4392 - val_loss: 0.4460
Epoch 15/100
0s - loss: 0.4361 - val_loss: 0.4449
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:35:39,809 - 22_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.444867
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5892 - val_loss: 0.5336
Epoch 2/100
0s - loss: 0.5122 - val_loss: 0.5010
Epoch 3/100
0s - loss: 0.4853 - val_loss: 0.4852
Epoch 4/100
0s - loss: 0.4748 - val_loss: 0.4783
Epoch 5/100
0s - loss: 0.4681 - val_loss: 0.4737
Epoch 6/100
0s - loss: 0.4626 - val_loss: 0.4706
Epoch 7/100
0s - loss: 0.4585 - val_loss: 0.4685
Epoch 8/100
0s - loss: 0.4555 - val_loss: 0.4667
Epoch 9/100
0s - loss: 0.4526 - val_loss: 0.4653
Epoch 10/100
0s - loss: 0.4495 - val_loss: 0.4641
Epoch 11/100
0s - loss: 0.4470 - val_loss: 0.4628
Epoch 12/100
0s - loss: 0.4440 - val_loss: 0.4618
Epoch 13/100
0s - loss: 0.4414 - val_loss: 0.4609
Epoch 14/100
0s - loss: 0.4387 - val_loss: 0.4600
Epoch 15/100
0s - loss: 0.4358 - val_loss: 0.4586
Epoch 16/100
0s - loss: 0.4329 - val_loss: 0.4575
Epoch 17/100
0s - loss: 0.4299 - val_loss: 0.4581
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:35:50,500 - 22_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.458137
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5803 - val_loss: 0.5276
Epoch 2/100
0s - loss: 0.5112 - val_loss: 0.4914
Epoch 3/100
0s - loss: 0.4839 - val_loss: 0.4742
Epoch 4/100
0s - loss: 0.4744 - val_loss: 0.4689
Epoch 5/100
0s - loss: 0.4687 - val_loss: 0.4641
Epoch 6/100
0s - loss: 0.4644 - val_loss: 0.4618
Epoch 7/100
0s - loss: 0.4605 - val_loss: 0.4586
Epoch 8/100
0s - loss: 0.4566 - val_loss: 0.4564
Epoch 9/100
0s - loss: 0.4533 - val_loss: 0.4544
Epoch 10/100
0s - loss: 0.4505 - val_loss: 0.4527
Epoch 11/100
0s - loss: 0.4475 - val_loss: 0.4514
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4503
Epoch 13/100
0s - loss: 0.4412 - val_loss: 0.4486
Epoch 14/100
0s - loss: 0.4384 - val_loss: 0.4476
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4468
Epoch 16/100
0s - loss: 0.4321 - val_loss: 0.4459
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:00,764 - 22_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.445896
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:00,765 - 22_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453720
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5840 - val_loss: 0.5267
Epoch 2/100
0s - loss: 0.5120 - val_loss: 0.4935
Epoch 3/100
0s - loss: 0.4870 - val_loss: 0.4810
Epoch 4/100
0s - loss: 0.4781 - val_loss: 0.4759
Epoch 5/100
0s - loss: 0.4722 - val_loss: 0.4703
Epoch 6/100
0s - loss: 0.4666 - val_loss: 0.4673
Epoch 7/100
0s - loss: 0.4626 - val_loss: 0.4647
Epoch 8/100
0s - loss: 0.4588 - val_loss: 0.4628
Epoch 9/100
0s - loss: 0.4560 - val_loss: 0.4651
Epoch 10/100
0s - loss: 0.4542 - val_loss: 0.4610
Epoch 11/100
0s - loss: 0.4516 - val_loss: 0.4588
Epoch 12/100
0s - loss: 0.4491 - val_loss: 0.4575
Epoch 13/100
0s - loss: 0.4463 - val_loss: 0.4570
Epoch 14/100
0s - loss: 0.4441 - val_loss: 0.4561
Epoch 15/100
0s - loss: 0.4416 - val_loss: 0.4561
Epoch 16/100
0s - loss: 0.4397 - val_loss: 0.4543
Epoch 17/100
0s - loss: 0.4369 - val_loss: 0.4525
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:11,327 - 23_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.452513
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5864 - val_loss: 0.5247
Epoch 2/100
0s - loss: 0.5104 - val_loss: 0.4892
Epoch 3/100
0s - loss: 0.4852 - val_loss: 0.4758
Epoch 4/100
0s - loss: 0.4757 - val_loss: 0.4707
Epoch 5/100
0s - loss: 0.4700 - val_loss: 0.4656
Epoch 6/100
0s - loss: 0.4646 - val_loss: 0.4622
Epoch 7/100
0s - loss: 0.4604 - val_loss: 0.4598
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4578
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4569
Epoch 10/100
0s - loss: 0.4512 - val_loss: 0.4552
Epoch 11/100
0s - loss: 0.4484 - val_loss: 0.4539
Epoch 12/100
0s - loss: 0.4453 - val_loss: 0.4527
Epoch 13/100
0s - loss: 0.4426 - val_loss: 0.4513
Epoch 14/100
0s - loss: 0.4391 - val_loss: 0.4504
Epoch 15/100
0s - loss: 0.4362 - val_loss: 0.4495
Epoch 16/100
0s - loss: 0.4333 - val_loss: 0.4499
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:21,285 - 23_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.449888
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5900 - val_loss: 0.5357
Epoch 2/100
0s - loss: 0.5123 - val_loss: 0.5009
Epoch 3/100
0s - loss: 0.4849 - val_loss: 0.4889
Epoch 4/100
0s - loss: 0.4740 - val_loss: 0.4824
Epoch 5/100
0s - loss: 0.4678 - val_loss: 0.4789
Epoch 6/100
0s - loss: 0.4635 - val_loss: 0.4754
Epoch 7/100
0s - loss: 0.4596 - val_loss: 0.4737
Epoch 8/100
0s - loss: 0.4564 - val_loss: 0.4701
Epoch 9/100
0s - loss: 0.4525 - val_loss: 0.4687
Epoch 10/100
0s - loss: 0.4497 - val_loss: 0.4676
Epoch 11/100
0s - loss: 0.4470 - val_loss: 0.4675
Epoch 12/100
0s - loss: 0.4448 - val_loss: 0.4653
Epoch 13/100
0s - loss: 0.4415 - val_loss: 0.4640
Epoch 14/100
0s - loss: 0.4383 - val_loss: 0.4636
Epoch 15/100
0s - loss: 0.4355 - val_loss: 0.4629
Epoch 16/100
0s - loss: 0.4328 - val_loss: 0.4611
Epoch 17/100
0s - loss: 0.4293 - val_loss: 0.4606
Epoch 18/100
0s - loss: 0.4267 - val_loss: 0.4600
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:32,757 - 23_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.460030
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5897 - val_loss: 0.5281
Epoch 2/100
0s - loss: 0.5144 - val_loss: 0.4945
Epoch 3/100
0s - loss: 0.4876 - val_loss: 0.4812
Epoch 4/100
0s - loss: 0.4764 - val_loss: 0.4735
Epoch 5/100
0s - loss: 0.4696 - val_loss: 0.4690
Epoch 6/100
0s - loss: 0.4646 - val_loss: 0.4658
Epoch 7/100
0s - loss: 0.4602 - val_loss: 0.4625
Epoch 8/100
0s - loss: 0.4564 - val_loss: 0.4601
Epoch 9/100
0s - loss: 0.4530 - val_loss: 0.4577
Epoch 10/100
0s - loss: 0.4501 - val_loss: 0.4573
Epoch 11/100
0s - loss: 0.4470 - val_loss: 0.4547
Epoch 12/100
0s - loss: 0.4440 - val_loss: 0.4532
Epoch 13/100
0s - loss: 0.4414 - val_loss: 0.4522
Epoch 14/100
0s - loss: 0.4383 - val_loss: 0.4513
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4498
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:42,421 - 23_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.449759
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5863 - val_loss: 0.5320
Epoch 2/100
0s - loss: 0.5132 - val_loss: 0.4970
Epoch 3/100
0s - loss: 0.4854 - val_loss: 0.4822
Epoch 4/100
0s - loss: 0.4755 - val_loss: 0.4767
Epoch 5/100
0s - loss: 0.4693 - val_loss: 0.4728
Epoch 6/100
0s - loss: 0.4638 - val_loss: 0.4686
Epoch 7/100
0s - loss: 0.4593 - val_loss: 0.4658
Epoch 8/100
0s - loss: 0.4558 - val_loss: 0.4636
Epoch 9/100
0s - loss: 0.4529 - val_loss: 0.4620
Epoch 10/100
0s - loss: 0.4496 - val_loss: 0.4611
Epoch 11/100
0s - loss: 0.4467 - val_loss: 0.4591
Epoch 12/100
0s - loss: 0.4436 - val_loss: 0.4585
Epoch 13/100
0s - loss: 0.4411 - val_loss: 0.4576
Epoch 14/100
0s - loss: 0.4388 - val_loss: 0.4563
Epoch 15/100
0s - loss: 0.4356 - val_loss: 0.4556
Epoch 16/100
0s - loss: 0.4323 - val_loss: 0.4559
Epoch 17/100
0s - loss: 0.4298 - val_loss: 0.4544
Epoch 18/100
0s - loss: 0.4269 - val_loss: 0.4536
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:36:53,896 - 23_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.453596
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5854 - val_loss: 0.5259
Epoch 2/100
0s - loss: 0.5146 - val_loss: 0.4879
Epoch 3/100
0s - loss: 0.4882 - val_loss: 0.4752
Epoch 4/100
0s - loss: 0.4778 - val_loss: 0.4677
Epoch 5/100
0s - loss: 0.4711 - val_loss: 0.4631
Epoch 6/100
0s - loss: 0.4662 - val_loss: 0.4606
Epoch 7/100
0s - loss: 0.4621 - val_loss: 0.4563
Epoch 8/100
0s - loss: 0.4584 - val_loss: 0.4545
Epoch 9/100
0s - loss: 0.4551 - val_loss: 0.4525
Epoch 10/100
0s - loss: 0.4522 - val_loss: 0.4515
Epoch 11/100
0s - loss: 0.4496 - val_loss: 0.4498
Epoch 12/100
0s - loss: 0.4471 - val_loss: 0.4491
Epoch 13/100
0s - loss: 0.4438 - val_loss: 0.4478
Epoch 14/100
0s - loss: 0.4411 - val_loss: 0.4463
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4462
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:03,797 - 23_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.446225
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5845 - val_loss: 0.5425
Epoch 2/100
0s - loss: 0.5128 - val_loss: 0.5083
Epoch 3/100
0s - loss: 0.4841 - val_loss: 0.4976
Epoch 4/100
0s - loss: 0.4746 - val_loss: 0.4908
Epoch 5/100
0s - loss: 0.4687 - val_loss: 0.4859
Epoch 6/100
0s - loss: 0.4634 - val_loss: 0.4821
Epoch 7/100
0s - loss: 0.4585 - val_loss: 0.4796
Epoch 8/100
0s - loss: 0.4550 - val_loss: 0.4767
Epoch 9/100
0s - loss: 0.4518 - val_loss: 0.4750
Epoch 10/100
0s - loss: 0.4493 - val_loss: 0.4740
Epoch 11/100
0s - loss: 0.4465 - val_loss: 0.4733
Epoch 12/100
0s - loss: 0.4440 - val_loss: 0.4727
Epoch 13/100
0s - loss: 0.4410 - val_loss: 0.4708
Epoch 14/100
0s - loss: 0.4379 - val_loss: 0.4701
Epoch 15/100
0s - loss: 0.4351 - val_loss: 0.4692
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:13,527 - 23_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.469249
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5840 - val_loss: 0.5315
Epoch 2/100
0s - loss: 0.5153 - val_loss: 0.4959
Epoch 3/100
0s - loss: 0.4885 - val_loss: 0.4758
Epoch 4/100
0s - loss: 0.4767 - val_loss: 0.4691
Epoch 5/100
0s - loss: 0.4703 - val_loss: 0.4637
Epoch 6/100
0s - loss: 0.4654 - val_loss: 0.4593
Epoch 7/100
0s - loss: 0.4609 - val_loss: 0.4570
Epoch 8/100
0s - loss: 0.4579 - val_loss: 0.4559
Epoch 9/100
0s - loss: 0.4551 - val_loss: 0.4539
Epoch 10/100
0s - loss: 0.4526 - val_loss: 0.4532
Epoch 11/100
0s - loss: 0.4500 - val_loss: 0.4508
Epoch 12/100
0s - loss: 0.4470 - val_loss: 0.4494
Epoch 13/100
0s - loss: 0.4441 - val_loss: 0.4480
Epoch 14/100
0s - loss: 0.4409 - val_loss: 0.4472
Epoch 15/100
0s - loss: 0.4384 - val_loss: 0.4469
Epoch 16/100
0s - loss: 0.4360 - val_loss: 0.4455
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:23,997 - 23_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.445521
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5837 - val_loss: 0.5330
Epoch 2/100
0s - loss: 0.5126 - val_loss: 0.4971
Epoch 3/100
0s - loss: 0.4847 - val_loss: 0.4853
Epoch 4/100
0s - loss: 0.4745 - val_loss: 0.4777
Epoch 5/100
0s - loss: 0.4681 - val_loss: 0.4743
Epoch 6/100
0s - loss: 0.4632 - val_loss: 0.4716
Epoch 7/100
0s - loss: 0.4591 - val_loss: 0.4682
Epoch 8/100
0s - loss: 0.4556 - val_loss: 0.4661
Epoch 9/100
0s - loss: 0.4525 - val_loss: 0.4651
Epoch 10/100
0s - loss: 0.4497 - val_loss: 0.4635
Epoch 11/100
0s - loss: 0.4470 - val_loss: 0.4629
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4623
Epoch 13/100
0s - loss: 0.4415 - val_loss: 0.4596
Epoch 14/100
0s - loss: 0.4382 - val_loss: 0.4588
Epoch 15/100
0s - loss: 0.4352 - val_loss: 0.4575
Epoch 16/100
0s - loss: 0.4324 - val_loss: 0.4571
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:34,320 - 23_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.457084
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5851 - val_loss: 0.5318
Epoch 2/100
0s - loss: 0.5122 - val_loss: 0.4923
Epoch 3/100
0s - loss: 0.4859 - val_loss: 0.4756
Epoch 4/100
0s - loss: 0.4751 - val_loss: 0.4684
Epoch 5/100
0s - loss: 0.4682 - val_loss: 0.4634
Epoch 6/100
0s - loss: 0.4633 - val_loss: 0.4595
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4571
Epoch 8/100
0s - loss: 0.4558 - val_loss: 0.4549
Epoch 9/100
0s - loss: 0.4527 - val_loss: 0.4535
Epoch 10/100
0s - loss: 0.4498 - val_loss: 0.4519
Epoch 11/100
0s - loss: 0.4470 - val_loss: 0.4519
Epoch 12/100
0s - loss: 0.4442 - val_loss: 0.4494
Epoch 13/100
0s - loss: 0.4408 - val_loss: 0.4487
Epoch 14/100
0s - loss: 0.4378 - val_loss: 0.4474
Epoch 15/100
0s - loss: 0.4345 - val_loss: 0.4466
Epoch 16/100
0s - loss: 0.4315 - val_loss: 0.4462
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:44,867 - 23_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.446153
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:44,867 - 23_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453002
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5829 - val_loss: 0.5282
Epoch 2/100
0s - loss: 0.5155 - val_loss: 0.4950
Epoch 3/100
0s - loss: 0.4902 - val_loss: 0.4814
Epoch 4/100
0s - loss: 0.4786 - val_loss: 0.4745
Epoch 5/100
0s - loss: 0.4716 - val_loss: 0.4700
Epoch 6/100
0s - loss: 0.4665 - val_loss: 0.4673
Epoch 7/100
0s - loss: 0.4618 - val_loss: 0.4658
Epoch 8/100
0s - loss: 0.4591 - val_loss: 0.4640
Epoch 9/100
0s - loss: 0.4558 - val_loss: 0.4615
Epoch 10/100
0s - loss: 0.4533 - val_loss: 0.4599
Epoch 11/100
0s - loss: 0.4503 - val_loss: 0.4586
Epoch 12/100
0s - loss: 0.4480 - val_loss: 0.4579
Epoch 13/100
0s - loss: 0.4456 - val_loss: 0.4569
Epoch 14/100
0s - loss: 0.4447 - val_loss: 0.4569
Epoch 15/100
0s - loss: 0.4417 - val_loss: 0.4553
Epoch 16/100
0s - loss: 0.4393 - val_loss: 0.4544
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:37:54,940 - 24_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.454438
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5842 - val_loss: 0.5272
Epoch 2/100
0s - loss: 0.5146 - val_loss: 0.4918
Epoch 3/100
0s - loss: 0.4866 - val_loss: 0.4769
Epoch 4/100
0s - loss: 0.4759 - val_loss: 0.4707
Epoch 5/100
0s - loss: 0.4696 - val_loss: 0.4669
Epoch 6/100
0s - loss: 0.4649 - val_loss: 0.4638
Epoch 7/100
0s - loss: 0.4605 - val_loss: 0.4607
Epoch 8/100
0s - loss: 0.4571 - val_loss: 0.4582
Epoch 9/100
0s - loss: 0.4532 - val_loss: 0.4564
Epoch 10/100
0s - loss: 0.4504 - val_loss: 0.4549
Epoch 11/100
0s - loss: 0.4472 - val_loss: 0.4538
Epoch 12/100
0s - loss: 0.4442 - val_loss: 0.4531
Epoch 13/100
0s - loss: 0.4416 - val_loss: 0.4511
Epoch 14/100
0s - loss: 0.4378 - val_loss: 0.4508
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4497
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:38:04,404 - 24_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.449737
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5840 - val_loss: 0.5338
Epoch 2/100
0s - loss: 0.5091 - val_loss: 0.4989
Epoch 3/100
0s - loss: 0.4834 - val_loss: 0.4875
Epoch 4/100
0s - loss: 0.4736 - val_loss: 0.4824
Epoch 5/100
0s - loss: 0.4672 - val_loss: 0.4793
Epoch 6/100
0s - loss: 0.4626 - val_loss: 0.4756
Epoch 7/100
0s - loss: 0.4583 - val_loss: 0.4717
Epoch 8/100
0s - loss: 0.4548 - val_loss: 0.4702
Epoch 9/100
0s - loss: 0.4519 - val_loss: 0.4681
Epoch 10/100
0s - loss: 0.4488 - val_loss: 0.4669
Epoch 11/100
0s - loss: 0.4456 - val_loss: 0.4656
Epoch 12/100
0s - loss: 0.4429 - val_loss: 0.4648
Epoch 13/100
0s - loss: 0.4398 - val_loss: 0.4639
Epoch 14/100
0s - loss: 0.4368 - val_loss: 0.4625
Epoch 15/100
0s - loss: 0.4335 - val_loss: 0.4622
Epoch 16/100
0s - loss: 0.4306 - val_loss: 0.4609
Epoch 17/100
0s - loss: 0.4274 - val_loss: 0.4596
Epoch 18/100
0s - loss: 0.4243 - val_loss: 0.4598
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:38:15,594 - 24_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.459819
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5883 - val_loss: 0.5268
Epoch 2/100
0s - loss: 0.5152 - val_loss: 0.4971
Epoch 3/100
0s - loss: 0.4888 - val_loss: 0.4792
Epoch 4/100
0s - loss: 0.4760 - val_loss: 0.4722
Epoch 5/100
0s - loss: 0.4698 - val_loss: 0.4681
Epoch 6/100
0s - loss: 0.4650 - val_loss: 0.4643
Epoch 7/100
0s - loss: 0.4607 - val_loss: 0.4627
Epoch 8/100
0s - loss: 0.4577 - val_loss: 0.4604
Epoch 9/100
0s - loss: 0.4550 - val_loss: 0.4595
Epoch 10/100
0s - loss: 0.4528 - val_loss: 0.4581
Epoch 11/100
0s - loss: 0.4503 - val_loss: 0.4573
Epoch 12/100
0s - loss: 0.4474 - val_loss: 0.4548
Epoch 13/100
0s - loss: 0.4447 - val_loss: 0.4536
Epoch 14/100
0s - loss: 0.4419 - val_loss: 0.4525
Epoch 15/100
0s - loss: 0.4392 - val_loss: 0.4517
Epoch 16/100
0s - loss: 0.4364 - val_loss: 0.4506
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:38:25,666 - 24_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.450643
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5879 - val_loss: 0.5313
Epoch 2/100
0s - loss: 0.5122 - val_loss: 0.4963
Epoch 3/100
0s - loss: 0.4859 - val_loss: 0.4817
Epoch 4/100
0s - loss: 0.4743 - val_loss: 0.4766
Epoch 5/100
0s - loss: 0.4679 - val_loss: 0.4712
Epoch 6/100
0s - loss: 0.4629 - val_loss: 0.4683
Epoch 7/100
0s - loss: 0.4593 - val_loss: 0.4664
Epoch 8/100
0s - loss: 0.4559 - val_loss: 0.4637
Epoch 9/100
0s - loss: 0.4526 - val_loss: 0.4619
Epoch 10/100
0s - loss: 0.4500 - val_loss: 0.4608
Epoch 11/100
0s - loss: 0.4471 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4443 - val_loss: 0.4598
Epoch 13/100
0s - loss: 0.4414 - val_loss: 0.4573
Epoch 14/100
0s - loss: 0.4378 - val_loss: 0.4569
Epoch 15/100
0s - loss: 0.4350 - val_loss: 0.4560
Epoch 16/100
0s - loss: 0.4322 - val_loss: 0.4543
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:38:35,797 - 24_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.454345
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5896 - val_loss: 0.5255
Epoch 2/100
0s - loss: 0.5128 - val_loss: 0.4888
Epoch 3/100
0s - loss: 0.4870 - val_loss: 0.4727
Epoch 4/100
0s - loss: 0.4762 - val_loss: 0.4659
Epoch 5/100
0s - loss: 0.4698 - val_loss: 0.4629
Epoch 6/100
0s - loss: 0.4651 - val_loss: 0.4592
Epoch 7/100
0s - loss: 0.4613 - val_loss: 0.4564
Epoch 8/100
0s - loss: 0.4576 - val_loss: 0.4543
Epoch 9/100
0s - loss: 0.4549 - val_loss: 0.4525
Epoch 10/100
0s - loss: 0.4522 - val_loss: 0.4512
Epoch 11/100
0s - loss: 0.4493 - val_loss: 0.4503
Epoch 12/100
0s - loss: 0.4465 - val_loss: 0.4496
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:38:43,807 - 24_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.449586
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5878 - val_loss: 0.5438
Epoch 2/100
0s - loss: 0.5124 - val_loss: 0.5085
Epoch 3/100
0s - loss: 0.4848 - val_loss: 0.4958
Epoch 4/100
0s - loss: 0.4737 - val_loss: 0.4897
Epoch 5/100
0s - loss: 0.4675 - val_loss: 0.4851
Epoch 6/100
0s - loss: 0.4625 - val_loss: 0.4810
Epoch 7/100
0s - loss: 0.4582 - val_loss: 0.4785
Epoch 8/100
0s - loss: 0.4551 - val_loss: 0.4767
Epoch 9/100
0s - loss: 0.4520 - val_loss: 0.4754
Epoch 10/100
0s - loss: 0.4492 - val_loss: 0.4740
Epoch 11/100
0s - loss: 0.4465 - val_loss: 0.4744
Epoch 12/100
0s - loss: 0.4441 - val_loss: 0.4722
Epoch 13/100
0s - loss: 0.4413 - val_loss: 0.4708
Epoch 14/100
0s - loss: 0.4382 - val_loss: 0.4709
Epoch 15/100
0s - loss: 0.4357 - val_loss: 0.4697
Epoch 16/100
0s - loss: 0.4322 - val_loss: 0.4683
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:38:53,913 - 24_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.468309
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5822 - val_loss: 0.5266
Epoch 2/100
0s - loss: 0.5130 - val_loss: 0.4943
Epoch 3/100
0s - loss: 0.4888 - val_loss: 0.4780
Epoch 4/100
0s - loss: 0.4778 - val_loss: 0.4693
Epoch 5/100
0s - loss: 0.4706 - val_loss: 0.4643
Epoch 6/100
0s - loss: 0.4660 - val_loss: 0.4600
Epoch 7/100
0s - loss: 0.4619 - val_loss: 0.4579
Epoch 8/100
0s - loss: 0.4583 - val_loss: 0.4554
Epoch 9/100
0s - loss: 0.4550 - val_loss: 0.4532
Epoch 10/100
0s - loss: 0.4519 - val_loss: 0.4524
Epoch 11/100
0s - loss: 0.4494 - val_loss: 0.4516
Epoch 12/100
0s - loss: 0.4465 - val_loss: 0.4493
Epoch 13/100
0s - loss: 0.4436 - val_loss: 0.4484
Epoch 14/100
0s - loss: 0.4408 - val_loss: 0.4477
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4473
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:03,547 - 24_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.447270
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5888 - val_loss: 0.5303
Epoch 2/100
0s - loss: 0.5112 - val_loss: 0.4969
Epoch 3/100
0s - loss: 0.4850 - val_loss: 0.4836
Epoch 4/100
0s - loss: 0.4730 - val_loss: 0.4764
Epoch 5/100
0s - loss: 0.4661 - val_loss: 0.4716
Epoch 6/100
0s - loss: 0.4609 - val_loss: 0.4692
Epoch 7/100
0s - loss: 0.4571 - val_loss: 0.4668
Epoch 8/100
0s - loss: 0.4538 - val_loss: 0.4666
Epoch 9/100
0s - loss: 0.4511 - val_loss: 0.4643
Epoch 10/100
0s - loss: 0.4479 - val_loss: 0.4621
Epoch 11/100
0s - loss: 0.4444 - val_loss: 0.4613
Epoch 12/100
0s - loss: 0.4417 - val_loss: 0.4598
Epoch 13/100
0s - loss: 0.4384 - val_loss: 0.4592
Epoch 14/100
0s - loss: 0.4357 - val_loss: 0.4576
Epoch 15/100
0s - loss: 0.4329 - val_loss: 0.4564
Epoch 16/100
0s - loss: 0.4295 - val_loss: 0.4563
Epoch 17/100
0s - loss: 0.4267 - val_loss: 0.4548
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:14,270 - 24_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.454798
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5839 - val_loss: 0.5279
Epoch 2/100
0s - loss: 0.5116 - val_loss: 0.4916
Epoch 3/100
0s - loss: 0.4850 - val_loss: 0.4749
Epoch 4/100
0s - loss: 0.4745 - val_loss: 0.4688
Epoch 5/100
0s - loss: 0.4687 - val_loss: 0.4643
Epoch 6/100
0s - loss: 0.4637 - val_loss: 0.4607
Epoch 7/100
0s - loss: 0.4596 - val_loss: 0.4577
Epoch 8/100
0s - loss: 0.4563 - val_loss: 0.4559
Epoch 9/100
0s - loss: 0.4537 - val_loss: 0.4543
Epoch 10/100
0s - loss: 0.4509 - val_loss: 0.4531
Epoch 11/100
0s - loss: 0.4483 - val_loss: 0.4527
Epoch 12/100
0s - loss: 0.4459 - val_loss: 0.4510
Epoch 13/100
0s - loss: 0.4429 - val_loss: 0.4491
Epoch 14/100
0s - loss: 0.4398 - val_loss: 0.4484
Epoch 15/100
0s - loss: 0.4368 - val_loss: 0.4479
Epoch 16/100
0s - loss: 0.4341 - val_loss: 0.4464
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:24,436 - 24_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.446361
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:24,437 - 24_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453531
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5797 - val_loss: 0.5296
Epoch 2/100
0s - loss: 0.5159 - val_loss: 0.4944
Epoch 3/100
0s - loss: 0.4892 - val_loss: 0.4805
Epoch 4/100
0s - loss: 0.4776 - val_loss: 0.4768
Epoch 5/100
0s - loss: 0.4714 - val_loss: 0.4722
Epoch 6/100
0s - loss: 0.4658 - val_loss: 0.4669
Epoch 7/100
0s - loss: 0.4618 - val_loss: 0.4683
Epoch 8/100
0s - loss: 0.4601 - val_loss: 0.4649
Epoch 9/100
0s - loss: 0.4567 - val_loss: 0.4628
Epoch 10/100
0s - loss: 0.4546 - val_loss: 0.4607
Epoch 11/100
0s - loss: 0.4518 - val_loss: 0.4603
Epoch 12/100
0s - loss: 0.4493 - val_loss: 0.4580
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:32,257 - 25_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.457952
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5860 - val_loss: 0.5264
Epoch 2/100
0s - loss: 0.5117 - val_loss: 0.4894
Epoch 3/100
0s - loss: 0.4853 - val_loss: 0.4786
Epoch 4/100
0s - loss: 0.4750 - val_loss: 0.4698
Epoch 5/100
0s - loss: 0.4681 - val_loss: 0.4649
Epoch 6/100
0s - loss: 0.4627 - val_loss: 0.4614
Epoch 7/100
0s - loss: 0.4584 - val_loss: 0.4595
Epoch 8/100
0s - loss: 0.4552 - val_loss: 0.4574
Epoch 9/100
0s - loss: 0.4524 - val_loss: 0.4556
Epoch 10/100
0s - loss: 0.4493 - val_loss: 0.4541
Epoch 11/100
0s - loss: 0.4462 - val_loss: 0.4533
Epoch 12/100
0s - loss: 0.4432 - val_loss: 0.4515
Epoch 13/100
0s - loss: 0.4403 - val_loss: 0.4506
Epoch 14/100
0s - loss: 0.4376 - val_loss: 0.4493
Epoch 15/100
0s - loss: 0.4347 - val_loss: 0.4477
Epoch 16/100
0s - loss: 0.4317 - val_loss: 0.4482
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:42,231 - 25_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.448185
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5374
Epoch 2/100
0s - loss: 0.5141 - val_loss: 0.5036
Epoch 3/100
0s - loss: 0.4850 - val_loss: 0.4891
Epoch 4/100
0s - loss: 0.4750 - val_loss: 0.4829
Epoch 5/100
0s - loss: 0.4674 - val_loss: 0.4783
Epoch 6/100
0s - loss: 0.4621 - val_loss: 0.4748
Epoch 7/100
0s - loss: 0.4580 - val_loss: 0.4721
Epoch 8/100
0s - loss: 0.4552 - val_loss: 0.4707
Epoch 9/100
0s - loss: 0.4526 - val_loss: 0.4691
Epoch 10/100
0s - loss: 0.4498 - val_loss: 0.4677
Epoch 11/100
0s - loss: 0.4468 - val_loss: 0.4665
Epoch 12/100
0s - loss: 0.4441 - val_loss: 0.4663
Epoch 13/100
0s - loss: 0.4413 - val_loss: 0.4650
Epoch 14/100
0s - loss: 0.4383 - val_loss: 0.4628
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4621
Epoch 16/100
0s - loss: 0.4321 - val_loss: 0.4615
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:39:52,445 - 25_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.461493
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5874 - val_loss: 0.5248
Epoch 2/100
0s - loss: 0.5104 - val_loss: 0.4912
Epoch 3/100
0s - loss: 0.4844 - val_loss: 0.4790
Epoch 4/100
0s - loss: 0.4747 - val_loss: 0.4725
Epoch 5/100
0s - loss: 0.4684 - val_loss: 0.4688
Epoch 6/100
0s - loss: 0.4637 - val_loss: 0.4645
Epoch 7/100
0s - loss: 0.4591 - val_loss: 0.4622
Epoch 8/100
0s - loss: 0.4557 - val_loss: 0.4598
Epoch 9/100
0s - loss: 0.4528 - val_loss: 0.4586
Epoch 10/100
0s - loss: 0.4502 - val_loss: 0.4570
Epoch 11/100
0s - loss: 0.4474 - val_loss: 0.4547
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4533
Epoch 13/100
0s - loss: 0.4415 - val_loss: 0.4519
Epoch 14/100
0s - loss: 0.4384 - val_loss: 0.4522
Epoch 15/100
0s - loss: 0.4359 - val_loss: 0.4505
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:40:02,003 - 25_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.450476
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5867 - val_loss: 0.5334
Epoch 2/100
0s - loss: 0.5133 - val_loss: 0.4989
Epoch 3/100
0s - loss: 0.4872 - val_loss: 0.4830
Epoch 4/100
0s - loss: 0.4759 - val_loss: 0.4774
Epoch 5/100
0s - loss: 0.4700 - val_loss: 0.4730
Epoch 6/100
0s - loss: 0.4648 - val_loss: 0.4693
Epoch 7/100
0s - loss: 0.4604 - val_loss: 0.4672
Epoch 8/100
0s - loss: 0.4571 - val_loss: 0.4650
Epoch 9/100
0s - loss: 0.4538 - val_loss: 0.4627
Epoch 10/100
0s - loss: 0.4512 - val_loss: 0.4619
Epoch 11/100
0s - loss: 0.4482 - val_loss: 0.4603
Epoch 12/100
0s - loss: 0.4454 - val_loss: 0.4590
Epoch 13/100
0s - loss: 0.4426 - val_loss: 0.4585
Epoch 14/100
0s - loss: 0.4395 - val_loss: 0.4577
Epoch 15/100
0s - loss: 0.4362 - val_loss: 0.4567
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:40:11,687 - 25_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.456740
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5864 - val_loss: 0.5230
Epoch 2/100
0s - loss: 0.5129 - val_loss: 0.4864
Epoch 3/100
0s - loss: 0.4865 - val_loss: 0.4731
Epoch 4/100
0s - loss: 0.4766 - val_loss: 0.4669
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4624
Epoch 6/100
0s - loss: 0.4649 - val_loss: 0.4590
Epoch 7/100
0s - loss: 0.4611 - val_loss: 0.4559
Epoch 8/100
0s - loss: 0.4579 - val_loss: 0.4541
Epoch 9/100
0s - loss: 0.4551 - val_loss: 0.4533
Epoch 10/100
0s - loss: 0.4525 - val_loss: 0.4513
Epoch 11/100
0s - loss: 0.4495 - val_loss: 0.4504
Epoch 12/100
0s - loss: 0.4470 - val_loss: 0.4495
Epoch 13/100
0s - loss: 0.4441 - val_loss: 0.4493
Epoch 14/100
0s - loss: 0.4418 - val_loss: 0.4468
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4463
Epoch 16/100
0s - loss: 0.4354 - val_loss: 0.4457
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:40:21,857 - 25_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.445728
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5841 - val_loss: 0.5423
Epoch 2/100
0s - loss: 0.5134 - val_loss: 0.5098
Epoch 3/100
0s - loss: 0.4863 - val_loss: 0.4955
Epoch 4/100
0s - loss: 0.4739 - val_loss: 0.4897
Epoch 5/100
0s - loss: 0.4674 - val_loss: 0.4851
Epoch 6/100
0s - loss: 0.4621 - val_loss: 0.4830
Epoch 7/100
0s - loss: 0.4582 - val_loss: 0.4780
Epoch 8/100
0s - loss: 0.4543 - val_loss: 0.4762
Epoch 9/100
0s - loss: 0.4516 - val_loss: 0.4753
Epoch 10/100
0s - loss: 0.4490 - val_loss: 0.4742
Epoch 11/100
0s - loss: 0.4459 - val_loss: 0.4733
Epoch 12/100
0s - loss: 0.4432 - val_loss: 0.4720
Epoch 13/100
0s - loss: 0.4401 - val_loss: 0.4705
Epoch 14/100
0s - loss: 0.4373 - val_loss: 0.4698
Epoch 15/100
0s - loss: 0.4345 - val_loss: 0.4691
Epoch 16/100
0s - loss: 0.4318 - val_loss: 0.4680
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:40:32,028 - 25_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.468046
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5889 - val_loss: 0.5279
Epoch 2/100
0s - loss: 0.5137 - val_loss: 0.4951
Epoch 3/100
0s - loss: 0.4888 - val_loss: 0.4766
Epoch 4/100
0s - loss: 0.4761 - val_loss: 0.4671
Epoch 5/100
0s - loss: 0.4690 - val_loss: 0.4619
Epoch 6/100
0s - loss: 0.4647 - val_loss: 0.4583
Epoch 7/100
0s - loss: 0.4603 - val_loss: 0.4559
Epoch 8/100
0s - loss: 0.4568 - val_loss: 0.4541
Epoch 9/100
0s - loss: 0.4541 - val_loss: 0.4526
Epoch 10/100
0s - loss: 0.4511 - val_loss: 0.4512
Epoch 11/100
0s - loss: 0.4482 - val_loss: 0.4496
Epoch 12/100
0s - loss: 0.4454 - val_loss: 0.4486
Epoch 13/100
0s - loss: 0.4425 - val_loss: 0.4469
Epoch 14/100
0s - loss: 0.4395 - val_loss: 0.4463
Epoch 15/100
0s - loss: 0.4361 - val_loss: 0.4449
Epoch 16/100
0s - loss: 0.4335 - val_loss: 0.4436
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:40:42,248 - 25_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.443633
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5846 - val_loss: 0.5287
Epoch 2/100
0s - loss: 0.5109 - val_loss: 0.4976
Epoch 3/100
0s - loss: 0.4854 - val_loss: 0.4854
Epoch 4/100
0s - loss: 0.4751 - val_loss: 0.4803
Epoch 5/100
0s - loss: 0.4686 - val_loss: 0.4739
Epoch 6/100
0s - loss: 0.4633 - val_loss: 0.4719
Epoch 7/100
0s - loss: 0.4591 - val_loss: 0.4687
Epoch 8/100
0s - loss: 0.4560 - val_loss: 0.4677
Epoch 9/100
0s - loss: 0.4529 - val_loss: 0.4655
Epoch 10/100
0s - loss: 0.4499 - val_loss: 0.4642
Epoch 11/100
0s - loss: 0.4470 - val_loss: 0.4630
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4630
Epoch 13/100
0s - loss: 0.4418 - val_loss: 0.4613
Epoch 14/100
0s - loss: 0.4388 - val_loss: 0.4599
Epoch 15/100
0s - loss: 0.4358 - val_loss: 0.4597
Epoch 16/100
0s - loss: 0.4329 - val_loss: 0.4586
Epoch 17/100
0s - loss: 0.4302 - val_loss: 0.4575
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:40:52,922 - 25_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.457508
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5889 - val_loss: 0.5322
Epoch 2/100
0s - loss: 0.5161 - val_loss: 0.4982
Epoch 3/100
0s - loss: 0.4889 - val_loss: 0.4768
Epoch 4/100
0s - loss: 0.4758 - val_loss: 0.4689
Epoch 5/100
0s - loss: 0.4688 - val_loss: 0.4644
Epoch 6/100
0s - loss: 0.4637 - val_loss: 0.4612
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4581
Epoch 8/100
0s - loss: 0.4561 - val_loss: 0.4558
Epoch 9/100
0s - loss: 0.4531 - val_loss: 0.4544
Epoch 10/100
0s - loss: 0.4503 - val_loss: 0.4529
Epoch 11/100
0s - loss: 0.4473 - val_loss: 0.4514
Epoch 12/100
0s - loss: 0.4445 - val_loss: 0.4514
Epoch 13/100
0s - loss: 0.4416 - val_loss: 0.4490
Epoch 14/100
0s - loss: 0.4383 - val_loss: 0.4480
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4477
Epoch 16/100
0s - loss: 0.4325 - val_loss: 0.4461
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:03,012 - 25_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.446083
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:03,013 - 25_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453584
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5863 - val_loss: 0.5280
Epoch 2/100
0s - loss: 0.5140 - val_loss: 0.4934
Epoch 3/100
0s - loss: 0.4884 - val_loss: 0.4852
Epoch 4/100
0s - loss: 0.4797 - val_loss: 0.4769
Epoch 5/100
0s - loss: 0.4718 - val_loss: 0.4706
Epoch 6/100
0s - loss: 0.4665 - val_loss: 0.4686
Epoch 7/100
0s - loss: 0.4629 - val_loss: 0.4655
Epoch 8/100
0s - loss: 0.4599 - val_loss: 0.4648
Epoch 9/100
0s - loss: 0.4579 - val_loss: 0.4625
Epoch 10/100
0s - loss: 0.4550 - val_loss: 0.4615
Epoch 11/100
0s - loss: 0.4527 - val_loss: 0.4598
Epoch 12/100
0s - loss: 0.4499 - val_loss: 0.4582
Epoch 13/100
0s - loss: 0.4482 - val_loss: 0.4562
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:11,486 - 26_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.456220
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5864 - val_loss: 0.5325
Epoch 2/100
0s - loss: 0.5203 - val_loss: 0.4965
Epoch 3/100
0s - loss: 0.4886 - val_loss: 0.4768
Epoch 4/100
0s - loss: 0.4763 - val_loss: 0.4708
Epoch 5/100
0s - loss: 0.4701 - val_loss: 0.4664
Epoch 6/100
0s - loss: 0.4655 - val_loss: 0.4631
Epoch 7/100
0s - loss: 0.4607 - val_loss: 0.4600
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4572
Epoch 9/100
0s - loss: 0.4534 - val_loss: 0.4559
Epoch 10/100
0s - loss: 0.4503 - val_loss: 0.4546
Epoch 11/100
0s - loss: 0.4477 - val_loss: 0.4540
Epoch 12/100
0s - loss: 0.4447 - val_loss: 0.4521
Epoch 13/100
0s - loss: 0.4411 - val_loss: 0.4507
Epoch 14/100
0s - loss: 0.4381 - val_loss: 0.4497
Epoch 15/100
0s - loss: 0.4352 - val_loss: 0.4489
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:21,115 - 26_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.448903
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5359
Epoch 2/100
0s - loss: 0.5127 - val_loss: 0.5010
Epoch 3/100
0s - loss: 0.4846 - val_loss: 0.4886
Epoch 4/100
0s - loss: 0.4747 - val_loss: 0.4834
Epoch 5/100
0s - loss: 0.4677 - val_loss: 0.4785
Epoch 6/100
0s - loss: 0.4622 - val_loss: 0.4743
Epoch 7/100
0s - loss: 0.4580 - val_loss: 0.4727
Epoch 8/100
0s - loss: 0.4551 - val_loss: 0.4703
Epoch 9/100
0s - loss: 0.4521 - val_loss: 0.4687
Epoch 10/100
0s - loss: 0.4494 - val_loss: 0.4689
Epoch 11/100
0s - loss: 0.4467 - val_loss: 0.4659
Epoch 12/100
0s - loss: 0.4433 - val_loss: 0.4646
Epoch 13/100
0s - loss: 0.4405 - val_loss: 0.4636
Epoch 14/100
0s - loss: 0.4377 - val_loss: 0.4631
Epoch 15/100
0s - loss: 0.4347 - val_loss: 0.4635
Epoch 16/100
0s - loss: 0.4318 - val_loss: 0.4608
Epoch 17/100
0s - loss: 0.4285 - val_loss: 0.4601
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:31,846 - 26_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.460085
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5846 - val_loss: 0.5278
Epoch 2/100
0s - loss: 0.5130 - val_loss: 0.4947
Epoch 3/100
0s - loss: 0.4886 - val_loss: 0.4806
Epoch 4/100
0s - loss: 0.4770 - val_loss: 0.4731
Epoch 5/100
0s - loss: 0.4698 - val_loss: 0.4681
Epoch 6/100
0s - loss: 0.4643 - val_loss: 0.4654
Epoch 7/100
0s - loss: 0.4600 - val_loss: 0.4615
Epoch 8/100
0s - loss: 0.4562 - val_loss: 0.4601
Epoch 9/100
0s - loss: 0.4535 - val_loss: 0.4584
Epoch 10/100
0s - loss: 0.4502 - val_loss: 0.4563
Epoch 11/100
0s - loss: 0.4474 - val_loss: 0.4547
Epoch 12/100
0s - loss: 0.4446 - val_loss: 0.4535
Epoch 13/100
0s - loss: 0.4414 - val_loss: 0.4524
Epoch 14/100
0s - loss: 0.4390 - val_loss: 0.4527
Epoch 15/100
0s - loss: 0.4366 - val_loss: 0.4503
Epoch 16/100
0s - loss: 0.4336 - val_loss: 0.4496
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:42,046 - 26_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.449638
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5859 - val_loss: 0.5347
Epoch 2/100
0s - loss: 0.5161 - val_loss: 0.4987
Epoch 3/100
0s - loss: 0.4880 - val_loss: 0.4843
Epoch 4/100
0s - loss: 0.4774 - val_loss: 0.4778
Epoch 5/100
0s - loss: 0.4703 - val_loss: 0.4735
Epoch 6/100
0s - loss: 0.4650 - val_loss: 0.4696
Epoch 7/100
0s - loss: 0.4606 - val_loss: 0.4669
Epoch 8/100
0s - loss: 0.4570 - val_loss: 0.4643
Epoch 9/100
0s - loss: 0.4539 - val_loss: 0.4621
Epoch 10/100
0s - loss: 0.4509 - val_loss: 0.4612
Epoch 11/100
0s - loss: 0.4479 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4451 - val_loss: 0.4592
Epoch 13/100
0s - loss: 0.4420 - val_loss: 0.4576
Epoch 14/100
0s - loss: 0.4388 - val_loss: 0.4562
Epoch 15/100
0s - loss: 0.4360 - val_loss: 0.4570
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:41:51,621 - 26_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.456990
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5840 - val_loss: 0.5255
Epoch 2/100
0s - loss: 0.5128 - val_loss: 0.4859
Epoch 3/100
0s - loss: 0.4865 - val_loss: 0.4742
Epoch 4/100
0s - loss: 0.4769 - val_loss: 0.4667
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4638
Epoch 6/100
0s - loss: 0.4661 - val_loss: 0.4594
Epoch 7/100
0s - loss: 0.4620 - val_loss: 0.4575
Epoch 8/100
0s - loss: 0.4589 - val_loss: 0.4565
Epoch 9/100
0s - loss: 0.4560 - val_loss: 0.4529
Epoch 10/100
0s - loss: 0.4525 - val_loss: 0.4519
Epoch 11/100
0s - loss: 0.4495 - val_loss: 0.4504
Epoch 12/100
0s - loss: 0.4469 - val_loss: 0.4496
Epoch 13/100
0s - loss: 0.4442 - val_loss: 0.4485
Epoch 14/100
0s - loss: 0.4413 - val_loss: 0.4473
Epoch 15/100
0s - loss: 0.4386 - val_loss: 0.4471
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:01,325 - 26_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.447071
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5815 - val_loss: 0.5350
Epoch 2/100
0s - loss: 0.5071 - val_loss: 0.5093
Epoch 3/100
0s - loss: 0.4839 - val_loss: 0.4950
Epoch 4/100
0s - loss: 0.4730 - val_loss: 0.4894
Epoch 5/100
0s - loss: 0.4675 - val_loss: 0.4852
Epoch 6/100
0s - loss: 0.4623 - val_loss: 0.4817
Epoch 7/100
0s - loss: 0.4580 - val_loss: 0.4790
Epoch 8/100
0s - loss: 0.4543 - val_loss: 0.4769
Epoch 9/100
0s - loss: 0.4515 - val_loss: 0.4758
Epoch 10/100
0s - loss: 0.4482 - val_loss: 0.4744
Epoch 11/100
0s - loss: 0.4456 - val_loss: 0.4729
Epoch 12/100
0s - loss: 0.4424 - val_loss: 0.4710
Epoch 13/100
0s - loss: 0.4394 - val_loss: 0.4707
Epoch 14/100
0s - loss: 0.4368 - val_loss: 0.4692
Epoch 15/100
0s - loss: 0.4338 - val_loss: 0.4716
Epoch 16/100
0s - loss: 0.4315 - val_loss: 0.4677
Epoch 17/100
0s - loss: 0.4278 - val_loss: 0.4666
Epoch 18/100
0s - loss: 0.4249 - val_loss: 0.4663
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:12,436 - 26_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.466256
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5872 - val_loss: 0.5287
Epoch 2/100
0s - loss: 0.5153 - val_loss: 0.4946
Epoch 3/100
0s - loss: 0.4885 - val_loss: 0.4763
Epoch 4/100
0s - loss: 0.4769 - val_loss: 0.4694
Epoch 5/100
0s - loss: 0.4710 - val_loss: 0.4649
Epoch 6/100
0s - loss: 0.4655 - val_loss: 0.4599
Epoch 7/100
0s - loss: 0.4611 - val_loss: 0.4572
Epoch 8/100
0s - loss: 0.4576 - val_loss: 0.4550
Epoch 9/100
0s - loss: 0.4544 - val_loss: 0.4530
Epoch 10/100
0s - loss: 0.4516 - val_loss: 0.4518
Epoch 11/100
0s - loss: 0.4487 - val_loss: 0.4505
Epoch 12/100
0s - loss: 0.4458 - val_loss: 0.4486
Epoch 13/100
0s - loss: 0.4428 - val_loss: 0.4475
Epoch 14/100
0s - loss: 0.4396 - val_loss: 0.4472
Epoch 15/100
0s - loss: 0.4374 - val_loss: 0.4457
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:22,088 - 26_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.445669
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5906 - val_loss: 0.5344
Epoch 2/100
0s - loss: 0.5153 - val_loss: 0.4991
Epoch 3/100
0s - loss: 0.4864 - val_loss: 0.4850
Epoch 4/100
0s - loss: 0.4761 - val_loss: 0.4800
Epoch 5/100
0s - loss: 0.4704 - val_loss: 0.4756
Epoch 6/100
0s - loss: 0.4655 - val_loss: 0.4743
Epoch 7/100
0s - loss: 0.4616 - val_loss: 0.4710
Epoch 8/100
0s - loss: 0.4578 - val_loss: 0.4682
Epoch 9/100
0s - loss: 0.4547 - val_loss: 0.4667
Epoch 10/100
0s - loss: 0.4517 - val_loss: 0.4649
Epoch 11/100
0s - loss: 0.4487 - val_loss: 0.4643
Epoch 12/100
0s - loss: 0.4462 - val_loss: 0.4626
Epoch 13/100
0s - loss: 0.4437 - val_loss: 0.4617
Epoch 14/100
0s - loss: 0.4408 - val_loss: 0.4602
Epoch 15/100
0s - loss: 0.4383 - val_loss: 0.4604
Epoch 16/100
0s - loss: 0.4353 - val_loss: 0.4583
Epoch 17/100
0s - loss: 0.4323 - val_loss: 0.4581
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:32,813 - 26_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.458123
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5890 - val_loss: 0.5308
Epoch 2/100
0s - loss: 0.5123 - val_loss: 0.4916
Epoch 3/100
0s - loss: 0.4855 - val_loss: 0.4756
Epoch 4/100
0s - loss: 0.4755 - val_loss: 0.4691
Epoch 5/100
0s - loss: 0.4692 - val_loss: 0.4650
Epoch 6/100
0s - loss: 0.4645 - val_loss: 0.4609
Epoch 7/100
0s - loss: 0.4601 - val_loss: 0.4585
Epoch 8/100
0s - loss: 0.4569 - val_loss: 0.4557
Epoch 9/100
0s - loss: 0.4538 - val_loss: 0.4539
Epoch 10/100
0s - loss: 0.4512 - val_loss: 0.4526
Epoch 11/100
0s - loss: 0.4484 - val_loss: 0.4513
Epoch 12/100
0s - loss: 0.4454 - val_loss: 0.4506
Epoch 13/100
0s - loss: 0.4426 - val_loss: 0.4486
Epoch 14/100
0s - loss: 0.4394 - val_loss: 0.4479
Epoch 15/100
0s - loss: 0.4367 - val_loss: 0.4472
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:42,484 - 26_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.447198
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:42,484 - 26_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453615
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5862 - val_loss: 0.5279
Epoch 2/100
0s - loss: 0.5154 - val_loss: 0.4932
Epoch 3/100
0s - loss: 0.4887 - val_loss: 0.4795
Epoch 4/100
0s - loss: 0.4774 - val_loss: 0.4742
Epoch 5/100
0s - loss: 0.4710 - val_loss: 0.4705
Epoch 6/100
0s - loss: 0.4669 - val_loss: 0.4684
Epoch 7/100
0s - loss: 0.4630 - val_loss: 0.4658
Epoch 8/100
0s - loss: 0.4600 - val_loss: 0.4649
Epoch 9/100
0s - loss: 0.4573 - val_loss: 0.4618
Epoch 10/100
0s - loss: 0.4540 - val_loss: 0.4613
Epoch 11/100
0s - loss: 0.4515 - val_loss: 0.4604
Epoch 12/100
0s - loss: 0.4494 - val_loss: 0.4585
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:42:50,507 - 27_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.458460
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5860 - val_loss: 0.5224
Epoch 2/100
0s - loss: 0.5113 - val_loss: 0.4903
Epoch 3/100
0s - loss: 0.4865 - val_loss: 0.4758
Epoch 4/100
0s - loss: 0.4760 - val_loss: 0.4705
Epoch 5/100
0s - loss: 0.4696 - val_loss: 0.4663
Epoch 6/100
0s - loss: 0.4639 - val_loss: 0.4625
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4588
Epoch 8/100
0s - loss: 0.4564 - val_loss: 0.4573
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4552
Epoch 10/100
0s - loss: 0.4510 - val_loss: 0.4541
Epoch 11/100
0s - loss: 0.4482 - val_loss: 0.4527
Epoch 12/100
0s - loss: 0.4457 - val_loss: 0.4511
Epoch 13/100
0s - loss: 0.4426 - val_loss: 0.4508
Epoch 14/100
0s - loss: 0.4401 - val_loss: 0.4499
Epoch 15/100
0s - loss: 0.4375 - val_loss: 0.4487
Epoch 16/100
0s - loss: 0.4344 - val_loss: 0.4481
Epoch 17/100
0s - loss: 0.4316 - val_loss: 0.4464
Epoch 18/100
0s - loss: 0.4286 - val_loss: 0.4458
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:43:01,650 - 27_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.445762
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5812 - val_loss: 0.5333
Epoch 2/100
0s - loss: 0.5111 - val_loss: 0.4999
Epoch 3/100
0s - loss: 0.4840 - val_loss: 0.4876
Epoch 4/100
0s - loss: 0.4735 - val_loss: 0.4823
Epoch 5/100
0s - loss: 0.4669 - val_loss: 0.4782
Epoch 6/100
0s - loss: 0.4617 - val_loss: 0.4744
Epoch 7/100
0s - loss: 0.4578 - val_loss: 0.4719
Epoch 8/100
0s - loss: 0.4547 - val_loss: 0.4699
Epoch 9/100
0s - loss: 0.4517 - val_loss: 0.4689
Epoch 10/100
0s - loss: 0.4491 - val_loss: 0.4669
Epoch 11/100
0s - loss: 0.4463 - val_loss: 0.4660
Epoch 12/100
0s - loss: 0.4435 - val_loss: 0.4649
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:43:09,885 - 27_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.464908
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5876 - val_loss: 0.5262
Epoch 2/100
0s - loss: 0.5138 - val_loss: 0.4950
Epoch 3/100
0s - loss: 0.4876 - val_loss: 0.4798
Epoch 4/100
0s - loss: 0.4765 - val_loss: 0.4740
Epoch 5/100
0s - loss: 0.4707 - val_loss: 0.4695
Epoch 6/100
0s - loss: 0.4650 - val_loss: 0.4646
Epoch 7/100
0s - loss: 0.4602 - val_loss: 0.4610
Epoch 8/100
0s - loss: 0.4566 - val_loss: 0.4597
Epoch 9/100
0s - loss: 0.4533 - val_loss: 0.4583
Epoch 10/100
0s - loss: 0.4508 - val_loss: 0.4564
Epoch 11/100
0s - loss: 0.4482 - val_loss: 0.4550
Epoch 12/100
0s - loss: 0.4454 - val_loss: 0.4543
Epoch 13/100
0s - loss: 0.4428 - val_loss: 0.4534
Epoch 14/100
0s - loss: 0.4398 - val_loss: 0.4528
Epoch 15/100
0s - loss: 0.4369 - val_loss: 0.4509
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:43:19,677 - 27_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.450883
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5877 - val_loss: 0.5338
Epoch 2/100
0s - loss: 0.5137 - val_loss: 0.4969
Epoch 3/100
0s - loss: 0.4843 - val_loss: 0.4818
Epoch 4/100
0s - loss: 0.4745 - val_loss: 0.4772
Epoch 5/100
0s - loss: 0.4687 - val_loss: 0.4731
Epoch 6/100
0s - loss: 0.4639 - val_loss: 0.4698
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4668
Epoch 8/100
0s - loss: 0.4566 - val_loss: 0.4644
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4627
Epoch 10/100
0s - loss: 0.4505 - val_loss: 0.4613
Epoch 11/100
0s - loss: 0.4477 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4449 - val_loss: 0.4589
Epoch 13/100
0s - loss: 0.4422 - val_loss: 0.4582
Epoch 14/100
0s - loss: 0.4389 - val_loss: 0.4565
Epoch 15/100
0s - loss: 0.4360 - val_loss: 0.4558
Epoch 16/100
0s - loss: 0.4332 - val_loss: 0.4545
Epoch 17/100
0s - loss: 0.4298 - val_loss: 0.4541
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:43:30,459 - 27_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.454074
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5911 - val_loss: 0.5297
Epoch 2/100
0s - loss: 0.5181 - val_loss: 0.4938
Epoch 3/100
0s - loss: 0.4921 - val_loss: 0.4745
Epoch 4/100
0s - loss: 0.4782 - val_loss: 0.4676
Epoch 5/100
0s - loss: 0.4716 - val_loss: 0.4630
Epoch 6/100
0s - loss: 0.4667 - val_loss: 0.4601
Epoch 7/100
0s - loss: 0.4624 - val_loss: 0.4573
Epoch 8/100
0s - loss: 0.4588 - val_loss: 0.4552
Epoch 9/100
0s - loss: 0.4560 - val_loss: 0.4537
Epoch 10/100
0s - loss: 0.4530 - val_loss: 0.4525
Epoch 11/100
0s - loss: 0.4503 - val_loss: 0.4512
Epoch 12/100
0s - loss: 0.4476 - val_loss: 0.4527
Epoch 13/100
0s - loss: 0.4463 - val_loss: 0.4508
Epoch 14/100
0s - loss: 0.4430 - val_loss: 0.4504
Epoch 15/100
0s - loss: 0.4406 - val_loss: 0.4476
Epoch 16/100
0s - loss: 0.4376 - val_loss: 0.4469
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:43:40,913 - 27_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.446932
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5846 - val_loss: 0.5469
Epoch 2/100
0s - loss: 0.5154 - val_loss: 0.5103
Epoch 3/100
0s - loss: 0.4863 - val_loss: 0.4957
Epoch 4/100
0s - loss: 0.4744 - val_loss: 0.4903
Epoch 5/100
0s - loss: 0.4681 - val_loss: 0.4853
Epoch 6/100
0s - loss: 0.4629 - val_loss: 0.4809
Epoch 7/100
0s - loss: 0.4586 - val_loss: 0.4778
Epoch 8/100
0s - loss: 0.4550 - val_loss: 0.4772
Epoch 9/100
0s - loss: 0.4520 - val_loss: 0.4751
Epoch 10/100
0s - loss: 0.4491 - val_loss: 0.4736
Epoch 11/100
0s - loss: 0.4461 - val_loss: 0.4722
Epoch 12/100
0s - loss: 0.4433 - val_loss: 0.4714
Epoch 13/100
0s - loss: 0.4405 - val_loss: 0.4717
Epoch 14/100
0s - loss: 0.4388 - val_loss: 0.4714
Epoch 15/100
0s - loss: 0.4355 - val_loss: 0.4687
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:43:50,691 - 27_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.468695
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5889 - val_loss: 0.5310
Epoch 2/100
0s - loss: 0.5154 - val_loss: 0.4944
Epoch 3/100
0s - loss: 0.4881 - val_loss: 0.4770
Epoch 4/100
0s - loss: 0.4764 - val_loss: 0.4696
Epoch 5/100
0s - loss: 0.4697 - val_loss: 0.4631
Epoch 6/100
0s - loss: 0.4638 - val_loss: 0.4584
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4564
Epoch 8/100
0s - loss: 0.4560 - val_loss: 0.4535
Epoch 9/100
0s - loss: 0.4530 - val_loss: 0.4521
Epoch 10/100
0s - loss: 0.4499 - val_loss: 0.4514
Epoch 11/100
0s - loss: 0.4473 - val_loss: 0.4490
Epoch 12/100
0s - loss: 0.4442 - val_loss: 0.4482
Epoch 13/100
0s - loss: 0.4410 - val_loss: 0.4474
Epoch 14/100
0s - loss: 0.4380 - val_loss: 0.4452
Epoch 15/100
0s - loss: 0.4347 - val_loss: 0.4444
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:00,382 - 27_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.444403
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5847 - val_loss: 0.5334
Epoch 2/100
0s - loss: 0.5150 - val_loss: 0.4988
Epoch 3/100
0s - loss: 0.4867 - val_loss: 0.4877
Epoch 4/100
0s - loss: 0.4771 - val_loss: 0.4794
Epoch 5/100
0s - loss: 0.4693 - val_loss: 0.4742
Epoch 6/100
0s - loss: 0.4642 - val_loss: 0.4718
Epoch 7/100
0s - loss: 0.4600 - val_loss: 0.4694
Epoch 8/100
0s - loss: 0.4565 - val_loss: 0.4680
Epoch 9/100
0s - loss: 0.4534 - val_loss: 0.4658
Epoch 10/100
0s - loss: 0.4504 - val_loss: 0.4640
Epoch 11/100
0s - loss: 0.4474 - val_loss: 0.4633
Epoch 12/100
0s - loss: 0.4443 - val_loss: 0.4609
Epoch 13/100
0s - loss: 0.4417 - val_loss: 0.4605
Epoch 14/100
0s - loss: 0.4389 - val_loss: 0.4593
Epoch 15/100
0s - loss: 0.4362 - val_loss: 0.4589
Epoch 16/100
0s - loss: 0.4336 - val_loss: 0.4583
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:10,910 - 27_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.458299
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5876 - val_loss: 0.5293
Epoch 2/100
0s - loss: 0.5117 - val_loss: 0.4931
Epoch 3/100
0s - loss: 0.4866 - val_loss: 0.4770
Epoch 4/100
0s - loss: 0.4757 - val_loss: 0.4689
Epoch 5/100
0s - loss: 0.4689 - val_loss: 0.4635
Epoch 6/100
0s - loss: 0.4634 - val_loss: 0.4603
Epoch 7/100
0s - loss: 0.4594 - val_loss: 0.4587
Epoch 8/100
0s - loss: 0.4562 - val_loss: 0.4564
Epoch 9/100
0s - loss: 0.4532 - val_loss: 0.4556
Epoch 10/100
0s - loss: 0.4506 - val_loss: 0.4536
Epoch 11/100
0s - loss: 0.4471 - val_loss: 0.4510
Epoch 12/100
0s - loss: 0.4439 - val_loss: 0.4502
Epoch 13/100
0s - loss: 0.4409 - val_loss: 0.4491
Epoch 14/100
0s - loss: 0.4379 - val_loss: 0.4481
Epoch 15/100
0s - loss: 0.4351 - val_loss: 0.4471
Epoch 16/100
0s - loss: 0.4316 - val_loss: 0.4464
Epoch 17/100
0s - loss: 0.4288 - val_loss: 0.4455
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:21,976 - 27_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.445502
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:21,977 - 27_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453792
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5826 - val_loss: 0.5364
Epoch 2/100
0s - loss: 0.5185 - val_loss: 0.4969
Epoch 3/100
0s - loss: 0.4919 - val_loss: 0.4825
Epoch 4/100
0s - loss: 0.4797 - val_loss: 0.4760
Epoch 5/100
0s - loss: 0.4744 - val_loss: 0.4728
Epoch 6/100
0s - loss: 0.4692 - val_loss: 0.4697
Epoch 7/100
0s - loss: 0.4650 - val_loss: 0.4669
Epoch 8/100
0s - loss: 0.4616 - val_loss: 0.4647
Epoch 9/100
0s - loss: 0.4581 - val_loss: 0.4624
Epoch 10/100
0s - loss: 0.4560 - val_loss: 0.4609
Epoch 11/100
0s - loss: 0.4533 - val_loss: 0.4607
Epoch 12/100
0s - loss: 0.4511 - val_loss: 0.4590
Epoch 13/100
0s - loss: 0.4487 - val_loss: 0.4574
Epoch 14/100
0s - loss: 0.4458 - val_loss: 0.4567
Epoch 15/100
0s - loss: 0.4443 - val_loss: 0.4564
Epoch 16/100
0s - loss: 0.4418 - val_loss: 0.4541
Epoch 17/100
0s - loss: 0.4389 - val_loss: 0.4531
Epoch 18/100
0s - loss: 0.4361 - val_loss: 0.4519
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:33,167 - 28_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.451908
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5851 - val_loss: 0.5241
Epoch 2/100
0s - loss: 0.5131 - val_loss: 0.4901
Epoch 3/100
0s - loss: 0.4868 - val_loss: 0.4770
Epoch 4/100
0s - loss: 0.4770 - val_loss: 0.4720
Epoch 5/100
0s - loss: 0.4707 - val_loss: 0.4674
Epoch 6/100
0s - loss: 0.4651 - val_loss: 0.4623
Epoch 7/100
0s - loss: 0.4601 - val_loss: 0.4591
Epoch 8/100
0s - loss: 0.4566 - val_loss: 0.4579
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4559
Epoch 10/100
0s - loss: 0.4507 - val_loss: 0.4545
Epoch 11/100
0s - loss: 0.4480 - val_loss: 0.4537
Epoch 12/100
0s - loss: 0.4449 - val_loss: 0.4526
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:41,022 - 28_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.452555
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5870 - val_loss: 0.5351
Epoch 2/100
0s - loss: 0.5142 - val_loss: 0.5025
Epoch 3/100
0s - loss: 0.4853 - val_loss: 0.4898
Epoch 4/100
0s - loss: 0.4744 - val_loss: 0.4827
Epoch 5/100
0s - loss: 0.4677 - val_loss: 0.4778
Epoch 6/100
0s - loss: 0.4620 - val_loss: 0.4740
Epoch 7/100
0s - loss: 0.4577 - val_loss: 0.4715
Epoch 8/100
0s - loss: 0.4543 - val_loss: 0.4700
Epoch 9/100
0s - loss: 0.4513 - val_loss: 0.4685
Epoch 10/100
0s - loss: 0.4487 - val_loss: 0.4675
Epoch 11/100
0s - loss: 0.4462 - val_loss: 0.4666
Epoch 12/100
0s - loss: 0.4433 - val_loss: 0.4672
Epoch 13/100
0s - loss: 0.4409 - val_loss: 0.4649
Epoch 14/100
0s - loss: 0.4379 - val_loss: 0.4637
Epoch 15/100
0s - loss: 0.4346 - val_loss: 0.4628
Epoch 16/100
0s - loss: 0.4320 - val_loss: 0.4618
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:44:51,119 - 28_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.461848
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5872 - val_loss: 0.5288
Epoch 2/100
0s - loss: 0.5163 - val_loss: 0.5000
Epoch 3/100
0s - loss: 0.4903 - val_loss: 0.4819
Epoch 4/100
0s - loss: 0.4768 - val_loss: 0.4749
Epoch 5/100
0s - loss: 0.4701 - val_loss: 0.4690
Epoch 6/100
0s - loss: 0.4653 - val_loss: 0.4664
Epoch 7/100
0s - loss: 0.4614 - val_loss: 0.4631
Epoch 8/100
0s - loss: 0.4578 - val_loss: 0.4613
Epoch 9/100
0s - loss: 0.4549 - val_loss: 0.4593
Epoch 10/100
0s - loss: 0.4522 - val_loss: 0.4578
Epoch 11/100
0s - loss: 0.4493 - val_loss: 0.4563
Epoch 12/100
0s - loss: 0.4463 - val_loss: 0.4549
Epoch 13/100
0s - loss: 0.4436 - val_loss: 0.4535
Epoch 14/100
0s - loss: 0.4411 - val_loss: 0.4529
Epoch 15/100
0s - loss: 0.4382 - val_loss: 0.4519
Epoch 16/100
0s - loss: 0.4354 - val_loss: 0.4506
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:45:01,336 - 28_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.450613
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5882 - val_loss: 0.5325
Epoch 2/100
0s - loss: 0.5150 - val_loss: 0.5000
Epoch 3/100
0s - loss: 0.4876 - val_loss: 0.4829
Epoch 4/100
0s - loss: 0.4753 - val_loss: 0.4767
Epoch 5/100
0s - loss: 0.4688 - val_loss: 0.4727
Epoch 6/100
0s - loss: 0.4636 - val_loss: 0.4692
Epoch 7/100
0s - loss: 0.4600 - val_loss: 0.4660
Epoch 8/100
0s - loss: 0.4570 - val_loss: 0.4645
Epoch 9/100
0s - loss: 0.4536 - val_loss: 0.4628
Epoch 10/100
0s - loss: 0.4504 - val_loss: 0.4614
Epoch 11/100
0s - loss: 0.4475 - val_loss: 0.4601
Epoch 12/100
0s - loss: 0.4444 - val_loss: 0.4593
Epoch 13/100
0s - loss: 0.4420 - val_loss: 0.4586
Epoch 14/100
0s - loss: 0.4392 - val_loss: 0.4567
Epoch 15/100
0s - loss: 0.4360 - val_loss: 0.4565
Epoch 16/100
0s - loss: 0.4327 - val_loss: 0.4543
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:45:11,617 - 28_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.454316
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5861 - val_loss: 0.5285
Epoch 2/100
0s - loss: 0.5174 - val_loss: 0.4908
Epoch 3/100
0s - loss: 0.4884 - val_loss: 0.4732
Epoch 4/100
0s - loss: 0.4751 - val_loss: 0.4673
Epoch 5/100
0s - loss: 0.4690 - val_loss: 0.4617
Epoch 6/100
0s - loss: 0.4643 - val_loss: 0.4585
Epoch 7/100
0s - loss: 0.4605 - val_loss: 0.4551
Epoch 8/100
0s - loss: 0.4568 - val_loss: 0.4556
Epoch 9/100
0s - loss: 0.4543 - val_loss: 0.4521
Epoch 10/100
0s - loss: 0.4507 - val_loss: 0.4505
Epoch 11/100
0s - loss: 0.4481 - val_loss: 0.4506
Epoch 12/100
0s - loss: 0.4458 - val_loss: 0.4492
Epoch 13/100
0s - loss: 0.4430 - val_loss: 0.4479
Epoch 14/100
0s - loss: 0.4402 - val_loss: 0.4468
Epoch 15/100
0s - loss: 0.4370 - val_loss: 0.4454
Epoch 16/100
0s - loss: 0.4345 - val_loss: 0.4449
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:45:21,751 - 28_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.444921
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5863 - val_loss: 0.5404
Epoch 2/100
0s - loss: 0.5129 - val_loss: 0.5088
Epoch 3/100
0s - loss: 0.4851 - val_loss: 0.4962
Epoch 4/100
0s - loss: 0.4743 - val_loss: 0.4909
Epoch 5/100
0s - loss: 0.4682 - val_loss: 0.4845
Epoch 6/100
0s - loss: 0.4630 - val_loss: 0.4821
Epoch 7/100
0s - loss: 0.4586 - val_loss: 0.4788
Epoch 8/100
0s - loss: 0.4546 - val_loss: 0.4762
Epoch 9/100
0s - loss: 0.4516 - val_loss: 0.4749
Epoch 10/100
0s - loss: 0.4485 - val_loss: 0.4736
Epoch 11/100
0s - loss: 0.4454 - val_loss: 0.4720
Epoch 12/100
0s - loss: 0.4423 - val_loss: 0.4699
Epoch 13/100
0s - loss: 0.4391 - val_loss: 0.4700
Epoch 14/100
0s - loss: 0.4361 - val_loss: 0.4691
Epoch 15/100
0s - loss: 0.4335 - val_loss: 0.4681
Epoch 16/100
0s - loss: 0.4301 - val_loss: 0.4666
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:45:32,024 - 28_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.466559
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5885 - val_loss: 0.5268
Epoch 2/100
0s - loss: 0.5106 - val_loss: 0.4895
Epoch 3/100
0s - loss: 0.4854 - val_loss: 0.4757
Epoch 4/100
0s - loss: 0.4752 - val_loss: 0.4682
Epoch 5/100
0s - loss: 0.4690 - val_loss: 0.4629
Epoch 6/100
0s - loss: 0.4638 - val_loss: 0.4589
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4563
Epoch 8/100
0s - loss: 0.4557 - val_loss: 0.4544
Epoch 9/100
0s - loss: 0.4529 - val_loss: 0.4523
Epoch 10/100
0s - loss: 0.4496 - val_loss: 0.4510
Epoch 11/100
0s - loss: 0.4464 - val_loss: 0.4498
Epoch 12/100
0s - loss: 0.4434 - val_loss: 0.4492
Epoch 13/100
0s - loss: 0.4404 - val_loss: 0.4474
Epoch 14/100
0s - loss: 0.4372 - val_loss: 0.4461
Epoch 15/100
0s - loss: 0.4340 - val_loss: 0.4453
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:45:41,775 - 28_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.445317
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5815 - val_loss: 0.5284
Epoch 2/100
0s - loss: 0.5083 - val_loss: 0.4944
Epoch 3/100
0s - loss: 0.4821 - val_loss: 0.4833
Epoch 4/100
0s - loss: 0.4738 - val_loss: 0.4782
Epoch 5/100
0s - loss: 0.4680 - val_loss: 0.4738
Epoch 6/100
0s - loss: 0.4627 - val_loss: 0.4708
Epoch 7/100
0s - loss: 0.4588 - val_loss: 0.4678
Epoch 8/100
0s - loss: 0.4553 - val_loss: 0.4664
Epoch 9/100
0s - loss: 0.4520 - val_loss: 0.4647
Epoch 10/100
0s - loss: 0.4493 - val_loss: 0.4637
Epoch 11/100
0s - loss: 0.4467 - val_loss: 0.4624
Epoch 12/100
0s - loss: 0.4437 - val_loss: 0.4613
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:45:49,829 - 28_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.461336
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5835 - val_loss: 0.5288
Epoch 2/100
0s - loss: 0.5095 - val_loss: 0.4901
Epoch 3/100
0s - loss: 0.4843 - val_loss: 0.4750
Epoch 4/100
0s - loss: 0.4752 - val_loss: 0.4690
Epoch 5/100
0s - loss: 0.4689 - val_loss: 0.4653
Epoch 6/100
0s - loss: 0.4644 - val_loss: 0.4620
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4579
Epoch 8/100
0s - loss: 0.4560 - val_loss: 0.4568
Epoch 9/100
0s - loss: 0.4534 - val_loss: 0.4537
Epoch 10/100
0s - loss: 0.4501 - val_loss: 0.4528
Epoch 11/100
0s - loss: 0.4469 - val_loss: 0.4513
Epoch 12/100
0s - loss: 0.4440 - val_loss: 0.4493
Epoch 13/100
0s - loss: 0.4409 - val_loss: 0.4487
Epoch 14/100
0s - loss: 0.4379 - val_loss: 0.4475
Epoch 15/100
0s - loss: 0.4346 - val_loss: 0.4468
Epoch 16/100
0s - loss: 0.4313 - val_loss: 0.4457
Epoch 17/100
0s - loss: 0.4287 - val_loss: 0.4451
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:00,583 - 28_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.445083
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:00,584 - 28_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453446
Train on 553 samples, validate on 69 samples
Epoch 1/100
0s - loss: 0.5887 - val_loss: 0.5307
Epoch 2/100
0s - loss: 0.5168 - val_loss: 0.4978
Epoch 3/100
0s - loss: 0.4916 - val_loss: 0.4818
Epoch 4/100
0s - loss: 0.4794 - val_loss: 0.4748
Epoch 5/100
0s - loss: 0.4724 - val_loss: 0.4733
Epoch 6/100
0s - loss: 0.4680 - val_loss: 0.4674
Epoch 7/100
0s - loss: 0.4629 - val_loss: 0.4655
Epoch 8/100
0s - loss: 0.4595 - val_loss: 0.4631
Epoch 9/100
0s - loss: 0.4565 - val_loss: 0.4615
Epoch 10/100
0s - loss: 0.4542 - val_loss: 0.4608
Epoch 11/100
0s - loss: 0.4517 - val_loss: 0.4592
Epoch 12/100
0s - loss: 0.4497 - val_loss: 0.4585
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:08,544 - 29_UsokinAE_450-250_150_elu|Fold #1 Loss = 0.458470
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5806 - val_loss: 0.5250
Epoch 2/100
0s - loss: 0.5140 - val_loss: 0.4928
Epoch 3/100
0s - loss: 0.4869 - val_loss: 0.4754
Epoch 4/100
0s - loss: 0.4750 - val_loss: 0.4695
Epoch 5/100
0s - loss: 0.4685 - val_loss: 0.4643
Epoch 6/100
0s - loss: 0.4630 - val_loss: 0.4618
Epoch 7/100
0s - loss: 0.4591 - val_loss: 0.4597
Epoch 8/100
0s - loss: 0.4559 - val_loss: 0.4565
Epoch 9/100
0s - loss: 0.4526 - val_loss: 0.4549
Epoch 10/100
0s - loss: 0.4497 - val_loss: 0.4537
Epoch 11/100
0s - loss: 0.4466 - val_loss: 0.4521
Epoch 12/100
0s - loss: 0.4435 - val_loss: 0.4513
Epoch 13/100
0s - loss: 0.4406 - val_loss: 0.4502
Epoch 14/100
0s - loss: 0.4376 - val_loss: 0.4495
Epoch 15/100
0s - loss: 0.4350 - val_loss: 0.4482
Epoch 16/100
0s - loss: 0.4320 - val_loss: 0.4473
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:18,587 - 29_UsokinAE_450-250_150_elu|Fold #2 Loss = 0.447349
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5824 - val_loss: 0.5313
Epoch 2/100
0s - loss: 0.5099 - val_loss: 0.4998
Epoch 3/100
0s - loss: 0.4841 - val_loss: 0.4886
Epoch 4/100
0s - loss: 0.4746 - val_loss: 0.4829
Epoch 5/100
0s - loss: 0.4685 - val_loss: 0.4786
Epoch 6/100
0s - loss: 0.4631 - val_loss: 0.4754
Epoch 7/100
0s - loss: 0.4587 - val_loss: 0.4725
Epoch 8/100
0s - loss: 0.4551 - val_loss: 0.4703
Epoch 9/100
0s - loss: 0.4521 - val_loss: 0.4687
Epoch 10/100
0s - loss: 0.4493 - val_loss: 0.4675
Epoch 11/100
0s - loss: 0.4466 - val_loss: 0.4661
Epoch 12/100
0s - loss: 0.4438 - val_loss: 0.4652
Epoch 13/100
0s - loss: 0.4413 - val_loss: 0.4645
Epoch 14/100
0s - loss: 0.4385 - val_loss: 0.4629
Epoch 15/100
0s - loss: 0.4353 - val_loss: 0.4653
Epoch 16/100
0s - loss: 0.4333 - val_loss: 0.4617
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:28,846 - 29_UsokinAE_450-250_150_elu|Fold #3 Loss = 0.461669
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5804 - val_loss: 0.5269
Epoch 2/100
0s - loss: 0.5112 - val_loss: 0.4904
Epoch 3/100
0s - loss: 0.4840 - val_loss: 0.4766
Epoch 4/100
0s - loss: 0.4734 - val_loss: 0.4708
Epoch 5/100
0s - loss: 0.4671 - val_loss: 0.4665
Epoch 6/100
0s - loss: 0.4633 - val_loss: 0.4648
Epoch 7/100
0s - loss: 0.4597 - val_loss: 0.4616
Epoch 8/100
0s - loss: 0.4564 - val_loss: 0.4602
Epoch 9/100
0s - loss: 0.4529 - val_loss: 0.4573
Epoch 10/100
0s - loss: 0.4500 - val_loss: 0.4556
Epoch 11/100
0s - loss: 0.4468 - val_loss: 0.4546
Epoch 12/100
0s - loss: 0.4440 - val_loss: 0.4529
Epoch 13/100
0s - loss: 0.4407 - val_loss: 0.4525
Epoch 14/100
0s - loss: 0.4385 - val_loss: 0.4506
Epoch 15/100
0s - loss: 0.4352 - val_loss: 0.4501
Epoch 16/100
0s - loss: 0.4322 - val_loss: 0.4498
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:39,174 - 29_UsokinAE_450-250_150_elu|Fold #4 Loss = 0.449767
Train on 562 samples, validate on 60 samples
Epoch 1/100
0s - loss: 0.5868 - val_loss: 0.5328
Epoch 2/100
0s - loss: 0.5150 - val_loss: 0.5006
Epoch 3/100
0s - loss: 0.4875 - val_loss: 0.4821
Epoch 4/100
0s - loss: 0.4755 - val_loss: 0.4764
Epoch 5/100
0s - loss: 0.4689 - val_loss: 0.4725
Epoch 6/100
0s - loss: 0.4636 - val_loss: 0.4680
Epoch 7/100
0s - loss: 0.4592 - val_loss: 0.4657
Epoch 8/100
0s - loss: 0.4558 - val_loss: 0.4634
Epoch 9/100
0s - loss: 0.4528 - val_loss: 0.4624
Epoch 10/100
0s - loss: 0.4501 - val_loss: 0.4616
Epoch 11/100
0s - loss: 0.4473 - val_loss: 0.4597
Epoch 12/100
0s - loss: 0.4446 - val_loss: 0.4592
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:47,142 - 29_UsokinAE_450-250_150_elu|Fold #5 Loss = 0.459183
Train on 556 samples, validate on 66 samples
Epoch 1/100
0s - loss: 0.5859 - val_loss: 0.5213
Epoch 2/100
0s - loss: 0.5129 - val_loss: 0.4885
Epoch 3/100
0s - loss: 0.4880 - val_loss: 0.4737
Epoch 4/100
0s - loss: 0.4771 - val_loss: 0.4666
Epoch 5/100
0s - loss: 0.4702 - val_loss: 0.4632
Epoch 6/100
0s - loss: 0.4659 - val_loss: 0.4589
Epoch 7/100
0s - loss: 0.4616 - val_loss: 0.4559
Epoch 8/100
0s - loss: 0.4578 - val_loss: 0.4540
Epoch 9/100
0s - loss: 0.4549 - val_loss: 0.4527
Epoch 10/100
0s - loss: 0.4524 - val_loss: 0.4510
Epoch 11/100
0s - loss: 0.4490 - val_loss: 0.4491
Epoch 12/100
0s - loss: 0.4463 - val_loss: 0.4489
Epoch 13/100
0s - loss: 0.4438 - val_loss: 0.4477
Epoch 14/100
0s - loss: 0.4409 - val_loss: 0.4475
Epoch 15/100
0s - loss: 0.4389 - val_loss: 0.4473
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:46:56,779 - 29_UsokinAE_450-250_150_elu|Fold #6 Loss = 0.447272
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5764 - val_loss: 0.5381
Epoch 2/100
0s - loss: 0.5073 - val_loss: 0.5059
Epoch 3/100
0s - loss: 0.4828 - val_loss: 0.4949
Epoch 4/100
0s - loss: 0.4735 - val_loss: 0.4897
Epoch 5/100
0s - loss: 0.4682 - val_loss: 0.4862
Epoch 6/100
0s - loss: 0.4626 - val_loss: 0.4833
Epoch 7/100
0s - loss: 0.4587 - val_loss: 0.4796
Epoch 8/100
0s - loss: 0.4548 - val_loss: 0.4773
Epoch 9/100
0s - loss: 0.4516 - val_loss: 0.4756
Epoch 10/100
0s - loss: 0.4489 - val_loss: 0.4737
Epoch 11/100
0s - loss: 0.4455 - val_loss: 0.4720
Epoch 12/100
0s - loss: 0.4427 - val_loss: 0.4707
Epoch 13/100
0s - loss: 0.4396 - val_loss: 0.4705
Epoch 14/100
0s - loss: 0.4373 - val_loss: 0.4692
Epoch 15/100
0s - loss: 0.4342 - val_loss: 0.4706
Epoch 16/100
0s - loss: 0.4320 - val_loss: 0.4708
Epoch 17/100
0s - loss: 0.4289 - val_loss: 0.4669
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:07,351 - 29_UsokinAE_450-250_150_elu|Fold #7 Loss = 0.466861
Train on 561 samples, validate on 61 samples
Epoch 1/100
0s - loss: 0.5849 - val_loss: 0.5271
Epoch 2/100
0s - loss: 0.5134 - val_loss: 0.4932
Epoch 3/100
0s - loss: 0.4863 - val_loss: 0.4748
Epoch 4/100
0s - loss: 0.4761 - val_loss: 0.4691
Epoch 5/100
0s - loss: 0.4710 - val_loss: 0.4627
Epoch 6/100
0s - loss: 0.4656 - val_loss: 0.4595
Epoch 7/100
0s - loss: 0.4607 - val_loss: 0.4560
Epoch 8/100
0s - loss: 0.4573 - val_loss: 0.4543
Epoch 9/100
0s - loss: 0.4542 - val_loss: 0.4518
Epoch 10/100
0s - loss: 0.4516 - val_loss: 0.4512
Epoch 11/100
0s - loss: 0.4491 - val_loss: 0.4499
Epoch 12/100
0s - loss: 0.4462 - val_loss: 0.4483
Epoch 13/100
0s - loss: 0.4437 - val_loss: 0.4486
Epoch 14/100
0s - loss: 0.4408 - val_loss: 0.4464
Epoch 15/100
0s - loss: 0.4375 - val_loss: 0.4453
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:16,910 - 29_UsokinAE_450-250_150_elu|Fold #8 Loss = 0.445314
Train on 560 samples, validate on 62 samples
Epoch 1/100
0s - loss: 0.5818 - val_loss: 0.5357
Epoch 2/100
0s - loss: 0.5171 - val_loss: 0.5004
Epoch 3/100
0s - loss: 0.4878 - val_loss: 0.4856
Epoch 4/100
0s - loss: 0.4762 - val_loss: 0.4796
Epoch 5/100
0s - loss: 0.4696 - val_loss: 0.4752
Epoch 6/100
0s - loss: 0.4637 - val_loss: 0.4714
Epoch 7/100
0s - loss: 0.4589 - val_loss: 0.4693
Epoch 8/100
0s - loss: 0.4556 - val_loss: 0.4666
Epoch 9/100
0s - loss: 0.4526 - val_loss: 0.4658
Epoch 10/100
0s - loss: 0.4501 - val_loss: 0.4640
Epoch 11/100
0s - loss: 0.4475 - val_loss: 0.4628
Epoch 12/100
0s - loss: 0.4442 - val_loss: 0.4615
Epoch 13/100
0s - loss: 0.4415 - val_loss: 0.4610
Epoch 14/100
0s - loss: 0.4385 - val_loss: 0.4608
Epoch 15/100
0s - loss: 0.4356 - val_loss: 0.4584
Epoch 16/100
0s - loss: 0.4323 - val_loss: 0.4576
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:27,150 - 29_UsokinAE_450-250_150_elu|Fold #9 Loss = 0.457617
Train on 564 samples, validate on 58 samples
Epoch 1/100
0s - loss: 0.5844 - val_loss: 0.5324
Epoch 2/100
0s - loss: 0.5127 - val_loss: 0.4910
Epoch 3/100
0s - loss: 0.4847 - val_loss: 0.4762
Epoch 4/100
0s - loss: 0.4753 - val_loss: 0.4703
Epoch 5/100
0s - loss: 0.4686 - val_loss: 0.4643
Epoch 6/100
0s - loss: 0.4630 - val_loss: 0.4599
Epoch 7/100
0s - loss: 0.4589 - val_loss: 0.4578
Epoch 8/100
0s - loss: 0.4558 - val_loss: 0.4563
Epoch 9/100
0s - loss: 0.4528 - val_loss: 0.4546
Epoch 10/100
0s - loss: 0.4497 - val_loss: 0.4527
Epoch 11/100
0s - loss: 0.4469 - val_loss: 0.4529
Epoch 12/100
0s - loss: 0.4450 - val_loss: 0.4515
Epoch 13/100
0s - loss: 0.4417 - val_loss: 0.4502
Epoch 14/100
0s - loss: 0.4386 - val_loss: 0.4487
Epoch 15/100
0s - loss: 0.4357 - val_loss: 0.4472
Epoch 16/100
0s - loss: 0.4326 - val_loss: 0.4463
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:37,304 - 29_UsokinAE_450-250_150_elu|Fold #10 Loss = 0.446327
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:37,304 - 29_UsokinAE_450-250_150_elu|Avg Validation Loss = 0.453983
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:37,306 - Finished hyperopt optimization
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:47:37,323 - Training Final AE: 30_UsokinAE_450-250_150_elu_FULL
Train on 622 samples, validate on 622 samples
Epoch 1/100
1s - loss: 0.5791 - val_loss: 0.5244
Epoch 2/100
0s - loss: 0.5067 - val_loss: 0.4871
Epoch 3/100
0s - loss: 0.4821 - val_loss: 0.4743
Epoch 4/100
0s - loss: 0.4721 - val_loss: 0.4670
Epoch 5/100
0s - loss: 0.4665 - val_loss: 0.4629
Epoch 6/100
0s - loss: 0.4620 - val_loss: 0.4583
Epoch 7/100
0s - loss: 0.4584 - val_loss: 0.4547
Epoch 8/100
0s - loss: 0.4549 - val_loss: 0.4519
Epoch 9/100
0s - loss: 0.4523 - val_loss: 0.4491
Epoch 10/100
0s - loss: 0.4492 - val_loss: 0.4459
Epoch 11/100
0s - loss: 0.4462 - val_loss: 0.4430
Epoch 12/100
0s - loss: 0.4433 - val_loss: 0.4400
Epoch 13/100
0s - loss: 0.4402 - val_loss: 0.4366
Epoch 14/100
0s - loss: 0.4371 - val_loss: 0.4340
Epoch 15/100
0s - loss: 0.4343 - val_loss: 0.4307
Epoch 16/100
0s - loss: 0.4310 - val_loss: 0.4274
Epoch 17/100
0s - loss: 0.4277 - val_loss: 0.4240
Epoch 18/100
0s - loss: 0.4246 - val_loss: 0.4211
Epoch 19/100
0s - loss: 0.4218 - val_loss: 0.4190
Epoch 20/100
0s - loss: 0.4188 - val_loss: 0.4149
Epoch 21/100
0s - loss: 0.4158 - val_loss: 0.4124
Epoch 22/100
0s - loss: 0.4135 - val_loss: 0.4115
Epoch 23/100
0s - loss: 0.4112 - val_loss: 0.4069
Epoch 24/100
0s - loss: 0.4082 - val_loss: 0.4052
Epoch 25/100
0s - loss: 0.4058 - val_loss: 0.4025
Epoch 26/100
0s - loss: 0.4031 - val_loss: 0.3998
Epoch 27/100
0s - loss: 0.4010 - val_loss: 0.3986
Epoch 28/100
0s - loss: 0.3989 - val_loss: 0.3955
Epoch 29/100
0s - loss: 0.3966 - val_loss: 0.3933
Epoch 30/100
0s - loss: 0.3946 - val_loss: 0.3914
Epoch 31/100
0s - loss: 0.3924 - val_loss: 0.3892
Epoch 32/100
0s - loss: 0.3906 - val_loss: 0.3867
Epoch 33/100
0s - loss: 0.3883 - val_loss: 0.3849
Epoch 34/100
0s - loss: 0.3861 - val_loss: 0.3829
Epoch 35/100
0s - loss: 0.3842 - val_loss: 0.3813
Epoch 36/100
0s - loss: 0.3826 - val_loss: 0.3798
Epoch 37/100
0s - loss: 0.3807 - val_loss: 0.3776
Epoch 38/100
0s - loss: 0.3788 - val_loss: 0.3761
Epoch 39/100
0s - loss: 0.3774 - val_loss: 0.3749
Epoch 40/100
0s - loss: 0.3758 - val_loss: 0.3732
Epoch 41/100
0s - loss: 0.3739 - val_loss: 0.3717
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:48:18,177 - 30_UsokinAE_450-250_150_elu_FULL|Loss = 0.371676
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:48:18,178 - Creating latent represenations...
[train_usokin-500g-scaled-2L-adam-ae] 2017-07-22 21:48:18,459 - Saving results
