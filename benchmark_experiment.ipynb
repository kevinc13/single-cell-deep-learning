{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import framework.clustering\n",
    "from framework.common.util import save_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"pollen\"\n",
    "n_clusters = 11\n",
    "clustering_method = \"hc\"\n",
    "\n",
    "label_col = \"cell_subtype\"\n",
    "latent_space_end_col_idx = -2\n",
    "\n",
    "latent_space_file = \"latent_representations.txt\"\n",
    "output_dir_name = \"benchmark_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Experiment(s) in Directory: pollen\n"
     ]
    }
   ],
   "source": [
    "full_dir = \"results/{}\".format(input_dir)\n",
    "output_dir = full_dir + \"/\" + output_dir_name\n",
    "\n",
    "def load_latent_space(filepath, latent_space_end_col_idx, label_col):\n",
    "    df = pd.read_csv(filepath, sep=\"\\t\", header=0, index_col=0)\n",
    "    latent_space = df.iloc[:, 0:latent_space_end_col_idx].values.astype(\n",
    "        dtype=np.float64)\n",
    "    labels = df.loc[:, label_col].values\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(labels)\n",
    "    int_labels = label_encoder.transform(labels)\n",
    "    return df, latent_space, labels, int_labels\n",
    "\n",
    "def evaluate_clustering(true_clusters, pred_clusters, features):\n",
    "    return OrderedDict({\n",
    "        \"ari\": metrics.adjusted_rand_score(true_clusters, pred_clusters),\n",
    "        \"ami\": metrics.adjusted_mutual_info_score(true_clusters, pred_clusters),\n",
    "        \"completeness_score\": metrics.completeness_score(true_clusters, pred_clusters),\n",
    "        \"homogeneity_score\": metrics.homogeneity_score(true_clusters, pred_clusters),\n",
    "        \"v_measure_score\": metrics.v_measure_score(true_clusters, pred_clusters),\n",
    "        \"silhouette_score\": metrics.silhouette_score(features, pred_clusters,\n",
    "                                                     metric='euclidean')\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"Benchmarking Experiment(s) in Directory: {}\".format(\n",
    "        os.path.basename(os.path.normpath(full_dir))))\n",
    "\n",
    "clustering_results = []\n",
    "clustering_results.append([\"experiment_name\", \"model_name\", \"ari\", \"ami\", \n",
    "                           \"completeness_score\", \"homogeneity_score\",\n",
    "                           \"v_measure_score\", \"silhouette_score\"])\n",
    "\n",
    "for filepath in glob.iglob(\n",
    "        full_dir + \"/**/\" + latent_space_file,\n",
    "        recursive=True):\n",
    "    model_dir = os.path.dirname(filepath)\n",
    "    model_name = os.path.basename(model_dir)\n",
    "    experiment_name = os.path.basename(\n",
    "        os.path.dirname(model_dir))\n",
    "\n",
    "    df, latent_space, labels, int_labels = load_latent_space(\n",
    "        filepath, latent_space_end_col_idx, label_col)\n",
    "    \n",
    "    if not os.path.exists(output_dir + \"/clustering\"):\n",
    "        os.makedirs(output_dir + \"/clustering\")\n",
    "    \n",
    "    clustering_obj_file = output_dir + \"/clustering/\" + \\\n",
    "        clustering_method + \"_\" + experiment_name + \".pkl\"\n",
    "    if not os.path.exists(clustering_obj_file):\n",
    "        clustering_method_ref = eval(\"framework.clustering.cluster_\" + clustering_method)\n",
    "        clustering_obj = clustering_method_ref(latent_space, n_clusters)\n",
    "        with open(clustering_obj_file, \"wb\") as f:\n",
    "            pickle.dump(clustering_obj, f)\n",
    "    else:\n",
    "        with open(clustering_obj_file, \"rb\") as f:\n",
    "            clustering_obj = pickle.load(f)\n",
    "    \n",
    "    results = list(evaluate_clustering(int_labels, clustering_obj[\"clusters\"], latent_space).values())\n",
    "    results = [experiment_name, model_name] + results\n",
    "    clustering_results.append(results)\n",
    "    \n",
    "save_data_table(clustering_results, \n",
    "                output_dir + \"/{}_clustering_results.txt\".format(clustering_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
