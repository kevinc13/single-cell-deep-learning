{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from framework.common.util import save_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "dataset = \"Pollen/processed/pollen.500g.txt\"\n",
    "# Number of genes to use\n",
    "n_genes = 500\n",
    "# Number of PCA components to use\n",
    "n_components = 10\n",
    "# Where to save the resulting PCA components\n",
    "results_dir = \"results/pollen/pca/pca_\" + str(n_genes) + \"g\"\n",
    "\n",
    "features_start_col_idx = 0\n",
    "has_labels = True\n",
    "features_end_col_idx = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data/\"\n",
    "filepath = base_dir + dataset\n",
    "df = pd.read_csv(filepath, sep=\"\\t\", header=0, index_col=0)\n",
    "\n",
    "if has_labels:\n",
    "    features = df.iloc[:, features_start_col_idx:features_end_col_idx].values.astype(dtype=np.float64)\n",
    "    label_info = df.iloc[:, features_end_col_idx:].values\n",
    "else:\n",
    "    features = df.iloc[:, features_start_col_idx:].values.astype(dtype=np.float64)\n",
    "    \n",
    "features_scaled = scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA and save the reduced dimensional representations\n",
    "pca_components = PCA(n_components=n_components).fit_transform(features_scaled)\n",
    "\n",
    "results = np.hstack((\n",
    "    np.expand_dims(df.index.values, axis=1),\n",
    "    pca_components\n",
    "))\n",
    "if has_labels:\n",
    "    results = np.hstack((results, label_info))\n",
    "    \n",
    "header = [\"cell_ids\"]\n",
    "for l in range(1, n_components + 1):\n",
    "    header.append(\"dim{}\".format(l))\n",
    "if has_labels:\n",
    "    header.extend(list(df.columns.values[features_end_col_idx:]))\n",
    "header = np.array(header)\n",
    "\n",
    "results = np.vstack((header, results))\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "save_data_table(\n",
    "    results,\n",
    "    results_dir + \"/latent_representations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
